<!DOCTYPE html>





<html class="theme-next mist use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="generator" content="Hexo 3.9.0">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/bitbug_favicon1.ico?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/bitbug_favicon.ico?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"right","display":"hide","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    save_scroll: false,
    copycode: {"enable":true,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="改变色彩空间目标 在本教程中，您将学习如何将图像从一种颜色空间转换为另一种颜色空间，例如BGR ↔ Gray，BGR ↔ HSV等。 除此之外，我们还将创建一个应用程序，以提取视频中的彩色对象 您将学习以下功能：cv.cvtColor()，cv.inRange()等 改变色彩空间OpenCV提供了150多种颜色空间转换方法。但是，我们将只研究两种使用最广泛的工具，即BGR ↔ Gray和BGR ↔">
<meta name="keywords" content="python,tensorflow,pytorch,人工智能">
<meta property="og:type" content="article">
<meta property="og:title" content="OpenCV中的图像处理">
<meta property="og:url" content="http://leesin.cc/opencv/OpenCV中的图像处理.html">
<meta property="og:site_name" content="Chen Jian&#39;s Blog">
<meta property="og:description" content="改变色彩空间目标 在本教程中，您将学习如何将图像从一种颜色空间转换为另一种颜色空间，例如BGR ↔ Gray，BGR ↔ HSV等。 除此之外，我们还将创建一个应用程序，以提取视频中的彩色对象 您将学习以下功能：cv.cvtColor()，cv.inRange()等 改变色彩空间OpenCV提供了150多种颜色空间转换方法。但是，我们将只研究两种使用最广泛的工具，即BGR ↔ Gray和BGR ↔">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://leesin.cc/images/hsv.PNG">
<meta property="og:image" content="http://leesin.cc/images/output_7_0.png">
<meta property="og:image" content="http://leesin.cc/images/output_9_0.png">
<meta property="og:image" content="http://leesin.cc/images/output_1_0.png">
<meta property="og:image" content="http://leesin.cc/images/output_3_0.png">
<meta property="og:image" content="http://leesin.cc/images/otsu.jpg">
<meta property="og:image" content="http://leesin.cc/images/filter.jpg">
<meta property="og:image" content="http://leesin.cc/images/blur.jpg">
<meta property="og:image" content="http://leesin.cc/images/gaussian.jpg">
<meta property="og:image" content="http://leesin.cc/images/median.jpg">
<meta property="og:image" content="http://leesin.cc/images/bilateral.jpg">
<meta property="og:image" content="http://leesin.cc/images/j.png">
<meta property="og:image" content="http://leesin.cc/images/erosion.png">
<meta property="og:image" content="http://leesin.cc/images/dilation.png">
<meta property="og:image" content="http://leesin.cc/images/opening.png">
<meta property="og:image" content="http://leesin.cc/images/closing.png">
<meta property="og:image" content="http://leesin.cc/images/gradient.png">
<meta property="og:image" content="http://leesin.cc/images/tophat.png">
<meta property="og:image" content="http://leesin.cc/images/blackhat.png">
<meta property="og:image" content="http://leesin.cc/images/gradients.jpg">
<meta property="og:image" content="http://leesin.cc/images/double_edge.jpg">
<meta property="og:image" content="http://leesin.cc/images/nms.jpg">
<meta property="og:image" content="http://leesin.cc/images/hysteresis.jpg">
<meta property="og:image" content="http://leesin.cc/images/output_6_0.png">
<meta property="og:image" content="http://leesin.cc/images/messipyr.jpg">
<meta property="og:image" content="http://leesin.cc/images/messiup.jpg">
<meta property="og:image" content="http://leesin.cc/images/lap.jpg">
<meta property="og:image" content="http://leesin.cc/images/orapple.jpg">
<meta property="og:image" content="http://leesin.cc/images/approx.jpg">
<meta property="og:image" content="http://leesin.cc/images/convexitydefects.jpg">
<meta property="og:image" content="http://leesin.cc/images/boundingrect.png">
<meta property="og:image" content="http://leesin.cc/images/circumcircle.png">
<meta property="og:image" content="http://leesin.cc/images/fitellipse.png">
<meta property="og:image" content="http://leesin.cc/images/fitline.jpg">
<meta property="og:image" content="http://leesin.cc/images/defects.jpg">
<meta property="og:image" content="http://leesin.cc/images/matchshapes.jpg">
<meta property="og:image" content="http://leesin.cc/images/hierarchy.png">
<meta property="og:image" content="http://leesin.cc/images/ccomp_hierarchy.png">
<meta property="og:image" content="http://leesin.cc/images/tree_hierarchy.png">
<meta property="og:image" content="http://leesin.cc/images/histogram_sample.jpg">
<meta property="og:image" content="http://leesin.cc/images/histogram_matplotlib.jpg">
<meta property="og:image" content="http://leesin.cc/images/histogram_masking.jpg">
<meta property="og:image" content="http://leesin.cc/images/histogram_equalization.png">
<meta property="og:image" content="http://leesin.cc/images/histeq_numpy2.jpg">
<meta property="og:image" content="http://leesin.cc/images/clahe_1.jpg">
<meta property="og:image" content="http://leesin.cc/images/clahe_2.jpg">
<meta property="og:image" content="http://leesin.cc/images/2dhist_matplotlib.jpg">
<meta property="og:image" content="http://leesin.cc/images/2dhist_opencv.jpg">
<meta property="og:image" content="http://leesin.cc/images/backproject_opencv.jpg">
<meta property="og:image" content="http://leesin.cc/images/fft1.jpg">
<meta property="og:image" content="http://leesin.cc/images/fft2.jpg">
<meta property="og:image" content="http://leesin.cc/images/fft4.jpg">
<meta property="og:image" content="http://leesin.cc/images/fft5.jpg">
<meta property="og:image" content="http://leesin.cc/images/messi_face.jpg">
<meta property="og:image" content="http://leesin.cc/images/template_ccoeff_1.jpg">
<meta property="og:image" content="http://leesin.cc/images/template_ccoeffn_2.jpg">
<meta property="og:image" content="http://leesin.cc/images/template_ccorr_3.jpg">
<meta property="og:image" content="http://leesin.cc/images/template_ccorrn_4.jpg">
<meta property="og:image" content="http://leesin.cc/images/template_sqdiff_5.jpg">
<meta property="og:image" content="http://leesin.cc/images/template_sqdiffn_6.jpg">
<meta property="og:image" content="http://leesin.cc/images/res_mario.jpg">
<meta property="og:image" content="http://leesin.cc/images/houghlines3.jpg">
<meta property="og:image" content="http://leesin.cc/images/houghlines5.jpg">
<meta property="og:image" content="http://leesin.cc/images/houghcircles2.jpg">
<meta property="og:image" content="http://leesin.cc/images/water_coins.jpg">
<meta property="og:image" content="http://leesin.cc/images/water_thresh.jpg">
<meta property="og:image" content="http://leesin.cc/images/water_fgbg.jpg">
<meta property="og:image" content="http://leesin.cc/images/water_dt.jpg">
<meta property="og:image" content="http://leesin.cc/images/water_marker.jpg">
<meta property="og:image" content="http://leesin.cc/images/water_result.jpg">
<meta property="og:image" content="http://leesin.cc/images/grabcut_output1.jpg">
<meta property="og:image" content="http://leesin.cc/images/grabcut_scheme.jpg">
<meta property="og:image" content="http://leesin.cc/images/grabcut_rect.jpg">
<meta property="og:image" content="http://leesin.cc/images/grabcut_mask.jpg">
<meta property="og:updated_time" content="2019-10-20T06:41:53.617Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="OpenCV中的图像处理">
<meta name="twitter:description" content="改变色彩空间目标 在本教程中，您将学习如何将图像从一种颜色空间转换为另一种颜色空间，例如BGR ↔ Gray，BGR ↔ HSV等。 除此之外，我们还将创建一个应用程序，以提取视频中的彩色对象 您将学习以下功能：cv.cvtColor()，cv.inRange()等 改变色彩空间OpenCV提供了150多种颜色空间转换方法。但是，我们将只研究两种使用最广泛的工具，即BGR ↔ Gray和BGR ↔">
<meta name="twitter:image" content="http://leesin.cc/images/hsv.PNG">
  <link rel="canonical" href="http://leesin.cc/opencv/OpenCV中的图像处理">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>OpenCV中的图像处理 | Chen Jian's Blog</title>
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  <div class="container sidebar-position-right">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Chen Jian's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-reading">
      
    

    <a href="/reading/" rel="section"><i class="menu-item-icon fa fa-fw fa-book"></i> <br>笔记</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-miscellaneous">
      
    

    <a href="/miscellaneous/" rel="section"><i class="menu-item-icon fa fa-fw fa-link"></i> <br>常用网站</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
      </li>
    
  </ul>

    

</nav>
  <div class="site-search">
    
  <div class="popup search-popup">
  <div class="search-header">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <div class="search-input-wrapper">
      <input autocomplete="off" autocorrect="off" autocapitalize="none"
             placeholder="搜索..." spellcheck="false"
             type="text" id="search-input">
    </div>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>
  <div id="search-result"></div>
</div>


  </div>
</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content page-post-detail">
            

  <div id="posts" class="posts-expand">
    

  <article class="post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leesin.cc/opencv/OpenCV中的图像处理.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="陈 建">
      <meta itemprop="description" content="当时明月在，曾照彩云归">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen Jian's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">OpenCV中的图像处理

          
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2019-10-04 23:11:00" itemprop="dateCreated datePublished" datetime="2019-10-04T23:11:00+08:00">2019-10-04</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-10-20 14:41:53" itemprop="dateModified" datetime="2019-10-20T14:41:53+08:00">2019-10-20</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/OpenCV-Python-教程/" itemprop="url" rel="index"><span itemprop="name">OpenCV-Python 教程</span></a></span>

                
                
              
            </span>
          

          
            <span class="post-meta-item" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="改变色彩空间"><a href="#改变色彩空间" class="headerlink" title="改变色彩空间"></a>改变色彩空间</h1><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ul>
<li>在本教程中，您将学习如何将图像从一种颜色空间转换为另一种颜色空间，例如<code>BGR ↔ Gray</code>，<code>BGR ↔ HSV</code>等。</li>
<li>除此之外，我们还将创建一个应用程序，以提取视频中的彩色对象</li>
<li>您将学习以下功能：<code>cv.cvtColor()</code>，<code>cv.inRange()</code>等</li>
</ul><h2 id="改变色彩空间-1"><a href="#改变色彩空间-1" class="headerlink" title="改变色彩空间"></a>改变色彩空间</h2><p>OpenCV提供了150多种颜色空间转换方法。但是，我们将只研究两种使用最广泛的工具，即<code>BGR ↔ Gray</code>和<code>BGR ↔ HSV</code>。</p><a id="more"></a>

<p>对于颜色转换，我们使用函数<code>cv.cvtColor（input_image，flag）</code>，其中flag确定转换的类型。</p>
<p>对于<code>BGR → Gray</code>转换，我们使用标志<code>cv.COLOR_BGR2GRAY</code>。同样，对于<code>BGR → HSV</code>，我们使用标志<code>cv.COLOR_BGR2HSV</code>。要获取其他标志，只需在Python终端中运行以下命令：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">flags = [i <span class="keyword">for</span> i <span class="keyword">in</span> dir(cv) <span class="keyword">if</span> i.startswith(<span class="string">'COLOR_'</span>)]</span><br><span class="line">print(flags)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;COLOR_BAYER_BG2BGR&apos;, &apos;COLOR_BAYER_BG2BGRA&apos;, &apos;COLOR_BAYER_BG2BGR_EA&apos;, &apos;COLOR_BAYER_BG2BGR_VNG&apos;, &apos;COLOR_BAYER_BG2GRAY&apos;, &apos;COLOR_BAYER_BG2RGB&apos;, &apos;COLOR_BAYER_BG2RGBA&apos;, &apos;COLOR_BAYER_BG2RGB_EA&apos;, &apos;COLOR_BAYER_BG2RGB_VNG&apos;, &apos;COLOR_BAYER_GB2BGR&apos;, &apos;COLOR_BAYER_GB2BGRA&apos;, &apos;COLOR_BAYER_GB2BGR_EA&apos;, &apos;COLOR_BAYER_GB2BGR_VNG&apos;, &apos;COLOR_BAYER_GB2GRAY&apos;, &apos;COLOR_BAYER_GB2RGB&apos;, &apos;COLOR_BAYER_GB2RGBA&apos;, &apos;COLOR_BAYER_GB2RGB_EA&apos;, &apos;COLOR_BAYER_GB2RGB_VNG&apos;, &apos;COLOR_BAYER_GR2BGR&apos;, &apos;COLOR_BAYER_GR2BGRA&apos;, &apos;COLOR_BAYER_GR2BGR_EA&apos;, &apos;COLOR_BAYER_GR2BGR_VNG&apos;, &apos;COLOR_BAYER_GR2GRAY&apos;, &apos;COLOR_BAYER_GR2RGB&apos;, &apos;COLOR_BAYER_GR2RGBA&apos;, &apos;COLOR_BAYER_GR2RGB_EA&apos;, &apos;COLOR_BAYER_GR2RGB_VNG&apos;, &apos;COLOR_BAYER_RG2BGR&apos;, &apos;COLOR_BAYER_RG2BGRA&apos;, &apos;COLOR_BAYER_RG2BGR_EA&apos;, &apos;COLOR_BAYER_RG2BGR_VNG&apos;, &apos;COLOR_BAYER_RG2GRAY&apos;, &apos;COLOR_BAYER_RG2RGB&apos;, &apos;COLOR_BAYER_RG2RGBA&apos;, &apos;COLOR_BAYER_RG2RGB_EA&apos;, &apos;COLOR_BAYER_RG2RGB_VNG&apos;, &apos;COLOR_BGR2BGR555&apos;, &apos;COLOR_BGR2BGR565&apos;, &apos;COLOR_BGR2BGRA&apos;, &apos;COLOR_BGR2GRAY&apos;, &apos;COLOR_BGR2HLS&apos;, &apos;COLOR_BGR2HLS_FULL&apos;, &apos;COLOR_BGR2HSV&apos;, &apos;COLOR_BGR2HSV_FULL&apos;, &apos;COLOR_BGR2LAB&apos;, &apos;COLOR_BGR2LUV&apos;, &apos;COLOR_BGR2Lab&apos;, &apos;COLOR_BGR2Luv&apos;, &apos;COLOR_BGR2RGB&apos;, &apos;COLOR_BGR2RGBA&apos;, &apos;COLOR_BGR2XYZ&apos;, &apos;COLOR_BGR2YCR_CB&apos;, &apos;COLOR_BGR2YCrCb&apos;, &apos;COLOR_BGR2YUV&apos;, &apos;COLOR_BGR2YUV_I420&apos;, &apos;COLOR_BGR2YUV_IYUV&apos;, &apos;COLOR_BGR2YUV_YV12&apos;, &apos;COLOR_BGR5552BGR&apos;, &apos;COLOR_BGR5552BGRA&apos;, &apos;COLOR_BGR5552GRAY&apos;, &apos;COLOR_BGR5552RGB&apos;, &apos;COLOR_BGR5552RGBA&apos;, &apos;COLOR_BGR5652BGR&apos;, &apos;COLOR_BGR5652BGRA&apos;, &apos;COLOR_BGR5652GRAY&apos;, &apos;COLOR_BGR5652RGB&apos;, &apos;COLOR_BGR5652RGBA&apos;, &apos;COLOR_BGRA2BGR&apos;, &apos;COLOR_BGRA2BGR555&apos;, &apos;COLOR_BGRA2BGR565&apos;, &apos;COLOR_BGRA2GRAY&apos;, &apos;COLOR_BGRA2RGB&apos;, &apos;COLOR_BGRA2RGBA&apos;, &apos;COLOR_BGRA2YUV_I420&apos;, &apos;COLOR_BGRA2YUV_IYUV&apos;, &apos;COLOR_BGRA2YUV_YV12&apos;, &apos;COLOR_BayerBG2BGR&apos;, &apos;COLOR_BayerBG2BGRA&apos;, &apos;COLOR_BayerBG2BGR_EA&apos;, &apos;COLOR_BayerBG2BGR_VNG&apos;, &apos;COLOR_BayerBG2GRAY&apos;, &apos;COLOR_BayerBG2RGB&apos;, &apos;COLOR_BayerBG2RGBA&apos;, &apos;COLOR_BayerBG2RGB_EA&apos;, &apos;COLOR_BayerBG2RGB_VNG&apos;, &apos;COLOR_BayerGB2BGR&apos;, &apos;COLOR_BayerGB2BGRA&apos;, &apos;COLOR_BayerGB2BGR_EA&apos;, &apos;COLOR_BayerGB2BGR_VNG&apos;, &apos;COLOR_BayerGB2GRAY&apos;, &apos;COLOR_BayerGB2RGB&apos;, &apos;COLOR_BayerGB2RGBA&apos;, &apos;COLOR_BayerGB2RGB_EA&apos;, &apos;COLOR_BayerGB2RGB_VNG&apos;, &apos;COLOR_BayerGR2BGR&apos;, &apos;COLOR_BayerGR2BGRA&apos;, &apos;COLOR_BayerGR2BGR_EA&apos;, &apos;COLOR_BayerGR2BGR_VNG&apos;, &apos;COLOR_BayerGR2GRAY&apos;, &apos;COLOR_BayerGR2RGB&apos;, &apos;COLOR_BayerGR2RGBA&apos;, &apos;COLOR_BayerGR2RGB_EA&apos;, &apos;COLOR_BayerGR2RGB_VNG&apos;, &apos;COLOR_BayerRG2BGR&apos;, &apos;COLOR_BayerRG2BGRA&apos;, &apos;COLOR_BayerRG2BGR_EA&apos;, &apos;COLOR_BayerRG2BGR_VNG&apos;, &apos;COLOR_BayerRG2GRAY&apos;, &apos;COLOR_BayerRG2RGB&apos;, &apos;COLOR_BayerRG2RGBA&apos;, &apos;COLOR_BayerRG2RGB_EA&apos;, &apos;COLOR_BayerRG2RGB_VNG&apos;, &apos;COLOR_COLORCVT_MAX&apos;, &apos;COLOR_GRAY2BGR&apos;, &apos;COLOR_GRAY2BGR555&apos;, &apos;COLOR_GRAY2BGR565&apos;, &apos;COLOR_GRAY2BGRA&apos;, &apos;COLOR_GRAY2RGB&apos;, &apos;COLOR_GRAY2RGBA&apos;, &apos;COLOR_HLS2BGR&apos;, &apos;COLOR_HLS2BGR_FULL&apos;, &apos;COLOR_HLS2RGB&apos;, &apos;COLOR_HLS2RGB_FULL&apos;, &apos;COLOR_HSV2BGR&apos;, &apos;COLOR_HSV2BGR_FULL&apos;, &apos;COLOR_HSV2RGB&apos;, &apos;COLOR_HSV2RGB_FULL&apos;, &apos;COLOR_LAB2BGR&apos;, &apos;COLOR_LAB2LBGR&apos;, &apos;COLOR_LAB2LRGB&apos;, &apos;COLOR_LAB2RGB&apos;, &apos;COLOR_LBGR2LAB&apos;, &apos;COLOR_LBGR2LUV&apos;, &apos;COLOR_LBGR2Lab&apos;, &apos;COLOR_LBGR2Luv&apos;, &apos;COLOR_LRGB2LAB&apos;, &apos;COLOR_LRGB2LUV&apos;, &apos;COLOR_LRGB2Lab&apos;, &apos;COLOR_LRGB2Luv&apos;, &apos;COLOR_LUV2BGR&apos;, &apos;COLOR_LUV2LBGR&apos;, &apos;COLOR_LUV2LRGB&apos;, &apos;COLOR_LUV2RGB&apos;, &apos;COLOR_Lab2BGR&apos;, &apos;COLOR_Lab2LBGR&apos;, &apos;COLOR_Lab2LRGB&apos;, &apos;COLOR_Lab2RGB&apos;, &apos;COLOR_Luv2BGR&apos;, &apos;COLOR_Luv2LBGR&apos;, &apos;COLOR_Luv2LRGB&apos;, &apos;COLOR_Luv2RGB&apos;, &apos;COLOR_M_RGBA2RGBA&apos;, &apos;COLOR_RGB2BGR&apos;, &apos;COLOR_RGB2BGR555&apos;, &apos;COLOR_RGB2BGR565&apos;, &apos;COLOR_RGB2BGRA&apos;, &apos;COLOR_RGB2GRAY&apos;, &apos;COLOR_RGB2HLS&apos;, &apos;COLOR_RGB2HLS_FULL&apos;, &apos;COLOR_RGB2HSV&apos;, &apos;COLOR_RGB2HSV_FULL&apos;, &apos;COLOR_RGB2LAB&apos;, &apos;COLOR_RGB2LUV&apos;, &apos;COLOR_RGB2Lab&apos;, &apos;COLOR_RGB2Luv&apos;, &apos;COLOR_RGB2RGBA&apos;, &apos;COLOR_RGB2XYZ&apos;, &apos;COLOR_RGB2YCR_CB&apos;, &apos;COLOR_RGB2YCrCb&apos;, &apos;COLOR_RGB2YUV&apos;, &apos;COLOR_RGB2YUV_I420&apos;, &apos;COLOR_RGB2YUV_IYUV&apos;, &apos;COLOR_RGB2YUV_YV12&apos;, &apos;COLOR_RGBA2BGR&apos;, &apos;COLOR_RGBA2BGR555&apos;, &apos;COLOR_RGBA2BGR565&apos;, &apos;COLOR_RGBA2BGRA&apos;, &apos;COLOR_RGBA2GRAY&apos;, &apos;COLOR_RGBA2M_RGBA&apos;, &apos;COLOR_RGBA2RGB&apos;, &apos;COLOR_RGBA2YUV_I420&apos;, &apos;COLOR_RGBA2YUV_IYUV&apos;, &apos;COLOR_RGBA2YUV_YV12&apos;, &apos;COLOR_RGBA2mRGBA&apos;, &apos;COLOR_XYZ2BGR&apos;, &apos;COLOR_XYZ2RGB&apos;, &apos;COLOR_YCR_CB2BGR&apos;, &apos;COLOR_YCR_CB2RGB&apos;, &apos;COLOR_YCrCb2BGR&apos;, &apos;COLOR_YCrCb2RGB&apos;, &apos;COLOR_YUV2BGR&apos;, &apos;COLOR_YUV2BGRA_I420&apos;, &apos;COLOR_YUV2BGRA_IYUV&apos;, &apos;COLOR_YUV2BGRA_NV12&apos;, &apos;COLOR_YUV2BGRA_NV21&apos;, &apos;COLOR_YUV2BGRA_UYNV&apos;, &apos;COLOR_YUV2BGRA_UYVY&apos;, &apos;COLOR_YUV2BGRA_Y422&apos;, &apos;COLOR_YUV2BGRA_YUNV&apos;, &apos;COLOR_YUV2BGRA_YUY2&apos;, &apos;COLOR_YUV2BGRA_YUYV&apos;, &apos;COLOR_YUV2BGRA_YV12&apos;, &apos;COLOR_YUV2BGRA_YVYU&apos;, &apos;COLOR_YUV2BGR_I420&apos;, &apos;COLOR_YUV2BGR_IYUV&apos;, &apos;COLOR_YUV2BGR_NV12&apos;, &apos;COLOR_YUV2BGR_NV21&apos;, &apos;COLOR_YUV2BGR_UYNV&apos;, &apos;COLOR_YUV2BGR_UYVY&apos;, &apos;COLOR_YUV2BGR_Y422&apos;, &apos;COLOR_YUV2BGR_YUNV&apos;, &apos;COLOR_YUV2BGR_YUY2&apos;, &apos;COLOR_YUV2BGR_YUYV&apos;, &apos;COLOR_YUV2BGR_YV12&apos;, &apos;COLOR_YUV2BGR_YVYU&apos;, &apos;COLOR_YUV2GRAY_420&apos;, &apos;COLOR_YUV2GRAY_I420&apos;, &apos;COLOR_YUV2GRAY_IYUV&apos;, &apos;COLOR_YUV2GRAY_NV12&apos;, &apos;COLOR_YUV2GRAY_NV21&apos;, &apos;COLOR_YUV2GRAY_UYNV&apos;, &apos;COLOR_YUV2GRAY_UYVY&apos;, &apos;COLOR_YUV2GRAY_Y422&apos;, &apos;COLOR_YUV2GRAY_YUNV&apos;, &apos;COLOR_YUV2GRAY_YUY2&apos;, &apos;COLOR_YUV2GRAY_YUYV&apos;, &apos;COLOR_YUV2GRAY_YV12&apos;, &apos;COLOR_YUV2GRAY_YVYU&apos;, &apos;COLOR_YUV2RGB&apos;, &apos;COLOR_YUV2RGBA_I420&apos;, &apos;COLOR_YUV2RGBA_IYUV&apos;, &apos;COLOR_YUV2RGBA_NV12&apos;, &apos;COLOR_YUV2RGBA_NV21&apos;, &apos;COLOR_YUV2RGBA_UYNV&apos;, &apos;COLOR_YUV2RGBA_UYVY&apos;, &apos;COLOR_YUV2RGBA_Y422&apos;, &apos;COLOR_YUV2RGBA_YUNV&apos;, &apos;COLOR_YUV2RGBA_YUY2&apos;, &apos;COLOR_YUV2RGBA_YUYV&apos;, &apos;COLOR_YUV2RGBA_YV12&apos;, &apos;COLOR_YUV2RGBA_YVYU&apos;, &apos;COLOR_YUV2RGB_I420&apos;, &apos;COLOR_YUV2RGB_IYUV&apos;, &apos;COLOR_YUV2RGB_NV12&apos;, &apos;COLOR_YUV2RGB_NV21&apos;, &apos;COLOR_YUV2RGB_UYNV&apos;, &apos;COLOR_YUV2RGB_UYVY&apos;, &apos;COLOR_YUV2RGB_Y422&apos;, &apos;COLOR_YUV2RGB_YUNV&apos;, &apos;COLOR_YUV2RGB_YUY2&apos;, &apos;COLOR_YUV2RGB_YUYV&apos;, &apos;COLOR_YUV2RGB_YV12&apos;, &apos;COLOR_YUV2RGB_YVYU&apos;, &apos;COLOR_YUV420P2BGR&apos;, &apos;COLOR_YUV420P2BGRA&apos;, &apos;COLOR_YUV420P2GRAY&apos;, &apos;COLOR_YUV420P2RGB&apos;, &apos;COLOR_YUV420P2RGBA&apos;, &apos;COLOR_YUV420SP2BGR&apos;, &apos;COLOR_YUV420SP2BGRA&apos;, &apos;COLOR_YUV420SP2GRAY&apos;, &apos;COLOR_YUV420SP2RGB&apos;, &apos;COLOR_YUV420SP2RGBA&apos;, &apos;COLOR_YUV420p2BGR&apos;, &apos;COLOR_YUV420p2BGRA&apos;, &apos;COLOR_YUV420p2GRAY&apos;, &apos;COLOR_YUV420p2RGB&apos;, &apos;COLOR_YUV420p2RGBA&apos;, &apos;COLOR_YUV420sp2BGR&apos;, &apos;COLOR_YUV420sp2BGRA&apos;, &apos;COLOR_YUV420sp2GRAY&apos;, &apos;COLOR_YUV420sp2RGB&apos;, &apos;COLOR_YUV420sp2RGBA&apos;, &apos;COLOR_mRGBA2RGBA&apos;]</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意:对于HSV，色相范围为[0,179]，饱和度范围为[0,255]，值范围为[0,255]。不同的软件使用不同的比例。因此，如果将OpenCV值与它们进行比较，则需要将这些范围标准化。</p>
</blockquote>
<h2 id="对象追踪"><a href="#对象追踪" class="headerlink" title="对象追踪"></a>对象追踪</h2><p>现在我们知道了如何将BGR图像转换为HSV，我们可以使用它来提取彩色对象。在HSV中，表示颜色比在BGR颜色空间中更容易。在我们的应用程序中，我们将尝试提取一个蓝色的对象。所以这是方法：</p>
<ul>
<li>拍摄视频的每一帧</li>
<li>从BGR转换为HSV颜色空间</li>
<li>我们将HSV图片的阈值范围设为蓝色</li>
<li>现在，仅提取蓝色对象，我们就可以在所需图像上执行任何操作。<br>以下是详细注释的代码：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">cap = cv.VideoCapture(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>):</span><br><span class="line">    _,frame = cap.read()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Convert BGR to HSV</span></span><br><span class="line">    hsv = cv.cvtColor(frame,cv.COLOR_BGR2HSV)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># define range of blue color in HSV</span></span><br><span class="line">    lower_blue = np.array([<span class="number">110</span>,<span class="number">50</span>,<span class="number">50</span>])</span><br><span class="line">    upper_blue = np.array([<span class="number">130</span>,<span class="number">255</span>,<span class="number">255</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Threshold the HSV image to get only blue colors</span></span><br><span class="line">    mask = cv.inRange(hsv,lower_blue,upper_blue)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Bitwise-AND mask and original image</span></span><br><span class="line">    res = cv.bitwise_and(frame,frame,mask=mask)</span><br><span class="line">    </span><br><span class="line">    cv.imshow(<span class="string">'frame'</span>,frame)</span><br><span class="line">    cv.imshow(<span class="string">'mask'</span>,mask)</span><br><span class="line">    cv.imshow(<span class="string">'res'</span>,res)</span><br><span class="line">    </span><br><span class="line">    k = cv.waitKey(<span class="number">5</span>) &amp; <span class="number">0xFF</span></span><br><span class="line">    <span class="keyword">if</span> k == <span class="number">27</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<p>显示如下：<br><img src="/images/hsv.PNG" alt></p>
<blockquote>
<p>注意:图像中有一些噪点。我们将在后面的章节中看到如何删除它们。<br>这是对象跟踪中最简单的方法。一旦学习了轮廓功能，您就可以做很多事情，例如找到该对象的质心并使用它来跟踪该对象，仅通过将手移到相机前面以及其他许多有趣的东西就可以绘制图表。</p>
</blockquote>
<h2 id="如何找到要追踪的HSV值？"><a href="#如何找到要追踪的HSV值？" class="headerlink" title="如何找到要追踪的HSV值？"></a>如何找到要追踪的HSV值？</h2><p>这是在<code>stackoverflow.com</code>中发现的常见问题。这非常简单，您可以使用相同的函数<code>cv.cvtColor()</code>。无需传递图像，只需传递所需的BGR值即可。例如，要查找Green的HSV值，请在Python终端中尝试以下命令：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">green = np.uint8([[[<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>]]])</span><br><span class="line">hsv_green = cv.cvtColor(green,cv.COLOR_BGR2HSV)</span><br><span class="line">print(hsv_green)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[[ 60 255 255]]]</span><br></pre></td></tr></table></figure>

<h1 id="图像的几何变换"><a href="#图像的几何变换" class="headerlink" title="图像的几何变换"></a>图像的几何变换</h1><h2 id="目标-1"><a href="#目标-1" class="headerlink" title="目标"></a>目标</h2><ul>
<li><p>学习将不同的几何变换应用于图像，例如平移，旋转，仿射变换等。</p>
</li>
<li><p>您将看到以下功能：<code>cv.getPerspectiveTransform</code></p>
</li>
</ul>
<h2 id="转换"><a href="#转换" class="headerlink" title="转换"></a>转换</h2><p>OpenCV提供了两个转换函数<code>cv.warpAffine</code>和<code>cv.warpPerspective</code>，您可以使用它们进行各种转换。<code>cv.warpAffine</code>采用2x3转换矩阵，而<code>cv.warpPerspective</code>采用3x3转换矩阵作为输入。</p>
<h2 id="缩放"><a href="#缩放" class="headerlink" title="缩放"></a>缩放</h2><p>缩放只是调整图像的大小。为此，OpenCV带有一个函数<code>cv.resize()</code>。图像的大小可以手动指定，也可以指定缩放比例。使用了不同的插值方法。首选插值方法是<code>cv.INTER_AREA</code>用于缩小，<code>cv.INTER_CUBIC（slow）</code>和<code>cv.INTER_LINEAR</code>用于缩放。默认情况下，出于所有调整大小的目的，使用的插值方法为<code>cv.INTER_LINEAR</code>。您可以使用以下方法之一调整输入图像的大小：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">'lena.jpg'</span>)</span><br><span class="line">res = cv.resize(img,<span class="literal">None</span>,fx=<span class="number">2</span>, fy=<span class="number">2</span>, interpolation = cv.INTER_CUBIC)</span><br><span class="line"><span class="comment">#OR</span></span><br><span class="line">height, width = img.shape[:<span class="number">2</span>]</span><br><span class="line">res = cv.resize(img,(<span class="number">2</span>*width, <span class="number">2</span>*height), interpolation = cv.INTER_CUBIC)</span><br><span class="line"></span><br><span class="line">cv.imshow(<span class="string">'resize'</span>,res)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<h2 id="平移"><a href="#平移" class="headerlink" title="平移"></a>平移</h2><p>平移是物体位置的移动<br>您可以将其放入np.float32类型的Numpy数组中，并将其传递给<code>cv.warpAffine</code>函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">'lena.jpg'</span>,<span class="number">0</span>) <span class="comment"># 改成1会报错</span></span><br><span class="line">rows,cols = img.shape</span><br><span class="line">M = np.float32([[<span class="number">1</span>,<span class="number">0</span>,<span class="number">100</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>]])</span><br><span class="line">dst = cv.warpAffine(img,M,(cols,rows))</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,dst)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<h2 id="旋转"><a href="#旋转" class="headerlink" title="旋转"></a>旋转</h2><p>OpenCV提供了可缩放的旋转以及可调整的旋转中心，因此您可以在自己喜欢的任何位置旋转。<br>为了找到此转换矩阵，OpenCV提供了一个函数<code>cv.getRotationMatrix2D</code>。请检查以下示例，该示例将图像相对于中心旋转90度而没有任何缩放比例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(<span class="string">'lena.jpg'</span>,<span class="number">0</span>) <span class="comment"># 还是不能改成1</span></span><br><span class="line">rows,cols = img.shape</span><br><span class="line"><span class="comment"># cols-1 and rows-1 are the coordinate limits.</span></span><br><span class="line">M = cv.getRotationMatrix2D(((cols<span class="number">-1</span>)/<span class="number">2.0</span>,(rows<span class="number">-1</span>)/<span class="number">2.0</span>),<span class="number">90</span>,<span class="number">1</span>)</span><br><span class="line">dst = cv.warpAffine(img,M,(cols,rows))</span><br><span class="line"></span><br><span class="line">cv.imshow(<span class="string">'rotation'</span>,dst)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<h2 id="仿射变换"><a href="#仿射变换" class="headerlink" title="仿射变换"></a>仿射变换</h2><p>在仿射变换中，原始图像中的所有平行线在输出图像中仍将平行。为了找到变换矩阵，我们需要输入图像中的三个点及其在输出图像中的对应位置。然后<code>cv.getAffineTransform</code>将创建一个2x3矩阵，该矩阵将传递给<code>cv.warpAffine</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = cv.imread(<span class="string">'lena.jpg'</span>)</span><br><span class="line">rows,cols,ch = img.shape</span><br><span class="line">pts1 = np.float32([[<span class="number">50</span>,<span class="number">50</span>],[<span class="number">200</span>,<span class="number">50</span>],[<span class="number">50</span>,<span class="number">200</span>]])</span><br><span class="line">pts2 = np.float32([[<span class="number">10</span>,<span class="number">100</span>],[<span class="number">200</span>,<span class="number">50</span>],[<span class="number">100</span>,<span class="number">250</span>]])</span><br><span class="line">M = cv.getAffineTransform(pts1,pts2)</span><br><span class="line">dst = cv.warpAffine(img,M,(cols,rows))</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img),plt.title(<span class="string">'Input'</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(dst),plt.title(<span class="string">'Output'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/output_7_0.png" alt="png"></p>
<h2 id="透视变换"><a href="#透视变换" class="headerlink" title="透视变换"></a>透视变换</h2><p>对于透视变换，您需要3x3变换矩阵。即使在转换后，直线也将保持直线。要找到此变换矩阵，您需要在输入图像上有4个点，在输出图像上需要相应的点。在这四个点中，其中三个不应共线。然后可以通过函数<code>cv.getPerspectiveTransform</code>找到变换矩阵。然后将<code>cv.warpPerspective</code>应用于此3x3转换矩阵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(<span class="string">'lena.jpg'</span>)</span><br><span class="line">rows,cols,ch = img.shape</span><br><span class="line">pts1 = np.float32([[<span class="number">56</span>,<span class="number">65</span>],[<span class="number">368</span>,<span class="number">52</span>],[<span class="number">28</span>,<span class="number">387</span>],[<span class="number">389</span>,<span class="number">390</span>]])</span><br><span class="line">pts2 = np.float32([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">300</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">300</span>],[<span class="number">300</span>,<span class="number">300</span>]])</span><br><span class="line">M = cv.getPerspectiveTransform(pts1,pts2)</span><br><span class="line">dst = cv.warpPerspective(img,M,(<span class="number">300</span>,<span class="number">300</span>))</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img),plt.title(<span class="string">'Input'</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(dst),plt.title(<span class="string">'Output'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/output_9_0.png" alt="png"></p>
<h1 id="图像阈值"><a href="#图像阈值" class="headerlink" title="图像阈值"></a>图像阈值</h1><h2 id="目标-2"><a href="#目标-2" class="headerlink" title="目标"></a>目标</h2><ul>
<li>在本教程中，您将学习简单阈值，自适应阈值和Otsu的阈值。</li>
<li>您将学习函数<code>cv.threshold</code>和<code>cv.adaptiveThreshold</code>。</li>
</ul>
<h2 id="简单阈值"><a href="#简单阈值" class="headerlink" title="简单阈值"></a>简单阈值</h2><p>在这里，问题直截了当。对于每个像素，应用相同的阈值。如果像素值小于阈值，则将其设置为0，否则将其设置为最大值。函数<code>cv.threshold</code>用于应用阈值。第一个参数是源图像，它应该是灰度图像。第二个参数是阈值，用于对像素值进行分类。第三个参数是分配给超过阈值的像素值的最大值。OpenCV提供了不同类型的阈值，这由函数的第四个参数给出。通过使用类型<code>cv.THRESH_BINARY</code>完成上述基本阈值处理。所有简单的阈值类型为：</p>
<ul>
<li>cv.THRESH_BINARY</li>
<li>cv.THRESH_BINARY_INV</li>
<li>cv.THRESH_TRUNC</li>
<li>cv.THRESH_TOZERO</li>
<li>cv.THRESH_TOZERO_INV<br>有关差异，请参见类型的文档。</li>
</ul>
<p>该方法返回两个输出。第一个是使用的阈值，第二个输出是阈值图像。</p>
<p>此代码比较了不同的简单阈值类型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'lena.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">ret,thresh1 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_BINARY)</span><br><span class="line">ret,thresh2 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_BINARY_INV)</span><br><span class="line">ret,thresh3 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_TRUNC)</span><br><span class="line">ret,thresh4 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_TOZERO)</span><br><span class="line">ret,thresh5 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_TOZERO_INV)</span><br><span class="line">titles = [<span class="string">'Original Image'</span>,<span class="string">'BINARY'</span>,<span class="string">'BINARY_INV'</span>,<span class="string">'TRUNC'</span>,<span class="string">'TOZERO'</span>,<span class="string">'TOZERO_INV'</span>]</span><br><span class="line">images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>),plt.imshow(images[i],<span class="string">'gray'</span>)</span><br><span class="line">    plt.title(titles[i])</span><br><span class="line">    plt.xticks([]),plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/output_1_0.png" alt="png"></p>
<h2 id="自适应阈值"><a href="#自适应阈值" class="headerlink" title="自适应阈值"></a>自适应阈值</h2><p>在上一节中，我们使用一个全局值作为阈值。但这可能并非在所有情况下都很好，例如，如果图像在不同区域具有不同的照明条件。在这种情况下，自适应阈值阈值化可以提供帮助。在此，算法基于像素周围的小区域确定像素的阈值。因此，对于同一图像的不同区域，我们获得了不同的阈值，这为光照度变化的图像提供了更好的结果。</p>
<p>除上述参数外，方法<code>cv.adaptiveThreshold</code>还包含三个输入参数：</p>
<p>该<code>adaptiveMethod</code>决定阈值是如何计算的：</p>
<p><code>cv.ADAPTIVE_THRESH_MEAN_C</code>：该阈值是该附近区域减去恒定的平均Ç。<br><code>cv.ADAPTIVE_THRESH_GAUSSIAN_C</code>：阈值是邻域值减去常数C的高斯加权和。<br>该<code>BLOCKSIZE</code>确定附近区域的大小和Ç是从平均值或附近的像素的加权和中减去一个常数。</p>
<p>下面的代码比较了光照变化的图像的全局阈值和自适应阈值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'lena.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">img = cv.medianBlur(img,<span class="number">5</span>)</span><br><span class="line">ret,th1 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_BINARY)</span><br><span class="line">th2 = cv.adaptiveThreshold(img,<span class="number">255</span>,cv.ADAPTIVE_THRESH_MEAN_C,\</span><br><span class="line">            cv.THRESH_BINARY,<span class="number">11</span>,<span class="number">2</span>)</span><br><span class="line">th3 = cv.adaptiveThreshold(img,<span class="number">255</span>,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\</span><br><span class="line">            cv.THRESH_BINARY,<span class="number">11</span>,<span class="number">2</span>)</span><br><span class="line">titles = [<span class="string">'Original Image'</span>, <span class="string">'Global Thresholding (v = 127)'</span>,</span><br><span class="line">            <span class="string">'Adaptive Mean Thresholding'</span>, <span class="string">'Adaptive Gaussian Thresholding'</span>]</span><br><span class="line">images = [img, th1, th2, th3]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">2</span>,i+<span class="number">1</span>),plt.imshow(images[i],<span class="string">'gray'</span>)</span><br><span class="line">    plt.title(titles[i])</span><br><span class="line">    plt.xticks([]),plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/output_3_0.png" alt="png"></p>
<h2 id="Otsu’s-Binarization"><a href="#Otsu’s-Binarization" class="headerlink" title="Otsu’s Binarization"></a>Otsu’s Binarization</h2><p>在全局阈值化中，我们使用任意选择的值作为阈值。相反，Otsu的方法避免了必须选择一个值并自动确定它的情况。</p>
<p>考虑仅具有两个不同图像值的图像（双峰图像），其中直方图将仅包含两个峰。一个好的阈值应该在这两个值的中间。类似地，Otsu的方法从图像直方图中确定最佳全局阈值。</p>
<p>为此，使用了<code>cv.threshold()</code>函数，其中<code>cv.THRESH_OTSU</code>作为附加标志传递。阈值可以任意选择。然后，算法找到最佳阈值，该阈值作为第一输出返回。</p>
<p>查看以下示例。输入图像为噪点图像。在第一种情况下，将应用值127的全局阈值。在第二种情况下，将直接应用Otsu的阈值。在第三种情况下，首先使用5x5高斯核对图像进行滤波以去除噪声，然后应用Otsu阈值处理。了解噪声过滤如何改善结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'noisy2.png'</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># global thresholding</span></span><br><span class="line">ret1,th1 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_BINARY)</span><br><span class="line"><span class="comment"># Otsu's thresholding</span></span><br><span class="line">ret2,th2 = cv.threshold(img,<span class="number">0</span>,<span class="number">255</span>,cv.THRESH_BINARY+cv.THRESH_OTSU)</span><br><span class="line"><span class="comment"># Otsu's thresholding after Gaussian filtering</span></span><br><span class="line">blur = cv.GaussianBlur(img,(<span class="number">5</span>,<span class="number">5</span>),<span class="number">0</span>)</span><br><span class="line">ret3,th3 = cv.threshold(blur,<span class="number">0</span>,<span class="number">255</span>,cv.THRESH_BINARY+cv.THRESH_OTSU)</span><br><span class="line"><span class="comment"># plot all the images and their histograms</span></span><br><span class="line">images = [img, <span class="number">0</span>, th1,</span><br><span class="line">          img, <span class="number">0</span>, th2,</span><br><span class="line">          blur, <span class="number">0</span>, th3]</span><br><span class="line">titles = [<span class="string">'Original Noisy Image'</span>,<span class="string">'Histogram'</span>,<span class="string">'Global Thresholding (v=127)'</span>,</span><br><span class="line">          <span class="string">'Original Noisy Image'</span>,<span class="string">'Histogram'</span>,<span class="string">"Otsu's Thresholding"</span>,</span><br><span class="line">          <span class="string">'Gaussian filtered Image'</span>,<span class="string">'Histogram'</span>,<span class="string">"Otsu's Thresholding"</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    plt.subplot(<span class="number">3</span>,<span class="number">3</span>,i*<span class="number">3</span>+<span class="number">1</span>),plt.imshow(images[i*<span class="number">3</span>],<span class="string">'gray'</span>)</span><br><span class="line">    plt.title(titles[i*<span class="number">3</span>]), plt.xticks([]), plt.yticks([])</span><br><span class="line">    plt.subplot(<span class="number">3</span>,<span class="number">3</span>,i*<span class="number">3</span>+<span class="number">2</span>),plt.hist(images[i*<span class="number">3</span>].ravel(),<span class="number">256</span>)</span><br><span class="line">    plt.title(titles[i*<span class="number">3</span>+<span class="number">1</span>]), plt.xticks([]), plt.yticks([])</span><br><span class="line">    plt.subplot(<span class="number">3</span>,<span class="number">3</span>,i*<span class="number">3</span>+<span class="number">3</span>),plt.imshow(images[i*<span class="number">3</span>+<span class="number">2</span>],<span class="string">'gray'</span>)</span><br><span class="line">    plt.title(titles[i*<span class="number">3</span>+<span class="number">2</span>]), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/otsu.jpg" alt></p>
<h1 id="平滑图像"><a href="#平滑图像" class="headerlink" title="平滑图像"></a>平滑图像</h1><h2 id="目标-3"><a href="#目标-3" class="headerlink" title="目标"></a>目标</h2><ul>
<li>使用各种低通滤镜模糊图像</li>
<li>将定制的滤镜应用于图像（2D卷积）</li>
</ul>
<h2 id="2D卷积（图像过滤）"><a href="#2D卷积（图像过滤）" class="headerlink" title="2D卷积（图像过滤）"></a>2D卷积（图像过滤）</h2><p>与一维信号一样，还可以使用各种<strong>低通滤波器（LPF）</strong>，<strong>高通滤波器（HPF）</strong>等对图像进行滤波。LPF有助于消除噪声，使图像模糊等。HPF滤波器有助于在图像中找到边缘。图片。</p>
<p>OpenCV提供了一个函数<code>cv.filter2D()</code>来将内核与映像进行卷积。例如，我们将尝试对图像进行平均滤波。<br>操作如下：将内核保持在一个像素以上，将所有25个像素加到该内核以下，取其平均值，然后用新的平均值替换中心像素。对于图像中的所有像素，它将继续此操作。尝试以下代码并检查结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="comment"># %matplotlib inline</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'original.jpg'</span>)</span><br><span class="line">kernel = np.ones((<span class="number">5</span>,<span class="number">5</span>),np.float32)/<span class="number">25</span></span><br><span class="line">dst = cv.filter2D(img,<span class="number">-1</span>,kernel)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img),plt.title(<span class="string">'Original'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(dst),plt.title(<span class="string">'Averaging'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/filter.jpg" alt></p>
<h2 id="图像模糊（图像平滑）"><a href="#图像模糊（图像平滑）" class="headerlink" title="图像模糊（图像平滑）"></a>图像模糊（图像平滑）</h2><p>通过将图像与低通滤波器内核进行卷积来实现图像模糊。这对于消除噪音很有用。它实际上从图像中删除了高频内容（例如，噪声，边缘）。因此，在此操作中边缘有些模糊。（嗯，有一些模糊技术也不会模糊边缘）。OpenCV主要提供四种类型的模糊技术。</p>
<h3 id="1-平均"><a href="#1-平均" class="headerlink" title="1.平均"></a>1.平均</h3><p>这是通过将图像与归一化框滤镜进行卷积来完成的。它仅获取内核区域下所有像素的平均值，并替换中心元素。这是通过功能<code>cv.blur()</code>或<code>cv.boxFilter()</code>完成的。检查文档以获取有关内核的更多详细信息。</p>
<blockquote>
<p>注意:如果您不想使用标准化的框式过滤器，请使用cv.boxFilter（）。将参数normalize = False传递给函数。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'original.jpg'</span>)</span><br><span class="line">blur = cv.blur(img,(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img),plt.title(<span class="string">'Original'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(blur),plt.title(<span class="string">'Blurred'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/blur.jpg" alt></p>
<h3 id="2-高斯模糊"><a href="#2-高斯模糊" class="headerlink" title="2.高斯模糊"></a>2.高斯模糊</h3><p>在这种情况下，代替盒式滤波器，使用了高斯核。这是通过功能<code>cv.GaussianBlur()</code>完成的。我们应指定内核的宽度和高度，该宽度和高度应为正数和奇数。我们还应指定X和Y方向的标准偏差，分别为sigmaX和sigmaY。如果仅指定sigmaX，则将sigmaY与sigmaX相同。如果两个都为零，则根据内核大小进行计算。高斯模糊对于从图像中去除高斯噪声非常有效。</p>
<p>如果需要，可以使用函数<code>cv.getGaussianKernel()</code>创建高斯内核。</p>
<p>可以针对高斯模糊修改以上代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blur = cv.GaussianBlur（img，（<span class="number">5</span>,<span class="number">5</span>），<span class="number">0</span>）</span><br></pre></td></tr></table></figure>

<p><img src="/images/gaussian.jpg" alt></p>
<h3 id="3-中位模糊"><a href="#3-中位模糊" class="headerlink" title="3.中位模糊"></a>3.中位模糊</h3><p>在这里，函数<code>cv.medianBlur()</code>提取内核区域下所有像素的中值，并将中心元素替换为该中值。这对于消除图像中的椒盐噪声非常有效。有趣的是，在上述过滤器中，中心元素是新计算的值，该值可以是图像中的像素值或新值。但是在中值模糊中，中心元素总是被图像中的某些像素值代替。有效降低噪音。其内核大小应为正奇数整数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">median = cv.medianBlur(img,<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/images/median.jpg" alt></p>
<h3 id="4-双边过滤"><a href="#4-双边过滤" class="headerlink" title="4.双边过滤"></a>4.双边过滤</h3><p><code>cv.bilateralFilter()</code>在去除噪声的同时保持边缘清晰锐利非常有效。但是，与其他过滤器相比，该操作速度较慢。我们已经看到，高斯滤波器采用像素周围的邻域并找到其高斯加权平均值。高斯滤波器仅是空间的函数，也就是说，滤波时会考虑附近的像素。它不考虑像素是否具有几乎相同的强度。它不考虑像素是否是边缘像素。因此它也模糊了边缘，这是我们不想做的。</p>
<p>双边滤波器在空间中也采用高斯滤波器，但是又有一个高斯滤波器，它是像素差的函数。空间的高斯函数确保仅考虑附近像素的模糊，而强度差的高斯函数确保仅考虑强度与中心像素相似的像素的模糊。由于边缘的像素强度变化较大，因此可以保留边缘。</p>
<p>以下示例显示了使用双边过滤器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blur = cv.bilateralFilter(img,<span class="number">9</span>,<span class="number">75</span>,<span class="number">75</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/images/bilateral.jpg" alt></p>
<h1 id="形态转换"><a href="#形态转换" class="headerlink" title="形态转换"></a>形态转换</h1><h2 id="目标-4"><a href="#目标-4" class="headerlink" title="目标"></a>目标</h2><ul>
<li>我们将学习不同的形态学操作，例如侵蚀，膨胀，打开，关闭等。</li>
<li>我们将看到不同的功能，例如：<code>cv.erode()</code>，<code>cv.dilate()</code>，<code>cv.morphologyEx()</code>等。</li>
</ul>
<h2 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h2><p>形态变换是基于图像形状的一些简单操作。通常在二进制图像上执行。它需要两个输入，一个是我们的原始图像，第二个是决定操作性质的结构元素或内核。两种基本的形态学算子是侵蚀和膨胀。然后，它的变体形式（如“打开”，“关闭”，“渐变”等）也开始起作用。在下图的帮助下，我们将一一看到它们：</p>
<p><img src="/images/j.png" alt></p>
<h2 id="1-侵蚀"><a href="#1-侵蚀" class="headerlink" title="1.侵蚀"></a>1.侵蚀</h2><p>侵蚀的基本思想就像仅是土壤侵蚀一样，它侵蚀了前景物体的边界（始终尝试使前景保持白色）。那是什么呢？内核在图像中滑动（如2D卷积）。仅当内核下的所有像素均为1时，原始图像中的像素（1或0）才被视为1，否则它将被侵蚀（设为零）。</p>
<p>因此发生的是，将根据内核的大小丢弃边界附近的所有像素。因此，前景对象的厚度或大小会减小，或者图像中的白色区域只会减小。这对于消除小的白噪声（如我们在色彩空间一章中看到的），分离两个连接的对象等非常有用。</p>
<p>在这里，作为一个例子，我将使用一个全是5x5的内核。让我们看看它是如何工作的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img = cv.imread(<span class="string">'j.png'</span>,<span class="number">0</span>)</span><br><span class="line">kernel = np.ones((<span class="number">5</span>,<span class="number">5</span>),np.uint8)</span><br><span class="line">erosion = cv.erode(img,kernel,iterations = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">cv.imshow(<span class="string">'k'</span>,erosion)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<p><img src="/images/erosion.png" alt></p>
<h2 id="2-膨胀"><a href="#2-膨胀" class="headerlink" title="2.膨胀"></a>2.膨胀</h2><p>它与侵蚀正好相反。如果内核下的至少一个像素为“ 1”，则像素元素为“ 1”。因此，它会增加图像中的白色区域或增加前景对象的大小。通常，在消除噪音的情况下，腐蚀后会膨胀。因为腐蚀会消除白噪声，但也会缩小物体。因此，我们对其进行了扩展。由于噪音消失了，它们不会回来，但是我们的目标区域增加了。在连接对象的损坏部分时也很有用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dilation = cv.dilate(img,kernel,iterations = <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/images/dilation.png" alt></p>
<h2 id="3-开运算"><a href="#3-开运算" class="headerlink" title="3.开运算"></a>3.开运算</h2><p>开运算只是侵蚀然后膨胀的另一个名称。如上文所述，它对于消除噪音很有用。这里我们使用函数<code>cv.morphologyEx()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">opening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)</span><br></pre></td></tr></table></figure>

<p><img src="/images/opening.png" alt></p>
<h2 id="4-闭运算"><a href="#4-闭运算" class="headerlink" title="4.闭运算"></a>4.闭运算</h2><p>关闭与打开，膨胀接着是侵蚀相反。在闭运算前景对象内部的小孔或对象上的小黑点时很有用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">closing = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)</span><br></pre></td></tr></table></figure>

<p><img src="/images/closing.png" alt></p>
<h2 id="5-形态梯度"><a href="#5-形态梯度" class="headerlink" title="5.形态梯度"></a>5.形态梯度</h2><p>这是图像的膨胀和腐蚀之间的区别。</p>
<p>结果将看起来像对象的轮廓。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gradient = cv.morphologyEx(img, cv.MORPH_GRADIENT, kernel)</span><br></pre></td></tr></table></figure>

<p><img src="/images/gradient.png" alt></p>
<h2 id="6-高帽"><a href="#6-高帽" class="headerlink" title="6.高帽"></a>6.高帽</h2><p>这是输入图像和图像打开之间的区别。下面的示例针对9x9内核完成。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tophat = cv.morphologyEx(img, cv.MORPH_TOPHAT, kernel)</span><br></pre></td></tr></table></figure>

<p><img src="/images/tophat.png" alt></p>
<h2 id="7-黑帽"><a href="#7-黑帽" class="headerlink" title="7.黑帽"></a>7.黑帽</h2><p>这是输入图像和输入图像关闭之间的差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blackhat = cv.morphologyEx(img, cv.MORPH_BLACKHAT, kernel)</span><br></pre></td></tr></table></figure>

<p><img src="/images/blackhat.png" alt></p>
<h2 id="结构元素"><a href="#结构元素" class="headerlink" title="结构元素"></a>结构元素</h2><p>在Numpy的帮助下，我们在前面的示例中手动创建了一个结构元素。它是矩形。但是在某些情况下，您可能需要椭圆形/圆形的内核。因此，为此，OpenCV具有一个函数<code>cv.getStructuringElement()</code>。您只需传递内核的形状和大小，即可获得所需的内核。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Rectangular Kernel</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cv.getStructuringElement(cv.MORPH_RECT,(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]], dtype=uint8)</span><br><span class="line"><span class="comment"># Elliptical Kernel</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cv.getStructuringElement(cv.MORPH_ELLIPSE,(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]], dtype=uint8)</span><br><span class="line"><span class="comment"># Cross-shaped Kernel</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cv.getStructuringElement(cv.MORPH_CROSS,(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]], dtype=uint8)</span><br></pre></td></tr></table></figure>

<h1 id="图像渐变"><a href="#图像渐变" class="headerlink" title="图像渐变"></a>图像渐变</h1><h2 id="目标-5"><a href="#目标-5" class="headerlink" title="目标"></a>目标</h2><ul>
<li>查找图像渐变，边缘等</li>
<li>我们将看到以下函数：<code>cv.Sobel()</code>，<code>cv.Scharr()</code>，<code>cv.Laplacian()</code>等</li>
</ul>
<h2 id="理论-1"><a href="#理论-1" class="headerlink" title="理论"></a>理论</h2><p>OpenCV提供了三种类型的梯度滤波器或高通滤波器，即<code>Sobel</code>，<code>Scharr</code>和<code>Laplacian</code>。</p>
<p>Sobel算子是高斯平滑加微分运算的联合运算，因此它更抗噪声。您可以指定要采用的导数方向，垂直或水平（分别通过参数yorder和xorder）。您还可以通过参数ksize指定内核的大小。如果ksize = -1，则使用3x3 Scharr滤波器，其效果要比3x3 Sobel滤波器更好。请参阅文档以了解所使用的内核。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'dave.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">laplacian = cv.Laplacian(img,cv.CV_64F)</span><br><span class="line">sobelx = cv.Sobel(img,cv.CV_64F,<span class="number">1</span>,<span class="number">0</span>,ksize=<span class="number">5</span>)</span><br><span class="line">sobely = cv.Sobel(img,cv.CV_64F,<span class="number">0</span>,<span class="number">1</span>,ksize=<span class="number">5</span>)</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>),plt.imshow(img,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Original'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>),plt.imshow(laplacian,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Laplacian'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>),plt.imshow(sobelx,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Sobel X'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>),plt.imshow(sobely,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Sobel Y'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/gradients.jpg" alt></p>
<h2 id="一个重要的事情！"><a href="#一个重要的事情！" class="headerlink" title="一个重要的事情！"></a>一个重要的事情！</h2><p>在我们的最后一个示例中，输出数据类型为cv.CV_8U或np.uint8。但这有一个小问题。黑色到白色的过渡被视为正斜率（具有正值），而白色到黑色的过渡被视为负斜率（具有负值）。因此，当您将数据转换为np.uint8时，所有负斜率均设为零。<br>如果要检测两个边缘，更好的选择是将输出数据类型保留为更高的形式，例如cv.CV_16S，cv.CV_64F等，取其绝对值，然后转换回cv.CV_8U。下面的代码演示了水平Sobel滤波器的处理过程以及结果的差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'box.png'</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># Output dtype = cv.CV_8U</span></span><br><span class="line">sobelx8u = cv.Sobel(img,cv.CV_8U,<span class="number">1</span>,<span class="number">0</span>,ksize=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># Output dtype = cv.CV_64F. Then take its absolute and convert to cv.CV_8U</span></span><br><span class="line">sobelx64f = cv.Sobel(img,cv.CV_64F,<span class="number">1</span>,<span class="number">0</span>,ksize=<span class="number">5</span>)</span><br><span class="line">abs_sobel64f = np.absolute(sobelx64f)</span><br><span class="line">sobel_8u = np.uint8(abs_sobel64f)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>),plt.imshow(img,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Original'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>),plt.imshow(sobelx8u,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Sobel CV_8U'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>),plt.imshow(sobel_8u,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Sobel abs(CV_64F)'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/double_edge.jpg" alt></p>
<h1 id="Canny边缘检测"><a href="#Canny边缘检测" class="headerlink" title="Canny边缘检测"></a>Canny边缘检测</h1><h2 id="目标-6"><a href="#目标-6" class="headerlink" title="目标"></a>目标</h2><ul>
<li>边缘检测的概念</li>
<li>OpenCV函数：<code>cv.Canny（）</code></li>
</ul>
<h2 id="理论-2"><a href="#理论-2" class="headerlink" title="理论"></a>理论</h2><p>Canny Edge Detection是一种流行的边缘检测算法。</p>
<p>1.这是一个多阶段算法，我们将经历每个阶段。<br>2.<strong>降噪</strong>由于边缘检测容易受到图像中噪声的影响，因此第一步是使用5x5高斯滤波器消除图像中的噪声。我们已经在前面的章节中看到了这一点。<br>3.<strong>查找图像的强度梯度</strong>然后使用Sobel核在水平和垂直方向上对平滑的图像进行滤波，以在水平方向()和垂直方向()上获得一阶导数。从这两个图像中，我们可以找到每个像素的边缘渐变和方向，渐变方向始终垂直于边缘。将其舍入为代表垂直，水平和两个对角线方向的四个角度之一<br>4.<strong>非最大抑制</strong>在获得梯度大小和方向后，将对图像进行全面扫描，以去除可能不构成边缘的所有不需要的像素。为此，在每个像素处，检查像素是否是其在梯度方向上附近的局部最大值。查看下面的图片：</p>
<p><img src="/images/nms.jpg" alt></p>
<p>点A在边缘（垂直方向）上。渐变方向垂直于边缘。点B和C在梯度方向上。因此，将A点与B点和C点进行检查，看是否形成局部最大值。如果是这样，则考虑将其用于下一阶段，否则将其抑制（置为零）。</p>
<p>简而言之，您得到的结果是带有“细边”的二进制图像。</p>
<p><strong>5.磁滞阈值</strong></p>
<p>该阶段确定哪些边缘全部是真正的边缘，哪些不是。为此，我们需要两个阈值minVal和maxVal。强度梯度大于maxVal的任何边缘必定是边缘，而小于minVal的那些强度必定是非边缘，因此将其丢弃。介于这两个阈值之间的对象根据其连通性被分类为边缘或非边缘。如果它们连接到“保证边缘”像素，则将它们视为边缘的一部分。否则，它们也将被丢弃。见下图：</p>
<p><img src="/images/hysteresis.jpg" alt></p>
<p>边缘A在maxVal之上，因此被视为“确定边缘”。尽管边C低于maxVal，但它连接到边A，因此也被视为有效边，我们得到了完整的曲线。但是边缘B尽管在minVal之上并且与边缘C处于同一区域，但是它没有连接到任何“确保边缘”，因此被丢弃。因此，非常重要的一点是我们必须相应地选择minVal和maxVal以获得正确的结果。</p>
<p>在边缘为长线的假设下，该阶段还消除了小像素噪声。</p>
<p>因此，我们最终得到的是图像中的强边缘。</p>
<h2 id="OpenCV中的Canny-Edge检测"><a href="#OpenCV中的Canny-Edge检测" class="headerlink" title="OpenCV中的Canny Edge检测"></a>OpenCV中的Canny Edge检测</h2><p>OpenCV将以上所有内容放在单个函数<code>cv.Canny()</code>中。我们将看到如何使用它。第一个参数是我们的输入图像。第二个和第三个参数分别是我们的<code>minVal</code>和<code>maxVal</code>。第三个参数是<code>perture_size</code>。它是用于查找图像渐变的Sobel内核的大小。默认情况下为3。最后一个参数是<code>L2gradient</code>，它指定用于查找梯度幅度的方程式。如果为True，则使用上面提到的更精确的方程式,否则使用下面的方程式：Edge_Gradient(G)=|Gx|+|Gy|，默认是Flase</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'lena.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">edges = cv.Canny(img,<span class="number">100</span>,<span class="number">200</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Original Image'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(edges,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Edge Image'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/output_6_0.png" alt="png"></p>
<h1 id="图像金字塔"><a href="#图像金字塔" class="headerlink" title="图像金字塔"></a>图像金字塔</h1><h2 id="目标-7"><a href="#目标-7" class="headerlink" title="目标"></a>目标</h2><ul>
<li>我们将学习图像金字塔</li>
<li>我们将使用图像金字塔创建一个新的水果“ Orapple”</li>
<li>我们将看到以下功能：<code>cv.pyrUp（）</code>，<code>cv.pyrDown（）</code></li>
</ul>
<h2 id="理论-3"><a href="#理论-3" class="headerlink" title="理论"></a>理论</h2><p>通常，我们过去使用的是恒定大小的图像。但是在某些情况下，我们需要使用不同分辨率的（相同）图像。例如，当在图像中搜索诸如面部之类的东西时，我们不确定对象将以何种大小出现在所述图像中。在这种情况下，我们将需要创建一组具有不同分辨率的相同图像，并在所有图像中搜索对象。这些具有不同分辨率的图像集称为“ 图像金字塔”（因为当它们堆叠在底部时，最高分辨率的图像位于顶部，最低分辨率的图像位于顶部时，看起来像金字塔）。</p>
<p>有两种图像金字塔。<strong>1）高斯金字塔</strong>和<strong>2）拉普拉斯金字塔</strong></p>
<p>高斯金字塔中的较高级别（低分辨率）是通过删除较低级别（较高分辨率）图像中的连续行和列而形成的。然后，较高级别的每个像素由基础级别的5个像素的贡献与高斯权重形成。这样，图像变成图像。因此面积减少到原始面积的四分之一。它称为八度。当我们在金字塔中越靠上时（即分辨率降低），这种模式就会继续。同样，在扩展时，每个级别的面积变为4倍。我们可以使用<code>cv.pyrDown()</code>和<code>cv.pyrUp()</code>函数找到高斯金字塔。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread（<span class="string">'messi5.jpg'</span>）</span><br><span class="line">lower_reso = cv.pyrDown（higher_reso）</span><br></pre></td></tr></table></figure>

<p>以下是图像金字塔中的4个级别。</p>
<p><img src="/images/messipyr.jpg" alt></p>
<p>现在，您可以使用<code>cv.pyrUp()</code>函数查看图像金字塔。</p>
<p>upper_reso2 = cv.pyrUp（lower_reso）</p>
<p>请记住，<code>higher_reso2</code>不等于<code>higher_reso</code>，因为一旦降低分辨率，便会丢失信息。图像下方是在以前情况下从最小图像创建的金字塔下3级。将其与原始图像进行比较：</p>
<p><img src="/images/messiup.jpg" alt></p>
<p>拉普拉斯金字塔由高斯金字塔形成。没有专用功能。拉普拉斯金字塔图像仅像边缘图像。它的大部分元素为零。它们用于图像压缩。拉普拉斯金字塔的层由高斯金字塔的层与高斯金字塔的上层的扩展版本之间的差形成。拉普拉斯水平的三个水平如下所示（调整了对比度以增强内容）：</p>
<p><img src="/images/lap.jpg" alt></p>
<h2 id="使用金字塔进行图像融合"><a href="#使用金字塔进行图像融合" class="headerlink" title="使用金字塔进行图像融合"></a>使用金字塔进行图像融合</h2><p>金字塔的一种应用是图像融合。例如，在图像拼接中，您需要将两个图像堆叠在一起，但是由于图像之间的不连续性，可能看起来不太好。在这种情况下，使用金字塔混合图像可以无缝混合，而不会在图像中保留大量数据。一个经典的例子是将两种水果，橙和苹果混合在一起。现在查看结果本身，以了解我在说什么：</p>
<p><img src="/images/orapple.jpg" alt></p>
<p>请检查其他资源中的第一个参考，它具有图像混合，拉普拉斯金字塔等的完整图解详细信息。只需完成以下步骤即可：</p>
<ul>
<li>加载苹果和橙子的两个图像</li>
<li>查找苹果和橙子的高斯金字塔（在此示例中，级别数为6）</li>
<li>从高斯金字塔中找到他们的拉普拉斯金字塔</li>
<li>现在在每个拉普拉斯金字塔中加入苹果的左半部分和橙的右半部分</li>
<li>最后，从此联合图像金字塔中重建原始图像。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里用的是xrange，注意更改</span></span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np,sys</span><br><span class="line">A = cv.imread(<span class="string">'apple.jpg'</span>)</span><br><span class="line">B = cv.imread(<span class="string">'orange.jpg'</span>)</span><br><span class="line"><span class="comment"># generate Gaussian pyramid for A</span></span><br><span class="line">G = A.copy()</span><br><span class="line">gpA = [G]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">6</span>):</span><br><span class="line">    G = cv.pyrDown(G)</span><br><span class="line">    gpA.append(G)</span><br><span class="line"><span class="comment"># generate Gaussian pyramid for B</span></span><br><span class="line">G = B.copy()</span><br><span class="line">gpB = [G]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">6</span>):</span><br><span class="line">    G = cv.pyrDown(G)</span><br><span class="line">    gpB.append(G)</span><br><span class="line"><span class="comment"># generate Laplacian Pyramid for A</span></span><br><span class="line">lpA = [gpA[<span class="number">5</span>]]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">5</span>,<span class="number">0</span>,<span class="number">-1</span>):</span><br><span class="line">    GE = cv.pyrUp(gpA[i])</span><br><span class="line">    L = cv.subtract(gpA[i<span class="number">-1</span>],GE)</span><br><span class="line">    lpA.append(L)</span><br><span class="line"><span class="comment"># generate Laplacian Pyramid for B</span></span><br><span class="line">lpB = [gpB[<span class="number">5</span>]]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">5</span>,<span class="number">0</span>,<span class="number">-1</span>):</span><br><span class="line">    GE = cv.pyrUp(gpB[i])</span><br><span class="line">    L = cv.subtract(gpB[i<span class="number">-1</span>],GE)</span><br><span class="line">    lpB.append(L)</span><br><span class="line"><span class="comment"># Now add left and right halves of images in each level</span></span><br><span class="line">LS = []</span><br><span class="line"><span class="keyword">for</span> la,lb <span class="keyword">in</span> zip(lpA,lpB):</span><br><span class="line">    rows,cols,dpt = la.shape</span><br><span class="line">    ls = np.hstack((la[:,<span class="number">0</span>:cols/<span class="number">2</span>], lb[:,cols/<span class="number">2</span>:]))</span><br><span class="line">    LS.append(ls)</span><br><span class="line"><span class="comment"># now reconstruct</span></span><br><span class="line">ls_ = LS[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1</span>,<span class="number">6</span>):</span><br><span class="line">    ls_ = cv.pyrUp(ls_)</span><br><span class="line">    ls_ = cv.add(ls_, LS[i])</span><br><span class="line"><span class="comment"># image with direct connecting each half</span></span><br><span class="line">real = np.hstack((A[:,:cols/<span class="number">2</span>],B[:,cols/<span class="number">2</span>:]))</span><br><span class="line">cv.imwrite(<span class="string">'Pyramid_blending2.jpg'</span>,ls_)</span><br><span class="line">cv.imwrite(<span class="string">'Direct_blending.jpg'</span>,real)</span><br></pre></td></tr></table></figure>

<h1 id="OpenCV中的轮廓"><a href="#OpenCV中的轮廓" class="headerlink" title="OpenCV中的轮廓"></a>OpenCV中的轮廓</h1><h2 id="轮廓：入门"><a href="#轮廓：入门" class="headerlink" title="轮廓：入门"></a>轮廓：入门</h2><h3 id="目标-8"><a href="#目标-8" class="headerlink" title="目标"></a>目标</h3><ul>
<li>了解轮廓是什么。</li>
<li>学习寻找轮廓，绘制轮廓等</li>
<li>您将看到以下功能：<code>cv.findContours()</code>，<code>cv.drawContours()</code></li>
</ul>
<h3 id="什么是轮廓？"><a href="#什么是轮廓？" class="headerlink" title="什么是轮廓？"></a>什么是轮廓？</h3><p>轮廓可以简单地解释为连接具有相同颜色或强度的所有连续点（沿边界）的曲线。轮廓是用于形状分析以及对象检测和识别的有用工具。</p>
<ul>
<li>为了获得更高的准确性，请使用二进制图像。因此，在找到轮廓之前，请应用阈值或坎尼边缘检测。</li>
<li>从OpenCV 3.2开始，<code>findContours()</code>不再修改源图像。</li>
<li>在OpenCV中，找到轮廓就像从黑色背景中找到白色物体。因此请记住，要找到的对象应该是白色，背景应该是黑色。<br>让我们看看如何找到二进制图像的轮廓：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">im = cv.imread(<span class="string">'lena.jpg'</span>)</span><br><span class="line">imgray = cv.cvtColor(im, cv.COLOR_BGR2GRAY)</span><br><span class="line">ret, thresh = cv.threshold(imgray, <span class="number">127</span>, <span class="number">255</span>, <span class="number">0</span>)</span><br><span class="line">contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)</span><br></pre></td></tr></table></figure>

<p>在<code>cv.findContours()</code>函数中有三个参数，第一个是源图像，第二个是轮廓检索模式，第三个是轮廓逼近方法。并输出轮廓和层次。轮廓是图像中所有轮廓的Python列表。每个单独的轮廓都是对象边界点的（x，y）坐标的Numpy数组。</p>
<h3 id="如何绘制轮廓？"><a href="#如何绘制轮廓？" class="headerlink" title="如何绘制轮廓？"></a>如何绘制轮廓？</h3><p>要绘制轮廓，请使用<code>cv.drawContours</code>函数。只要有边界点，它也可以用来绘制任何形状。它的第一个参数是源图像，第二个参数是应该作为Python列表传递的轮廓，第三个参数是轮廓的索引（在绘制单个轮廓时很有用。要绘制所有轮廓，请传递-1），其余参数是颜色，厚度等等</p>
<ul>
<li>要在图像中绘制所有轮廓：<br><code>cv.drawContours(img, contours, -1, (0,255,0), 3)</code></li>
<li>要绘制单个轮廓，请说第四个轮廓：<br><code>cv.drawContours(img, contours, 3, (0,255,0), 3)</code><br>但是在大多数情况下，以下方法会很有用：<br><code>cnt = contours[4]
cv.drawContours(img, [cnt], 0, (0,255,0), 3)</code></li>
</ul>
<blockquote>
<p>最后两种方法相同，但是前进时，您会发现最后一种更有用。</p>
</blockquote>
<h3 id="轮廓近似法"><a href="#轮廓近似法" class="headerlink" title="轮廓近似法"></a>轮廓近似法</h3><p>这是<code>cv.findContours</code>函数中的第三个参数。它实际上表示什么？</p>
<p>上面我们告诉我们轮廓是强度相同的形状的边界。它存储形状边界的（x，y）坐标。但是它存储所有坐标吗？这是通过这种轮廓近似方法指定的。</p>
<p>如果传递<code>cv.CHAIN_APPROX_NONE</code>，则会存储所有边界点。但是实际上我们需要所有这些要点吗？例如，您找到了一条直线的轮廓。您是否需要线上的所有点来代表该线？不，我们只需要该线的两个端点即可。这就是<code>cv.CHAIN_APPROX_SIMPLE</code>所做的。它删除所有冗余点并压缩轮廓，从而节省内存。</p>
<h2 id="轮廓特征"><a href="#轮廓特征" class="headerlink" title="轮廓特征"></a>轮廓特征</h2><h3 id="目标-9"><a href="#目标-9" class="headerlink" title="目标"></a>目标</h3><ul>
<li>查找轮廓的不同特征，例如面积，周长，质心，边界框等</li>
<li>您将看到大量与轮廓有关的功能。</li>
</ul>
<h3 id="1-时刻"><a href="#1-时刻" class="headerlink" title="1.时刻"></a>1.时刻</h3><p>图像矩可帮助您计算某些特征，例如物体的重心，物体的面积等。请查看“ 图像矩”上的Wikipedia页面</p>
<p>函数<code>cv.moments()</code>提供了所有计算出的矩值的字典。见下文：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">'star.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">ret,thresh = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,<span class="number">0</span>)</span><br><span class="line">contours,hierarchy = cv.findContours(thresh, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">cnt = contours[<span class="number">0</span>]</span><br><span class="line">M = cv.moments(cnt)</span><br><span class="line">print( M )</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cx = int(M[<span class="string">'m10'</span>]/M[<span class="string">'m00'</span>])</span><br><span class="line">cy = int(M[<span class="string">'m01'</span>]/M[<span class="string">'m00'</span>])</span><br></pre></td></tr></table></figure>

<h3 id="2-轮廓面积"><a href="#2-轮廓面积" class="headerlink" title="2.轮廓面积"></a>2.轮廓面积</h3><p>轮廓区域由函数<code>cv.contourArea()</code>或从力矩M [‘m00’]中给出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">area = cv.contourArea(cnt)</span><br></pre></td></tr></table></figure>

<h3 id="3-轮廓周长"><a href="#3-轮廓周长" class="headerlink" title="3.轮廓周长"></a>3.轮廓周长</h3><p>也称为弧长。可以使用<code>cv.arcLength()</code>函数找到它。第二个参数指定形状是闭合轮廓（如果通过True）还是曲线。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">perimeter = cv.arcLength(cnt,<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h3 id="4-轮廓近似"><a href="#4-轮廓近似" class="headerlink" title="4.轮廓近似"></a>4.轮廓近似</h3><p>根据我们指定的精度，它可以将轮廓形状近似为顶点数量较少的其他形状。它是<code>Douglas-Peucker</code>算法的实现。</p>
<p>为了理解这一点，假设您试图在图像中找到一个正方形，但是由于图像中的某些问题，您没有得到一个完美的正方形，而是一个“坏形状”（如下图所示）。现在，您可以使用此功能来近似形状。在这种情况下，第二个参数称为<code>epsilon</code>，它是从轮廓到近似轮廓的最大距离。它是一个精度参数。需要正确选择<code>epsilon</code>才能获得正确的输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">epsilon = <span class="number">0.1</span>*cv.arcLength(cnt,<span class="literal">True</span>)</span><br><span class="line">approx = cv.approxPolyDP(cnt,epsilon,<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>下面，在第二张图片中，绿线显示了ε=弧长的10％时的近似曲线。第三幅图显示了ε=电弧长度的1％时的情况。第三个参数指定曲线是否闭合。</p>
<p><img src="/images/approx.jpg" alt></p>
<h3 id="5-凸包"><a href="#5-凸包" class="headerlink" title="5.凸包"></a>5.凸包</h3><p>凸包外观看起来与轮廓逼近相似，但并非如此（在某些情况下两者可能提供相同的结果）。在这里，<code>cv.convexHull()</code>函数检查曲线是否存在凸凹缺陷并对其进行校正。一般而言，凸曲线是始终凸出或至少平坦的曲线。如果在内部凸出，则称为凸度缺陷。例如，检查下面的手的图像。红线显示手的凸包。双向箭头标记显示凸度缺陷，这是船体与轮廓线之间的局部最大偏差。</p>
<p><img src="/images/convexitydefects.jpg" alt></p>
<p>关于它的语法，有一些事情需要讨论：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hull = cv.convexHull(points[, hull[, clockwise[, returnPoints]]</span><br></pre></td></tr></table></figure>

<p>参数详细信息：</p>
<ul>
<li><strong>points</strong>就是我们传入的轮廓。</li>
<li><strong>hull</strong>是输出，通常我们避免它。</li>
<li><strong>clockwise</strong>方向标记。如果为True，则输出凸包为顺时针方向。否则，其方向为逆时针方向。</li>
<li><strong>returnPoints</strong>：默认情况下为True。然后返回船体点的坐标。如果为False，则返回与船体点相对应的轮廓点的索引。<br>因此，要获得如上图所示的凸包，以下内容就足够了：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hull = cv.convexHull(cnt)</span><br></pre></td></tr></table></figure>

<p>但是，如果要查找凸度缺陷，则需要传递<code>returnPoints = False</code>。为了理解它，我们将拍摄上面的矩形图像。首先，我发现它的轮廓为cnt。现在，我发现它的带有<code>returnPoints = True</code>的凸包，得到以下值：[[[234 202]]，[[51 202]]，[[51 79]]，[[234 79]]]，它们是四个角矩形的点。现在，如果对<code>returnPoints = False</code>执行相同的操作，则会得到以下结果：[[129]，[67]，[0]，[142]]。这些是轮廓中相应点的索引。例如，检查第一个值：cnt [129] = [[234，202]]与第一个结果相同（对于其他结果依此类推）。</p>
<h3 id="6-检查凸度"><a href="#6-检查凸度" class="headerlink" title="6.检查凸度"></a>6.检查凸度</h3><p><code>cv.isContourConvex()</code>有一个函数可以检查曲线是否为凸形。它只是返回True还是False。没有大碍。</p>
<h3 id="7-边界矩形"><a href="#7-边界矩形" class="headerlink" title="7.边界矩形"></a>7.边界矩形</h3><p>有两种类型的边界矩形。</p>
<h4 id="7-A-直角矩形"><a href="#7-A-直角矩形" class="headerlink" title="7.A. 直角矩形"></a>7.A. 直角矩形</h4><p>它是一个直角矩形，不考虑对象的旋转。因此，边界矩形的面积将不会最小。它可以通过函数<code>cv.boundingRect()</code>找到。</p>
<p>令（x，y）为矩形的左上角坐标，而（w，h）为矩形的宽度和高度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x,y,w,h = cv.boundingRect(cnt)</span><br><span class="line">cv.rectangle(img,(x,y),(x+w,y+h),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<h4 id="7-b-旋转矩形"><a href="#7-b-旋转矩形" class="headerlink" title="7.b. 旋转矩形"></a>7.b. 旋转矩形</h4><p>在这里，边界矩形是用最小面积绘制的，因此它也考虑了旋转。使用的函数是<code>cv.minAreaRect()</code>。它返回一个Box2D结构，其中包含以下细节-（中心（x，y），（宽度，高度），旋转角度）。但是要绘制此矩形，我们需要矩形的4个角。它是通过函数<code>cv.boxPoints()</code>获得的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rect = cv.minAreaRect(cnt)</span><br><span class="line">box = cv.boxPoints(rect)</span><br><span class="line">box = np.int0(box)</span><br><span class="line">cv.drawContours(img,[box],<span class="number">0</span>,(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>),<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/images/boundingrect.png" alt></p>
<h3 id="8-最小外接圆"><a href="#8-最小外接圆" class="headerlink" title="8.最小外接圆"></a>8.最小外接圆</h3><p>接下来，我们使用函数<code>cv.minEnclosingCircle()</code>找到对象的外接圆。它是一个以最小面积完全覆盖对象的圆圈。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(x,y),radius = cv.minEnclosingCircle(cnt)</span><br><span class="line">center = (int(x),int(y))</span><br><span class="line">radius = int(radius)</span><br><span class="line">cv.circle(img,center,radius,(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/images/circumcircle.png" alt></p>
<h3 id="9-拟合椭圆"><a href="#9-拟合椭圆" class="headerlink" title="9.拟合椭圆"></a>9.拟合椭圆</h3><p>下一步是使椭圆适合对象。它返回椭圆所在的旋转形状。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ellipse = cv.fitEllipse(cnt)</span><br><span class="line">cv.ellipse(img,ellipse,(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/images/fitellipse.png" alt></p>
<h3 id="10-拟合线"><a href="#10-拟合线" class="headerlink" title="10.拟合线"></a>10.拟合线</h3><p>同样，我们可以将一条直线拟合到一组点。下图包含一组白点。我们可以近似一条直线。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rows,cols = img.shape[:<span class="number">2</span>]</span><br><span class="line">[vx,vy,x,y] = cv.fitLine(cnt, cv.DIST_L2,<span class="number">0</span>,<span class="number">0.01</span>,<span class="number">0.01</span>)</span><br><span class="line">lefty = int((-x*vy/vx) + y)</span><br><span class="line">righty = int(((cols-x)*vy/vx)+y)</span><br><span class="line">cv.line(img,(cols<span class="number">-1</span>,righty),(<span class="number">0</span>,lefty),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/images/fitline.jpg" alt></p>
<h2 id="轮廓属性"><a href="#轮廓属性" class="headerlink" title="轮廓属性"></a>轮廓属性</h2><p>在这里，我们将学习提取对象的一些常用属性，例如实体，等效直径，蒙版图像，平均强度等</p>
<h3 id="1-长宽比"><a href="#1-长宽比" class="headerlink" title="1.长宽比"></a>1.长宽比</h3><p>它是对象边界矩形的宽度与高度的比率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x,y,w,h = cv.boundingRect(cnt)</span><br><span class="line">aspect_ratio = float(w)/h</span><br></pre></td></tr></table></figure>

<h3 id="2-范围"><a href="#2-范围" class="headerlink" title="2.范围"></a>2.范围</h3><p>范围是轮廓区域与边界矩形区域的比率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">area = cv.contourArea(cnt)</span><br><span class="line">x,y,w,h = cv.boundingRect(cnt)</span><br><span class="line">rect_area = w*h</span><br><span class="line">extent = float(area)/rect_area</span><br></pre></td></tr></table></figure>

<h3 id="3-坚固性"><a href="#3-坚固性" class="headerlink" title="3.坚固性"></a>3.坚固性</h3><p>坚固度是轮廓面积与其凸包面积的比率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">area = cv.contourArea(cnt)</span><br><span class="line">hull = cv.convexHull(cnt)</span><br><span class="line">hull_area = cv.contourArea(hull)</span><br><span class="line">solidity = float(area)/hull_area</span><br></pre></td></tr></table></figure>

<h3 id="4-等效直径"><a href="#4-等效直径" class="headerlink" title="4.等效直径"></a>4.等效直径</h3><p>当量直径是面积与轮廓面积相同的圆的直径。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">area = cv.contourArea(cnt)</span><br><span class="line">equi_diameter = np.sqrt(<span class="number">4</span>*area/np.pi)</span><br></pre></td></tr></table></figure>

<h3 id="5-方向"><a href="#5-方向" class="headerlink" title="5.方向"></a>5.方向</h3><p>方向是物体指向的角度。以下方法还给出了主轴和副轴的长度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(x,y),(MA,ma),angle = cv.fitEllipse(cnt)</span><br></pre></td></tr></table></figure>

<h3 id="6-遮罩和像素点"><a href="#6-遮罩和像素点" class="headerlink" title="6.遮罩和像素点"></a>6.遮罩和像素点</h3><p>在某些情况下，我们可能需要构成该对象的所有点。可以按照以下步骤完成：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mask = np.zeros(imgray.shape,np.uint8)</span><br><span class="line">cv.drawContours(mask,[cnt],<span class="number">0</span>,<span class="number">255</span>,<span class="number">-1</span>)</span><br><span class="line">pixelpoints = np.transpose(np.nonzero(mask))</span><br><span class="line"><span class="comment">#pixelpoints = cv.findNonZero(mask)</span></span><br></pre></td></tr></table></figure>

<h3 id="7-最大值，最小值及其位置"><a href="#7-最大值，最小值及其位置" class="headerlink" title="7.最大值，最小值及其位置"></a>7.最大值，最小值及其位置</h3><p>我们可以使用遮罩图像找到这些参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">min_val, max_val, min_loc, max_loc = cv.minMaxLoc(imgray,mask = mask)</span><br></pre></td></tr></table></figure>

<h3 id="8-平均颜色或平均强度"><a href="#8-平均颜色或平均强度" class="headerlink" title="8.平均颜色或平均强度"></a>8.平均颜色或平均强度</h3><p>在这里，我们可以找到对象的平均颜色。或者可以是灰度模式下物体的平均强度。我们再次使用相同的蒙版进行此操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mean_val = cv.mean(im,mask = mask)</span><br></pre></td></tr></table></figure>

<h3 id="9-极端点"><a href="#9-极端点" class="headerlink" title="9.极端点"></a>9.极端点</h3><p>极点是指对象的最顶部，最底部，最右侧和最左侧的点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">leftmost = tuple(cnt[cnt[:,:,<span class="number">0</span>].argmin()][<span class="number">0</span>])</span><br><span class="line">rightmost = tuple(cnt[cnt[:,:,<span class="number">0</span>].argmax()][<span class="number">0</span>])</span><br><span class="line">topmost = tuple(cnt[cnt[:,:,<span class="number">1</span>].argmin()][<span class="number">0</span>])</span><br><span class="line">bottommost = tuple(cnt[cnt[:,:,<span class="number">1</span>].argmax()][<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<h2 id="轮廓：更多功能"><a href="#轮廓：更多功能" class="headerlink" title="轮廓：更多功能"></a>轮廓：更多功能</h2><h3 id="目标-10"><a href="#目标-10" class="headerlink" title="目标"></a>目标</h3><ul>
<li>凸性缺陷以及如何找到它们。</li>
<li>查找点到多边形的最短距离</li>
<li>匹配不同的形状</li>
</ul>
<h3 id="理论与规范"><a href="#理论与规范" class="headerlink" title="理论与规范"></a>理论与规范</h3><h3 id="1-凸性缺陷"><a href="#1-凸性缺陷" class="headerlink" title="1.凸性缺陷"></a>1.凸性缺陷</h3><p>我们看到了关于轮廓的凸包。物体与该船体的任何偏离都可以视为凸度缺陷。</p>
<p>OpenCV带有一个现成的函数<code>cv.convexityDefects()</code>来查找该函数。基本的函数调用如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hull = cv.convexHull(cnt,returnPoints = <span class="literal">False</span>)</span><br><span class="line">defects = cv.convexityDefects(cnt,hull)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意:请记住，在寻找凸包时，我们必须传递<code>returnPoints = False</code>，以便寻找凸缺陷。</p>
</blockquote>
<p>它返回一个数组，其中每行包含这些值- [起点，终点，最远点，到最远点的近似距离]。我们可以使用图像对其进行可视化。我们画一条连接起点和终点的线，然后在最远的点画一个圆。请记住，返回的前三个值是cnt的索引。因此，我们必须从cnt带来这些价值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img = cv.imread(<span class="string">'star.jpg'</span>)</span><br><span class="line">img_gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line">ret,thresh = cv.threshold(img_gray, <span class="number">127</span>, <span class="number">255</span>,<span class="number">0</span>)</span><br><span class="line">contours,hierarchy = cv.findContours(thresh,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">cnt = contours[<span class="number">0</span>]</span><br><span class="line">hull = cv.convexHull(cnt,returnPoints = <span class="literal">False</span>)</span><br><span class="line">defects = cv.convexityDefects(cnt,hull)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(defects.shape[<span class="number">0</span>]):</span><br><span class="line">    s,e,f,d = defects[i,<span class="number">0</span>]</span><br><span class="line">    start = tuple(cnt[s][<span class="number">0</span>])</span><br><span class="line">    end = tuple(cnt[e][<span class="number">0</span>])</span><br><span class="line">    far = tuple(cnt[f][<span class="number">0</span>])</span><br><span class="line">    cv.line(img,start,end,[<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>],<span class="number">2</span>)</span><br><span class="line">    cv.circle(img,far,<span class="number">5</span>,[<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>],<span class="number">-1</span>)</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<p><img src="/images/defects.jpg" alt></p>
<h3 id="2-点多边形测试"><a href="#2-点多边形测试" class="headerlink" title="2.点多边形测试"></a>2.点多边形测试</h3><p>此功能查找图像中的点与轮廓之间的最短距离。它返回的距离为：当点在轮廓外时为负；当点在轮廓内时为正；如果点在轮廓上，则返回零。</p>
<p>例如，我们可以如下检查点（50,50）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dist = cv.pointPolygonTest（cnt，（<span class="number">50</span>,<span class="number">50</span>），<span class="literal">True</span>）</span><br></pre></td></tr></table></figure>

<p>在函数中，第三个参数是<code>measureDist</code>。如果为True，则找到带符号的距离。如果为False，它将查找该点是在轮廓内部还是外部或轮廓上（它分别返回+ 1，-1、0）。</p>
<blockquote>
<p>注意:如果您不想查找距离，请确保第三个参数为False，因为这是一个耗时的过程。因此，将其设置为False可使速度提高2-3倍。</p>
</blockquote>
<h3 id="3-比较形状"><a href="#3-比较形状" class="headerlink" title="3.比较形状"></a>3.比较形状</h3><p>OpenCV带有函数<code>cv.matchShapes()</code>，使我们能够比较两个形状或两个轮廓，并返回显示相似性的度量。结果越低，匹配越好。它是基于<code>hu-moment</code>值计算的。文档中介绍了不同的测量方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img1 = cv.imread(<span class="string">'star.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">img2 = cv.imread(<span class="string">'star2.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">ret, thresh = cv.threshold(img1, <span class="number">127</span>, <span class="number">255</span>,<span class="number">0</span>)</span><br><span class="line">ret, thresh2 = cv.threshold(img2, <span class="number">127</span>, <span class="number">255</span>,<span class="number">0</span>)</span><br><span class="line">contours,hierarchy = cv.findContours(thresh,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">cnt1 = contours[<span class="number">0</span>]</span><br><span class="line">contours,hierarchy = cv.findContours(thresh2,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">cnt2 = contours[<span class="number">0</span>]</span><br><span class="line">ret = cv.matchShapes(cnt1,cnt2,<span class="number">1</span>,<span class="number">0.0</span>)</span><br><span class="line">print( ret )</span><br></pre></td></tr></table></figure>

<p>我尝试匹配以下给出的不同形状的形状：</p>
<p><img src="/images/matchshapes.jpg" alt></p>
<p>我得到以下结果：</p>
<ul>
<li>匹配图像A本身= 0.0</li>
<li>将图像A与图像B匹配= 0.001946</li>
<li>将图像A与图像C匹配= 0.326911<br>看，即使图像旋转也不会对该比较产生太大影响。</li>
</ul>
<p>也可以看看<br><code>Hu-Moments</code>是平移，旋转和缩放不变的七个时刻。第七个是偏斜不变的。这些值可以使用<code>cv.HuMoments()</code>函数找到。</p>
<h2 id="轮廓层次"><a href="#轮廓层次" class="headerlink" title="轮廓层次"></a>轮廓层次</h2><h3 id="目标-11"><a href="#目标-11" class="headerlink" title="目标"></a>目标</h3><p>这次，我们了解轮廓的层次结构，即<code>Contours</code>中的父子关系。</p>
<h3 id="理论-4"><a href="#理论-4" class="headerlink" title="理论"></a>理论</h3><p>在有关轮廓的最后几篇文章中，我们使用了与OpenCV提供的轮廓相关的一些功能。但是，当我们使用<code>cv.findContours()</code>函数在图像中找到轮廓时，我们传递了一个参数，即<code>Contour Retrieval Mode</code>。我们通常通过<code>cv.RETR_LIST</code>或<code>cv.RETR_TREE</code>，效果很好。但这实际上是什么意思？</p>
<p>另外，在输出中，我们得到了三个数组，第一个是图像，第二个是轮廓，另一个是我们命名为层次结构的输出（请检查上一篇文章中的代码）。但是，我们从未在任何地方使用此层次结构。那么，这个层次结构是什么呢？它与前面提到的函数参数有什么关系？</p>
<p>这就是本文要处理的内容。</p>
<h3 id="什么是层次结构？"><a href="#什么是层次结构？" class="headerlink" title="什么是层次结构？"></a>什么是层次结构？</h3><p>通常我们使用<code>cv.findContours()</code>函数来检测图像中的对象，对吗？有时对象位于不同的位置。但是在某些情况下，某些形状位于其他形状内。就像嵌套的数字一样。在这种情况下，我们将外部的一个称为父级，将内部的一个称为子级。这样，图像中的轮廓彼此之间就具有某种关系。并且我们可以指定一个轮廓如何相互连接，例如是其他轮廓的子轮廓，还是父轮廓等。这种关系的表示称为层次结构。</p>
<p>考虑下面的示例图像：</p>
<p><img src="/images/hierarchy.png" alt></p>
<p>在此图像中，我从0-5编号了一些形状。2和2a表示最外面的盒子的外部和内部轮廓。</p>
<p>在此，轮廓0,1,2在外部或最外部。我们可以说，它们处于0层次结构中，或者只是处于相同的层次结构级别中。</p>
<p>接下来是轮廓2a。可以将其视为轮廓2的子级（或者相反，轮廓2是轮廓2a的父级）。因此，将其设置为hierarchy-1。同样，contour-3是contour-2的子级，位于下一个层次结构中。最后，轮廓4,5是轮廓3a的子级，它们位于最后的层次结构级别。从编号方式上来说，轮廓4是轮廓3a的第一个子元素（也可以是轮廓5）。</p>
<p>我提到这些东西是为了理解诸如相同的层次结构级别，外部轮廓，子轮廓，父轮廓，第一个孩子等术语。现在让我们进入OpenCV。</p>
<p>OpenCV中的层次结构表示<br>因此，每个轮廓都有关于其层次结构，其子级，其父级等的信息。OpenCV将其表示为四个值的数组：[Next，Previous，First_Child，Parent]</p>
<p>*“下一个表示相同等级的下一个轮廓。” *<br>例如，在我们的图片中选择轮廓0。谁是同一级别的下一个轮廓？它是轮廓1。因此，只需将Next = 1放进去。同样对于Contour-1，下一个就是轮廓线2。所以下一个= 2。</p>
<p>那轮廓2呢？在同一层中没有下一个轮廓。简而言之，将Next = -1。那轮廓4呢？与轮廓5处于同一水平。所以它的下一个轮廓是轮廓5，所以Next = 5。</p>
<p>*“上一个表示相同轮廓级别的上一个轮廓。” *<br>和上面一样。轮廓1的先前轮廓是同一级别的轮廓0。同样对于轮廓2，它是轮廓1。对于轮廓0，没有先前值，因此将其设为-1。</p>
<p>*“ First_Child表示其第一个子轮廓。” *<br>无需任何解释。对于轮廓2，子级是轮廓2a。这样就得到了轮廓2a的相应索引值。那轮廓3a呢？它有两个孩子。但是我们只带第一个孩子。它是轮廓4。因此，轮廓3a的First_Child = 4。</p>
<p>*“父代表示其父代轮廓的索引。” *<br>它与First_Child相反。轮廓4和轮廓5的父轮廓均为轮廓3a。对于轮廓3a，它是轮廓3，依此类推。</p>
<blockquote>
<p>注意:如果没有孩子或父母，则该字段为-1</p>
</blockquote>
<p>因此，现在我们知道了OpenCV中使用的层次结构样式，我们可以借助上面给出的相同图像来检查OpenCV中的轮廓检索模式。即，像<code>cv.RETR_LIST</code>，<code>cv.RETR_TREE</code>，<code>cv.RETR_CCOMP</code>，<code>cv.RETR_EXTERNAL</code>等标志是什么意思？</p>
<h2 id="轮廓检索模式"><a href="#轮廓检索模式" class="headerlink" title="轮廓检索模式"></a>轮廓检索模式</h2><h3 id="1-RETR-LIST"><a href="#1-RETR-LIST" class="headerlink" title="1. RETR_LIST"></a>1. RETR_LIST</h3><p>这是四个标志中最简单的一个（从解释的角度来看）。它仅检索所有轮廓，但不创建任何父子关系。在这个规则下，父母和孩子是平等的，他们只是轮廓。即它们都属于同一层次结构级别。</p>
<p>因此，在这里，层次结构数组中的第3和第4项始终为-1。但是很明显，下一个和上一个术语将具有其相应的值。只需自己检查并验证即可。</p>
<p>以下是我得到的结果，每行是相应轮廓的层次结构详细信息。例如，第一行对应于轮廓0。下一个轮廓为轮廓1。因此Next =1。没有先前的轮廓，因此<code>Previous = -1</code>。如前所述，其余两个为-1。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>hierarchy</span><br><span class="line">array([[[ <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>],</span><br><span class="line">        [ <span class="number">2</span>,  <span class="number">0</span>, <span class="number">-1</span>, <span class="number">-1</span>],</span><br><span class="line">        [ <span class="number">3</span>,  <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">2</span>, <span class="number">-1</span>, <span class="number">-1</span>],</span><br><span class="line">        [ <span class="number">5</span>,  <span class="number">3</span>, <span class="number">-1</span>, <span class="number">-1</span>],</span><br><span class="line">        [ <span class="number">6</span>,  <span class="number">4</span>, <span class="number">-1</span>, <span class="number">-1</span>],</span><br><span class="line">        [ <span class="number">7</span>,  <span class="number">5</span>, <span class="number">-1</span>, <span class="number">-1</span>],</span><br><span class="line">        [<span class="number">-1</span>,  <span class="number">6</span>, <span class="number">-1</span>, <span class="number">-1</span>]]])</span><br></pre></td></tr></table></figure>

<p>如果不使用任何层次结构功能，这是在代码中使用的不错选择。</p>
<h3 id="2-RETR-EXTERNAL"><a href="#2-RETR-EXTERNAL" class="headerlink" title="2. RETR_EXTERNAL"></a>2. RETR_EXTERNAL</h3><p>如果使用此标志，则仅返回极端的外部标志。保留所有子轮廓。可以说，根据这项法律，只有每个家庭中的老大才能得到照顾。它不在乎家庭其他成员:</p>
<p>那么，在我们的图像中，有多少个极端的外部轮廓？即在等级0级别？只有3个，即轮廓0,1,2，对吗？现在尝试使用该标志查找轮廓。在此，赋予每个元素的值也与上述相同。与上面的结果进行比较。以下是我得到的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>hierarchy</span><br><span class="line">array([[[ <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>],</span><br><span class="line">        [ <span class="number">2</span>,  <span class="number">0</span>, <span class="number">-1</span>, <span class="number">-1</span>],</span><br><span class="line">        [<span class="number">-1</span>,  <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>]]])</span><br></pre></td></tr></table></figure>

<p>如果只想提取外部轮廓，则可以使用此标志。在某些情况下可能有用。</p>
<h3 id="3-RETR-CCOMP"><a href="#3-RETR-CCOMP" class="headerlink" title="3. RETR_CCOMP"></a>3. RETR_CCOMP</h3><p>该标志检索所有轮廓并将它们排列为2级层次结构。即，对象的外部轮廓（即其边界）位于层次1中。然后，将对象（如果有）中的孔的轮廓放置在层次2中。如果其中有任何对象，则其轮廓将仅再次放置在等级1中。以及它在等级2中的漏洞等等。</p>
<p>只需考虑黑色背景上的“白色大零”图像即可。零外圈属于第一层级，零内圈属于第二层级。</p>
<p>我们可以用一个简单的图像来解释它。在这里，我用红色标记了轮廓的顺序，并用绿色（1或2）标记了它们所属的层次。该顺序与OpenCV检测轮廓的顺序相同。</p>
<p><img src="/images/ccomp_hierarchy.png" alt></p>
<p>因此考虑第一个轮廓，即轮廓0。它是等级1。它有两个孔，轮廓1和2，它们属于层次2。因此，对于轮廓0，相同层次结构级别中的下一个轮廓为轮廓3。而且没有以前的。它的第一个子对象是层次结构2中的轮廓1。它没有父级，因为它位于1层级中。因此其层次结构数组为[3，-1,1，-1]</p>
<p>现在取轮廓1。它在等级2中。在同一层次结构中（轮廓1的父项下）下一个是轮廓2。没有上一个。没有孩子，但父母的轮廓为0。因此数组为[2，-1，-1,0]。</p>
<p>同样的轮廓2：它位于层次2中。在轮廓-0下的相同层次结构中没有下一个轮廓。所以没有下一步。上一个是轮廓1。没有孩子，父母的轮廓为0。因此数组为[-1,1，-1,0]。</p>
<p>轮廓-3：等级1中的下一个是轮廓5。上一个是轮廓0。孩子是轮廓4，没有父母。因此数组为[5,0,4，-1]。</p>
<p>轮廓-4：位于轮廓3下的层次2中，并且没有同级。所以没有下一个，没有以前的，没有孩子，父母是轮廓3。因此数组为[-1，-1，-1,3]。</p>
<p>剩下的可以填满。这是我得到的最终答案：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>hierarchy</span><br><span class="line">array([[[ <span class="number">3</span>, <span class="number">-1</span>,  <span class="number">1</span>, <span class="number">-1</span>],</span><br><span class="line">        [ <span class="number">2</span>, <span class="number">-1</span>, <span class="number">-1</span>,  <span class="number">0</span>],</span><br><span class="line">        [<span class="number">-1</span>,  <span class="number">1</span>, <span class="number">-1</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">5</span>,  <span class="number">0</span>,  <span class="number">4</span>, <span class="number">-1</span>],</span><br><span class="line">        [<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">7</span>,  <span class="number">3</span>,  <span class="number">6</span>, <span class="number">-1</span>],</span><br><span class="line">        [<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>,  <span class="number">5</span>],</span><br><span class="line">        [ <span class="number">8</span>,  <span class="number">5</span>, <span class="number">-1</span>, <span class="number">-1</span>],</span><br><span class="line">        [<span class="number">-1</span>,  <span class="number">7</span>, <span class="number">-1</span>, <span class="number">-1</span>]]])</span><br></pre></td></tr></table></figure>

<h3 id="4-RETR-TREE"><a href="#4-RETR-TREE" class="headerlink" title="4. RETR_TREE"></a>4. RETR_TREE</h3><p>这是最后一个家伙，Perfect先生。它检索所有轮廓并创建完整的族层次列表。它甚至告诉，谁是爷爷，父亲，儿子，孙子甚至更远… :)。</p>
<p>例如，我拍摄了上面的图片，重写了<code>cv.RETR_TREE</code>的代码，根据OpenCV给定的结果对轮廓进行重新排序并对其进行分析。同样，红色字母表示轮廓编号，绿色字母表示层次结构顺序。</p>
<p><img src="/images/tree_hierarchy.png" alt></p>
<p>取轮廓0：在层次0中。同一层次结构中的下一个轮廓是轮廓7。没有先前的轮廓。孩子是轮廓1。而且没有父母。因此数组为[7，-1,1，-1]。</p>
<p>取轮廓2：在等级1中。同一级别无轮廓。没有上一个。孩子是轮廓3。父级是轮廓1。因此数组为[-1，-1,3,1]。</p>
<p>还有，尝试一下。以下是完整答案：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>hierarchy</span><br><span class="line">array([[[ <span class="number">7</span>, <span class="number">-1</span>,  <span class="number">1</span>, <span class="number">-1</span>],</span><br><span class="line">        [<span class="number">-1</span>, <span class="number">-1</span>,  <span class="number">2</span>,  <span class="number">0</span>],</span><br><span class="line">        [<span class="number">-1</span>, <span class="number">-1</span>,  <span class="number">3</span>,  <span class="number">1</span>],</span><br><span class="line">        [<span class="number">-1</span>, <span class="number">-1</span>,  <span class="number">4</span>,  <span class="number">2</span>],</span><br><span class="line">        [<span class="number">-1</span>, <span class="number">-1</span>,  <span class="number">5</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">6</span>, <span class="number">-1</span>, <span class="number">-1</span>,  <span class="number">4</span>],</span><br><span class="line">        [<span class="number">-1</span>,  <span class="number">5</span>, <span class="number">-1</span>,  <span class="number">4</span>],</span><br><span class="line">        [ <span class="number">8</span>,  <span class="number">0</span>, <span class="number">-1</span>, <span class="number">-1</span>],</span><br><span class="line">        [<span class="number">-1</span>,  <span class="number">7</span>, <span class="number">-1</span>, <span class="number">-1</span>]]])</span><br></pre></td></tr></table></figure>

<h1 id="OpenCV中的直方图"><a href="#OpenCV中的直方图" class="headerlink" title="OpenCV中的直方图"></a>OpenCV中的直方图</h1><h2 id="直方图-1：查找，绘制，分析"><a href="#直方图-1：查找，绘制，分析" class="headerlink" title="直方图-1：查找，绘制，分析!!!"></a>直方图-1：查找，绘制，分析!!!</h2><h3 id="目标-12"><a href="#目标-12" class="headerlink" title="目标"></a>目标</h3><ul>
<li>使用OpenCV和Numpy函数查找直方图</li>
<li>使用OpenCV和Matplotlib函数绘制直方图</li>
<li>您将看到以下功能：cv.calcHist()，np.histogram()等。</li>
</ul>
<h3 id="理论-5"><a href="#理论-5" class="headerlink" title="理论"></a>理论</h3><p>那么直方图是什么？您可以将直方图视为图形或曲线图，从而使您对图像的强度分布有一个整体的了解。它是在X轴上具有像素值（不总是从0到255的范围），在Y轴上具有图像中相应像素数的图。</p>
<p>这只是理解图像的另一种方式。通过查看图像的直方图，您可以直观地了解该图像的对比度，亮度，强度分布等。当今几乎所有图像处理工具都提供直方图功能。以下是剑桥彩色网站上的图片，建议您访问该网站以获取更多详细信息。</p>
<p><img src="/images/histogram_sample.jpg" alt></p>
<p>您可以看到图像及其直方图。（请记住，此直方图是针对灰度图像而非彩色图像绘制的）。直方图的左侧区域显示图像中较暗像素的数量，而右侧区域则显示较亮像素的数量。从直方图中，您可以看到暗区域多于亮区域，中间调的数量（中间值的像素值，例如127附近）非常少。</p>
<h3 id="查找直方图"><a href="#查找直方图" class="headerlink" title="查找直方图"></a>查找直方图</h3><p>现在我们有了一个关于直方图的想法，我们可以研究如何找到它。OpenCV和Numpy都为此内置了功能。在使用这些功能之前，我们需要了解一些与直方图有关的术语。</p>
<p><strong>BINS</strong>：上面的直方图显示每个像素值的像素数，即从0到255。即，您需要256个值来显示上面的直方图。但是考虑一下，如果您不需要分别找到所有像素值的像素数，而是找到像素值间隔中的像素数怎么办？例如，您需要找到介于0到15之间，然后16到31之间，…，240到255之间的像素数。您只需要16个值即可表示直方图。这就是在<a href="https://docs.opencv.org/4.1.1/d8/dbc/tutorial_histogram_calculation.html" target="_blank" rel="noopener">OpenCV直方图教程</a>中给出的示例中所显示的内容。</p>
<p>因此，您要做的就是将整个直方图分成16个子部分，每个子部分的值就是其中所有像素数的总和。每个子部分都称为“ BIN”。在第一种情况下，bin的数量为256个（每个像素一个），而在第二种情况下，bin的数量仅为16个。BINS由OpenCV文档中的histSize术语表示。</p>
<p><strong>DIMS</strong>：这是我们为其收集数据的参数的数量。在这种情况下，我们仅收集关于强度值的一件事的数据。所以这里是1。</p>
<p>范围：这是您要测量的强度值的范围。通常，它是[0,256]，即所有强度值。</p>
<h4 id="1-OpenCV中的直方图计算"><a href="#1-OpenCV中的直方图计算" class="headerlink" title="1. OpenCV中的直方图计算"></a>1. OpenCV中的直方图计算</h4><p>因此，现在我们使用<code>cv.calcHist()</code>函数查找直方图。让我们熟悉一下函数及其参数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]])</span><br></pre></td></tr></table></figure>

<ul>
<li>images：它是uint8或float32类型的源图像。它应该放在方括号中，即“ [img]”。</li>
<li>channels：也以方括号给出。它是我们计算直方图的通道的索引。例如，如果输入为灰度图像，则其值为[0]。对于彩色图像，您可以传递[0]，[1]或[2]分别计算蓝色，绿色或红色通道的直方图。</li>
<li>mask：遮罩图像。为了找到完整图像的直方图，将其指定为“无”。但是，如果要查找图像特定区域的直方图，则必须为此创建一个遮罩图像并将其作为遮罩。（我将在后面显示一个示例。）</li>
<li>histSize：这表示我们的BIN计数。需要放在方括号中。对于全尺寸，我们通过[256]。</li>
<li>ranges：这是我们的RANGE。通常为[0,256]。<br>因此，让我们从示例图像开始。只需在灰度模式下加载图像并找到其完整的直方图即可。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(&apos;home.jpg&apos;,0)</span><br><span class="line">hist = cv.calcHist([img],[0],None,[256],[0,256])</span><br></pre></td></tr></table></figure>

<p>hist是256x1的数组，每个值对应于该图像中具有相应像素值的像素数。</p>
<h4 id="2-Numpy中的直方图计算"><a href="#2-Numpy中的直方图计算" class="headerlink" title="2. Numpy中的直方图计算"></a>2. Numpy中的直方图计算</h4><p>Numpy还为您提供了一个函数<code>np.histogram()</code>。因此，您可以在下面的行尝试代替<code>calcHist()</code>函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hist,bins = np.histogram(img.ravel(),<span class="number">256</span>,[<span class="number">0</span>,<span class="number">256</span>])</span><br></pre></td></tr></table></figure>

<p>hist与我们之前计算的相同。但是bin将具有257个元素，因为Numpy计算出bin的范围为0-0.99、1-1.99、2-2.99等。因此最终范围为255-255.99。为了表示这一点，他们还在料箱末端添加了256。但是我们不需要256。最多255就足够了。</p>
<p>也可以看看</p>
<p>Numpy还有另一个函数<code>np.bincount()</code>，它比<code>np.histogram()</code>快10倍左右。因此，对于一维直方图，您可以更好地尝试一下。不要忘记在<code>np.bincount</code>中设置<code>minlength = 256</code>。例如，<code>hist = np.bincount(img.ravel()，minlength = 256)</code></p>
<blockquote>
<p>注意:OpenCV函数比np.histogram()快（大约40倍）。因此，请坚持使用OpenCV功能。<br>现在我们应该绘制直方图，但是如何绘制？</p>
</blockquote>
<h3 id="绘制直方图"><a href="#绘制直方图" class="headerlink" title="绘制直方图"></a>绘制直方图</h3><p>有两种方法，</p>
<ul>
<li>简单方法：使用Matplotlib绘图功能</li>
<li>复杂方法：使用OpenCV绘图功能</li>
</ul>
<h4 id="1-使用Matplotlib"><a href="#1-使用Matplotlib" class="headerlink" title="1.使用Matplotlib"></a>1.使用Matplotlib</h4><p>Matplotlib带有直方图绘图功能：<code>matplotlib.pyplot.hist()</code></p>
<p>它直接找到直方图并将其绘制。您无需使用<code>calcHist()</code>或<code>np.histogram()</code>函数来查找直方图。请参见下面的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'home.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">plt.hist(img.ravel(),<span class="number">256</span>,[<span class="number">0</span>,<span class="number">256</span>]); plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/histogram_matplotlib.jpg" alt></p>
<p>或者，您可以使用matplotlib的法线图，这对于BGR图是很好的。为此，您需要首先找到直方图数据。试试下面的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'home.jpg'</span>)</span><br><span class="line">color = (<span class="string">'b'</span>,<span class="string">'g'</span>,<span class="string">'r'</span>)</span><br><span class="line"><span class="keyword">for</span> i,col <span class="keyword">in</span> enumerate(color):</span><br><span class="line">    histr = cv.calcHist([img],[i],<span class="literal">None</span>,[<span class="number">256</span>],[<span class="number">0</span>,<span class="number">256</span>])</span><br><span class="line">    plt.plot(histr,color = col)</span><br><span class="line">    plt.xlim([<span class="number">0</span>,<span class="number">256</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>您可以从上图中得出，蓝色在图像中具有一些高价值区域（显然这应该是由于天空）</p>
<h4 id="2-使用OpenCV"><a href="#2-使用OpenCV" class="headerlink" title="2.使用OpenCV"></a>2.使用OpenCV</h4><p>好吧，在这里您可以调整直方图的值及其bin值，使其看起来像x，y坐标，以便可以使用<code>cv.line()</code>或<code>cv.polyline()</code>函数绘制它以生成与上述相同的图像。OpenCV-Python2官方示例已经提供了此功能。检查示例<code>/python/hist.py</code>中的代码。</p>
<h3 id="掩膜的应用"><a href="#掩膜的应用" class="headerlink" title="掩膜的应用"></a>掩膜的应用</h3><p>我们使用<code>cv.calcHist()</code>查找完整图像的直方图。如果要查找图像某些区域的直方图怎么办？只需在要查找直方图的区域上创建白色的蒙版图像，否则创建黑色。然后通过这个作为面具。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(<span class="string">'home.jpg'</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># create a mask</span></span><br><span class="line">mask = np.zeros(img.shape[:<span class="number">2</span>], np.uint8)</span><br><span class="line">mask[<span class="number">100</span>:<span class="number">300</span>, <span class="number">100</span>:<span class="number">400</span>] = <span class="number">255</span></span><br><span class="line">masked_img = cv.bitwise_and(img,img,mask = mask)</span><br><span class="line"><span class="comment"># Calculate histogram with mask and without mask</span></span><br><span class="line"><span class="comment"># Check third argument for mask</span></span><br><span class="line">hist_full = cv.calcHist([img],[<span class="number">0</span>],<span class="literal">None</span>,[<span class="number">256</span>],[<span class="number">0</span>,<span class="number">256</span>])</span><br><span class="line">hist_mask = cv.calcHist([img],[<span class="number">0</span>],mask,[<span class="number">256</span>],[<span class="number">0</span>,<span class="number">256</span>])</span><br><span class="line">plt.subplot(<span class="number">221</span>), plt.imshow(img, <span class="string">'gray'</span>)</span><br><span class="line">plt.subplot(<span class="number">222</span>), plt.imshow(mask,<span class="string">'gray'</span>)</span><br><span class="line">plt.subplot(<span class="number">223</span>), plt.imshow(masked_img, <span class="string">'gray'</span>)</span><br><span class="line">plt.subplot(<span class="number">224</span>), plt.plot(hist_full), plt.plot(hist_mask)</span><br><span class="line">plt.xlim([<span class="number">0</span>,<span class="number">256</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/histogram_masking.jpg" alt></p>
<p>查看结果。在直方图中，蓝线表示完整图像的直方图，绿线表示遮蔽区域的直方图。</p>
<h2 id="直方图-2：直方图均衡"><a href="#直方图-2：直方图均衡" class="headerlink" title="直方图-2：直方图均衡"></a>直方图-2：直方图均衡</h2><h3 id="目标-13"><a href="#目标-13" class="headerlink" title="目标"></a>目标</h3><ul>
<li>我们将学习直方图均衡化的概念，并将其用于改善图像的对比度。</li>
</ul>
<h3 id="理论-6"><a href="#理论-6" class="headerlink" title="理论"></a>理论</h3><p>考虑一个图像，其像素值仅限于特定的值范围。例如，较亮的图像会将所有像素限制在较高的值。但是，好的图像将具有来自图像所有区域的像素。因此，您需要将此直方图拉伸到两端（如下图所示，来自维基百科），这就是直方图均衡化的作用（简单来说）。通常，这可以提高图像的对比度。</p>
<p><img src="/images/histogram_equalization.png" alt></p>
<p>在这里我们将看到其Numpy实现。之后，我们将看到OpenCV功能</p>
<p>您可以看到直方图位于较亮的区域。我们需要全方位的服务。为此，我们需要一个转换函数，该函数将较亮区域中的输入像素映射到整个区域中的输出像素。这就是直方图均衡化的作用。</p>
<p>现在，我们找到最小的直方图值（不包括0）并应用Wiki页面中给出的直方图均衡方程。但是我在这里使用了Numpy的masked array概念数组。对于掩码数组，所有操作都在非掩码元素上执行。您可以从有关屏蔽数组的Numpy文档中了解有关此内容的更多信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cdf_m = np.ma.masked_equal(cdf,<span class="number">0</span>)</span><br><span class="line">cdf_m = (cdf_m - cdf_m.min())*<span class="number">255</span>/(cdf_m.max()-cdf_m.min())</span><br><span class="line">cdf = np.ma.filled(cdf_m,<span class="number">0</span>).astype(<span class="string">'uint8'</span>)</span><br></pre></td></tr></table></figure>

<p>现在我们有了查找表，该表为我们提供了有关每个输入像素值的输出像素值是什么的信息。因此，我们仅应用变换。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img2 = cdf[img]</span><br></pre></td></tr></table></figure>

<p>现在我们像以前一样计算它的直方图和cdf（您这样做），结果如下所示：</p>
<p><img src="/images/histeq_numpy2.jpg" alt></p>
<p>另一个重要特征是，即使图像是较暗的图像（而不是我们使用的较亮的图像），在均衡后，我们将获得与获得的图像几乎相同的图像。结果，它被用作“参考工具”，以使所有图像具有相同的照明条件。在许多情况下这很有用。例如，在人脸识别中，在训练人脸数据之前，将人脸图像进行直方图均衡，以使它们全部具有相同的光照条件。</p>
<h3 id="OpenCV中的直方图均衡"><a href="#OpenCV中的直方图均衡" class="headerlink" title="OpenCV中的直方图均衡"></a>OpenCV中的直方图均衡</h3><p>OpenCV具有执行此操作的功能<code>cv.equalizeHist()</code>。它的输入只是灰度图像，输出是我们的直方图均衡图像。</p>
<p>下面是一个简单的代码片段，显示了它与我们使用的同一图像的用法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(<span class="string">'wiki.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">equ = cv.equalizeHist(img)</span><br><span class="line">res = np.hstack((img,equ)) <span class="comment">#stacking images side-by-side</span></span><br><span class="line">cv.imwrite(<span class="string">'res.png'</span>,res)</span><br></pre></td></tr></table></figure>

<p>因此，现在您可以在不同的光照条件下拍摄不同的图像，对其进行均衡并检查结果。</p>
<p>当图像的直方图限制在特定区域时，直方图均衡化效果很好。在直方图覆盖较大区域（即同时存在亮像素和暗像素）的强度变化较大的地方，效果不好。请检查其他资源中的SOF链接。</p>
<h3 id="CLAHE（对比度受限的自适应直方图均衡）"><a href="#CLAHE（对比度受限的自适应直方图均衡）" class="headerlink" title="CLAHE（对比度受限的自适应直方图均衡）"></a>CLAHE（对比度受限的自适应直方图均衡）</h3><p>我们刚刚看到的第一个直方图均衡化考虑了图像的整体对比度。在许多情况下，这不是一个好主意。例如，下图显示了输入图像及其在全局直方图均衡后的结果。</p>
<p><img src="/images/clahe_1.jpg" alt></p>
<p>直方图均衡后，背景对比度确实得到了改善。但是在两个图像中比较雕像的脸。由于亮度过高，我们在那里丢失了大多数信息。这是因为它的直方图不像我们在前面的案例中所看到的那样局限于特定区域（尝试绘制输入图像的直方图，您将获得更多的直觉）。</p>
<p>因此，为了解决这个问题，使用了自适应直方图均衡。在这种情况下，图像被分成称为“tiles”的小块（在OpenCV中，tileSize默认为8x8）。然后，像往常一样对这些块中的每一个进行直方图均衡。因此，在较小的区域中，直方图将局限于一个较小的区域（除非有噪声）。如果有噪音，它将被放大。为了避免这种情况，应用了对比度限制。如果任何直方图bin超过指定的对比度限制（在OpenCV中默认为40），则在应用直方图均衡之前，将这些像素裁剪并均匀地分布到其他bin。均衡后，要消除图块边界中的伪影，请应用双线性插值。</p>
<p>下面的代码片段显示了如何在OpenCV中应用CLAHE：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">'tsukuba_l.png'</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># create a CLAHE object (Arguments are optional).</span></span><br><span class="line">clahe = cv.createCLAHE(clipLimit=<span class="number">2.0</span>, tileGridSize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">cl1 = clahe.apply(img)</span><br><span class="line">cv.imwrite(<span class="string">'clahe_2.jpg'</span>,cl1)</span><br></pre></td></tr></table></figure>

<p>查看下面的结果，并将其与上面的结果进行比较，尤其是雕像区域：</p>
<p><img src="/images/clahe_2.jpg" alt></p>
<h2 id="直方图-3：2D直方图"><a href="#直方图-3：2D直方图" class="headerlink" title="直方图-3：2D直方图"></a>直方图-3：2D直方图</h2><h3 id="目标-14"><a href="#目标-14" class="headerlink" title="目标"></a>目标</h3><ul>
<li>在本章中，我们将学习查找和绘制2D直方图。这将在以后的章节中有所帮助。</li>
</ul>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>在第一篇文章中，我们计算并绘制了一维直方图。之所以称为一维，是因为我们仅考虑一个特征，即像素的灰度强度值。但是在二维直方图中，您要考虑两个特征。通常，它用于查找颜色直方图，其中两个特征是每个像素的色相和饱和度值。</p>
<p>已经有一个python样本<code>（samples/python/color_histogram.py）</code>用于查找颜色直方图。我们将尝试了解如何创建这种颜色直方图，这对于理解诸如直方图反投影之类的更多主题将很有用。</p>
<h3 id="OpenCV中的2D直方图"><a href="#OpenCV中的2D直方图" class="headerlink" title="OpenCV中的2D直方图"></a>OpenCV中的2D直方图</h3><p>它非常简单，并且使用相同的函数<code>cv.calcHist()</code>进行计算。<strong>对于颜色直方图，我们需要将图像从<code>BGR</code>转换为<code>HSV</code></strong>。（请记住，<strong>对于一维直方图，我们从BGR转换为灰度</strong>）。对于2D直方图，其参数将进行如下修改：</p>
<ul>
<li>channels = [0,1]， 因为我们需要同时处理H和S平面。</li>
<li>bins = [180,256] 对于H平面为180，对于S平面为256。</li>
<li>ranges = [0,180,0,256] 色相值介于0和180之间，饱和度介于0和256之间。</li>
</ul>
<p>现在检查以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">'home.jpg'</span>)</span><br><span class="line">hsv = cv.cvtColor(img,cv.COLOR_BGR2HSV)</span><br><span class="line">hist = cv.calcHist([hsv], [<span class="number">0</span>, <span class="number">1</span>], <span class="literal">None</span>, [<span class="number">180</span>, <span class="number">256</span>], [<span class="number">0</span>, <span class="number">180</span>, <span class="number">0</span>, <span class="number">256</span>])</span><br></pre></td></tr></table></figure>

<h3 id="numpy中的2D直方图"><a href="#numpy中的2D直方图" class="headerlink" title="numpy中的2D直方图"></a>numpy中的2D直方图</h3><p>Numpy还为此提供了一个特定功能：<code>np.histogram2d()</code>。（请记住，对于一维直方图，我们使用了<code>np.histogram()</code>）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'home.jpg'</span>)</span><br><span class="line">hsv = cv.cvtColor(img,cv.COLOR_BGR2HSV)</span><br><span class="line">hist, xbins, ybins = np.histogram2d(h.ravel(),s.ravel(),[<span class="number">180</span>,<span class="number">256</span>],[[<span class="number">0</span>,<span class="number">180</span>],[<span class="number">0</span>,<span class="number">256</span>]])</span><br></pre></td></tr></table></figure>

<h3 id="绘制2D直方图"><a href="#绘制2D直方图" class="headerlink" title="绘制2D直方图"></a>绘制2D直方图</h3><h4 id="方法-1：使用cv-imshow"><a href="#方法-1：使用cv-imshow" class="headerlink" title="方法-1：使用cv.imshow()"></a>方法-1：使用<code>cv.imshow()</code></h4><p>我们得到的结果是尺寸为180x256的二维数组。因此，可以使用<code>cv.imshow()</code>函数像平常一样显示它们。它将是一幅灰度图像，除非您知道不同颜色的色相值，否则不会对其中的颜色有太多了解。</p>
<h4 id="方法-2：使用Matplotlib"><a href="#方法-2：使用Matplotlib" class="headerlink" title="方法-2：使用Matplotlib"></a>方法-2：使用<code>Matplotlib</code></h4><p>我们可以使用<code>matplotlib.pyplot.imshow()</code>函数绘制具有不同颜色图的2D直方图。它使我们对不同的像素密度有了更好的了解。但是，这也并不能使我们一眼就能知道是什么颜色，除非您知道不同颜色的色相值。我还是更喜欢这种方法。它简单而更好。</p>
<blockquote>
<p>注意:使用此功能时，请记住，插值标记应最接近以获得更好的结果。</p>
</blockquote>
<p>代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'home.jpg'</span>)</span><br><span class="line">hsv = cv.cvtColor(img,cv.COLOR_BGR2HSV)</span><br><span class="line">hist = cv.calcHist( [hsv], [<span class="number">0</span>, <span class="number">1</span>], <span class="literal">None</span>, [<span class="number">180</span>, <span class="number">256</span>], [<span class="number">0</span>, <span class="number">180</span>, <span class="number">0</span>, <span class="number">256</span>] )</span><br><span class="line">plt.imshow(hist,interpolation = <span class="string">'nearest'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/2dhist_matplotlib.jpg" alt></p>
<p>在直方图中，您可以在H = 100和S = 200附近看到一些较高的值。它对应于天空的蓝色。同样，在H = 25和S = 100附近可以看到另一个峰值。它对应于宫殿的黄色。您可以使用GIMP等任何图像编辑工具进行验证。</p>
<h4 id="方法3：OpenCV示例样式！"><a href="#方法3：OpenCV示例样式！" class="headerlink" title="方法3：OpenCV示例样式！"></a>方法3：OpenCV示例样式！</h4><p>OpenCV-Python2示例中有一个颜色直方图的示例代码<code>（samples/python/color_histogram.py）</code>。如果运行代码，则可以看到直方图也显示了相应的颜色。或者简单地，它输出颜色编码的直方图。其结果非常好（尽管您需要添加额外的线束）。</p>
<p>在该代码中，作者在HSV中创建了一个颜色图。然后将其转换为BGR。将所得的直方图图像与此颜色图相乘。他还使用一些预处理步骤来删除小的孤立像素，从而获得良好的直方图。</p>
<p>我将它留给读者来运行代码，对其进行分析并拥有自己的解决方法。下面是与上面相同的图像的代码输出：</p>
<p><img src="/images/2dhist_opencv.jpg" alt></p>
<p>您可以在直方图中清楚地看到存在什么颜色，那里是蓝色，那里是黄色，并且由于棋盘而有些白色。不错！</p>
<h2 id="直方图-4：直方图反投影"><a href="#直方图-4：直方图反投影" class="headerlink" title="直方图-4：直方图反投影"></a>直方图-4：直方图反投影</h2><h3 id="目标-15"><a href="#目标-15" class="headerlink" title="目标"></a>目标</h3><ul>
<li>在本章中，我们将学习直方图反投影。</li>
</ul>
<h3 id="理论-7"><a href="#理论-7" class="headerlink" title="理论"></a>理论</h3><p>它是由Michael J.Swain和Dana H.Ballard在他们的论文“ 通过颜色直方图索引”中提出的。</p>
<p>简单来说到底是什么？它用于图像分割或在图像中查找感兴趣的对象。简而言之，它创建的图像大小与输入图像相同（但只有一个通道），其中每个像素对应于该像素属于我们物体的概率。用更简单的话来说，与其余部分相比，输出图像将使我们感兴趣的对象具有更多的白色。好吧，这是一个直观的解释。（我无法使其更简单）。直方图反投影与<code>camshift</code>算法等配合使用。</p>
<p>我们该怎么做呢 ？我们创建一个图像的直方图，其中包含我们感兴趣的对象（在我们的示例中是地面，离开播放器等）。对象应尽可能填充图像以获得更好的效果。而且颜色直方图比灰度直方图更可取，因为对象的颜色比其灰度强度是定义对象的更好方法。然后，我们将该直方图“反向投影”到需要找到对象的测试图像上，换句话说，我们计算出属于地面的每个像素的概率并将其显示出来。在适当的阈值下产生的输出仅使我们有基础。</p>
<h3 id="Numpy中的算法"><a href="#Numpy中的算法" class="headerlink" title="Numpy中的算法"></a>Numpy中的算法</h3><p>1.首先，我们需要计算我们要查找的对象（使其为“ M”）和要搜索的图像（使其为“ I”）的颜色直方图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cvfrom matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment">#roi is the object or region of object we need to find</span></span><br><span class="line">roi = cv.imread(<span class="string">'rose_red.png'</span>)</span><br><span class="line">hsv = cv.cvtColor(roi,cv.COLOR_BGR2HSV)</span><br><span class="line"><span class="comment">#target is the image we search in</span></span><br><span class="line">target = cv.imread(<span class="string">'rose.png'</span>)</span><br><span class="line">hsvt = cv.cvtColor(target,cv.COLOR_BGR2HSV)</span><br><span class="line"><span class="comment"># Find the histograms using calcHist. Can be done with np.histogram2d also</span></span><br><span class="line">M = cv.calcHist([hsv],[<span class="number">0</span>, <span class="number">1</span>], <span class="literal">None</span>, [<span class="number">180</span>, <span class="number">256</span>], [<span class="number">0</span>, <span class="number">180</span>, <span class="number">0</span>, <span class="number">256</span>] )</span><br><span class="line">I = cv.calcHist([hsvt],[<span class="number">0</span>, <span class="number">1</span>], <span class="literal">None</span>, [<span class="number">180</span>, <span class="number">256</span>], [<span class="number">0</span>, <span class="number">180</span>, <span class="number">0</span>, <span class="number">256</span>] )</span><br></pre></td></tr></table></figure>

<p>2.求出比率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">h,s,v = cv.split(hsvt)</span><br><span class="line">B = R[h.ravel(),s.ravel()]</span><br><span class="line">B = np.minimum(B,<span class="number">1</span>)</span><br><span class="line">B = B.reshape(hsvt.shape[:<span class="number">2</span>])</span><br></pre></td></tr></table></figure>

<p>3.在对圆盘应用卷积</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">disc = cv.getStructuringElement(cv.MORPH_ELLIPSE,(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">cv.filter2D(B,<span class="number">-1</span>,disc,B)</span><br><span class="line">B = np.uint8(B)</span><br><span class="line">cv.normalize(B,B,<span class="number">0</span>,<span class="number">255</span>,cv.NORM_MINMAX)</span><br></pre></td></tr></table></figure>

<p>现在最大强度的位置给了我们物体的位置。如果我们期望图像中有一个区域，则对合适的值进行阈值处理会得到不错的结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ret,thresh = cv.threshold(B,<span class="number">50</span>,<span class="number">255</span>,<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h3 id="OpenCV中的反投影"><a href="#OpenCV中的反投影" class="headerlink" title="OpenCV中的反投影"></a>OpenCV中的反投影</h3><p>OpenCV提供了一个内置函数<code>cv.calcBackProject()</code>。它的参数与<code>cv.calcHist()</code>函数几乎相同。它的参数之一是直方图，它是对象的直方图，我们必须找到它。另外，在传递给<code>backproject</code>函数之前，应对对象直方图进行标准化。它返回概率图像。然后，我们将图像与磁盘内核卷积并应用阈值。下面是我的代码和输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">roi = cv.imread(<span class="string">'rose_red.png'</span>)</span><br><span class="line">hsv = cv.cvtColor(roi,cv.COLOR_BGR2HSV)</span><br><span class="line">target = cv.imread(<span class="string">'rose.png'</span>)</span><br><span class="line">hsvt = cv.cvtColor(target,cv.COLOR_BGR2HSV)</span><br><span class="line"><span class="comment"># calculating object histogram</span></span><br><span class="line">roihist = cv.calcHist([hsv],[<span class="number">0</span>, <span class="number">1</span>], <span class="literal">None</span>, [<span class="number">180</span>, <span class="number">256</span>], [<span class="number">0</span>, <span class="number">180</span>, <span class="number">0</span>, <span class="number">256</span>] )</span><br><span class="line"><span class="comment"># normalize histogram and apply backprojection</span></span><br><span class="line">cv.normalize(roihist,roihist,<span class="number">0</span>,<span class="number">255</span>,cv.NORM_MINMAX)</span><br><span class="line">dst = cv.calcBackProject([hsvt],[<span class="number">0</span>,<span class="number">1</span>],roihist,[<span class="number">0</span>,<span class="number">180</span>,<span class="number">0</span>,<span class="number">256</span>],<span class="number">1</span>)</span><br><span class="line"><span class="comment"># Now convolute with circular disc</span></span><br><span class="line">disc = cv.getStructuringElement(cv.MORPH_ELLIPSE,(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">cv.filter2D(dst,<span class="number">-1</span>,disc,dst)</span><br><span class="line"><span class="comment"># threshold and binary AND</span></span><br><span class="line">ret,thresh = cv.threshold(dst,<span class="number">50</span>,<span class="number">255</span>,<span class="number">0</span>)</span><br><span class="line">thresh = cv.merge((thresh,thresh,thresh))</span><br><span class="line">res = cv.bitwise_and(target,thresh)</span><br><span class="line">res = np.vstack((target,thresh,res))</span><br><span class="line">cv.imwrite(<span class="string">'res.jpg'</span>,res)</span><br></pre></td></tr></table></figure>

<p>以下是我处理过的一个示例。我将蓝色矩形内的区域用作示例对象，我想提取整个地面。</p>
<p><img src="/images/backproject_opencv.jpg" alt></p>
<h1 id="OpenCV中的图像转换"><a href="#OpenCV中的图像转换" class="headerlink" title="OpenCV中的图像转换"></a>OpenCV中的图像转换</h1><h2 id="傅立叶变换"><a href="#傅立叶变换" class="headerlink" title="傅立叶变换"></a>傅立叶变换</h2><h3 id="目标-16"><a href="#目标-16" class="headerlink" title="目标"></a>目标</h3><ul>
<li>使用OpenCV查找图像的傅立叶变换</li>
<li>利用Numpy中可用的FFT功能</li>
<li>傅立叶变换的一些应用</li>
<li>我们将看到以下函数：<code>cv.dft()</code>，<code>cv.idft()</code>等</li>
</ul>
<h3 id="理论-8"><a href="#理论-8" class="headerlink" title="理论"></a>理论</h3><p>傅立叶变换用于分析各种滤波器的频率特性。对于图像，使用2D离散傅里叶变换（DFT）查找频域。快速算法称为快速傅立叶变换（FFT）用于计算DFT。关于这些的详细信息可以在任何图像处理或信号处理教科书中找到。请参阅其他资源_部分。</p>
<p>对于正弦信号$x(t) = Asin(2{\pi}ft)$，我们可以说F是信号的频率，如果采用其频域，则可以看到的尖峰F。如果对信号进行采样以形成离散信号，我们将获得相同的频域，但在$[-{\pi},{\pi}]$或$[0,2{\pi}]$（或对于N点DFT为是周期性的$[0,N]$）。您可以将图像视为在两个方向上采样的信号。因此，在X和Y方向都进行傅立叶变换，可以得到图像的频率表示。</p>
<p>更直观地说，对于正弦信号，如果振幅在短时间内变化如此之快，则可以说它是高频信号。如果变化缓慢，则为低频信号。您可以将相同的想法扩展到图像。图像中的振幅在哪里急剧变化？在边缘点或噪音。因此，可以说边缘和噪声是图像中的高频内容。如果幅度没有太大变化，则它是低频分量。（一些链接已添加到“其他资源”，其中通过示例直观地说明了频率变换）。</p>
<p>现在，我们将看到如何找到傅立叶变换。</p>
<h3 id="numpy中的傅立叶变换"><a href="#numpy中的傅立叶变换" class="headerlink" title="numpy中的傅立叶变换"></a>numpy中的傅立叶变换</h3><p>首先，我们将看到如何使用Numpy查找傅立叶变换。Numpy具有FFT软件包来执行此操作。<code>np.fft.fft2()</code>为我们提供了频率转换，它将是一个复杂的数组。它的第一个参数是输入图像，即灰度图像。第二个参数是可选的，它决定输出数组的大小。如果它大于输入图像的大小，则在计算FFT之前用零填充输入图像。如果小于输入图像，将裁切输入图像。如果未传递任何参数，则输出数组的大小将与输入的大小相同。</p>
<p>现在，一旦获得结果，零频率分量（DC分量）将位于左上角。如果要将其居中，则需要在两个方向结果移动。只需通过函数<code>np.fft.fftshift()</code>即可完成。（它更容易分析）。找到频率变换后，就可以找到幅度谱。<br>结果如下：</p>
<p><img src="/images/fft1.jpg" alt></p>
<p>看，您可以在中心看到更多白色区域，这表明低频内容更多。</p>
<p>因此，您找到了频率变换现在，您可以在频域中执行一些操作，例如高通滤波和重建图像，即找到逆DFT。为此，您只需用尺寸为60x60的矩形窗口遮罩即可消除低频。然后，使用np.fft.ifftshift（）应用反向移位，以使DC分量再次出现在左上角。然后使用np.ifft2（）函数找到逆FFT 。同样，结果将是一个复数。您可以采用其绝对值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">rows, cols = img.shape</span><br><span class="line">crow,ccol = rows//<span class="number">2</span> , cols//<span class="number">2</span></span><br><span class="line">fshift[crow<span class="number">-30</span>:crow+<span class="number">31</span>, ccol<span class="number">-30</span>:ccol+<span class="number">31</span>] = <span class="number">0</span></span><br><span class="line">f_ishift = np.fft.ifftshift(fshift)</span><br><span class="line">img_back = np.fft.ifft2(f_ishift)</span><br><span class="line">img_back = np.real(img_back)</span><br><span class="line">plt.subplot(<span class="number">131</span>),plt.imshow(img, cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Input Image'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">132</span>),plt.imshow(img_back, cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Image after HPF'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">133</span>),plt.imshow(img_back)</span><br><span class="line">plt.title(<span class="string">'Result in JET'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>Result look like below:</p>
<p><img src="/images/fft2.jpg" alt></p>
<p>结果表明高通滤波是边缘检测操作。这就是我们在“图像渐变”一章中看到的。这也表明大多数图像数据都存在于频谱的低频区域。无论如何，我们已经看到了如何在Numpy中找到DFT，IDFT等。现在，让我们看看如何在OpenCV中进行操作。</p>
<p>如果您仔细观察结果，尤其是最后一张JET颜色的图像，您会看到一些伪像（我用红色箭头标记的一个实例）。它在那里显示出一些波纹状结构，称为振铃效应。这是由我们用于遮罩的矩形窗口引起的。此蒙版转换为正弦形状，从而导致此问题。因此，矩形窗口不用于过滤。更好的选择是高斯Windows。</p>
<h3 id="OpenCV中的傅立叶变换"><a href="#OpenCV中的傅立叶变换" class="headerlink" title="OpenCV中的傅立叶变换"></a>OpenCV中的傅立叶变换</h3><p>OpenCV 为此提供了功能<code>cv.dft()</code>和<code>cv.idft()</code>。它返回与以前相同的结果，但是有两个通道。第一个通道将具有结果的实部，第二个通道将具有结果的虚部。输入的图像应首先转换为np.float32。我们将看到如何做。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'messi5.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">dft = cv.dft(np.float32(img),flags = cv.DFT_COMPLEX_OUTPUT)</span><br><span class="line">dft_shift = np.fft.fftshift(dft)</span><br><span class="line">magnitude_spectrum = <span class="number">20</span>*np.log(cv.magnitude(dft_shift[:,:,<span class="number">0</span>],dft_shift[:,:,<span class="number">1</span>]))</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img, cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Input Image'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(magnitude_spectrum, cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Magnitude Spectrum'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意:您还可以使用cv.cartToPolar（）一次返回大小和相位</p>
</blockquote>
<p>因此，现在我们必须进行逆DFT。在上面，我们创建了一个<code>HPF</code>，这次我们将看到如何去除图像中的高频内容，即我们将<code>LPF</code>应用于图像。实际上会使图像模糊。为此，我们首先创建一个在低频时具有高值（1）的蒙版，即，我们传递LF含量，并在HF区域传递0。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">rows, cols = img.shape</span><br><span class="line">crow,ccol = rows/<span class="number">2</span> , cols/<span class="number">2</span></span><br><span class="line"><span class="comment"># create a mask first, center square is 1, remaining all zeros</span></span><br><span class="line">mask = np.zeros((rows,cols,<span class="number">2</span>),np.uint8)</span><br><span class="line">mask[crow<span class="number">-30</span>:crow+<span class="number">30</span>, ccol<span class="number">-30</span>:ccol+<span class="number">30</span>] = <span class="number">1</span></span><br><span class="line"><span class="comment"># apply mask and inverse DFT</span></span><br><span class="line">fshift = dft_shift*mask</span><br><span class="line">f_ishift = np.fft.ifftshift(fshift)</span><br><span class="line">img_back = cv.idft(f_ishift)</span><br><span class="line">img_back = cv.magnitude(img_back[:,:,<span class="number">0</span>],img_back[:,:,<span class="number">1</span>])</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img, cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Input Image'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(img_back, cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Magnitude Spectrum'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/fft4.jpg" alt></p>
<blockquote>
<p>注意:像往常一样，OpenCV函数<code>cv.dft()</code>和<code>cv.idft()</code>比Numpy对应函数要快。但是Numpy功能更加人性化。有关性能问题的更多详细信息，请参阅以下部分。</p>
</blockquote>
<h3 id="DFT的性能优化"><a href="#DFT的性能优化" class="headerlink" title="DFT的性能优化"></a>DFT的性能优化</h3><p>对于某些阵列大小，DFT计算的性能更好。当阵列大小为2的幂时，它是最快的。大小为2、3和5的乘积的数组也得到了有效处理。因此，如果您担心代码的性能，可以在找到DFT之前将数组的大小修改为任何最佳大小（通过填充零）。对于OpenCV，您必须手动填充零。但是对于Numpy，您可以指定FFT计算的新大小，它将自动为您填充零。</p>
<p>那么我们如何找到这个最佳尺寸呢？OpenCV 为此提供了一个函数<code>cv.getOptimalDFTSize()</code>。它适用于<code>cv.dft()</code>和<code>np.fft.fft2()</code>。让我们使用<code>IPython magic</code>命令<code>timeit</code>检查它们的性能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">16</span>]: img = cv.imread(<span class="string">'messi5.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">In [<span class="number">17</span>]: rows,cols = img.shape</span><br><span class="line">In [<span class="number">18</span>]: print(<span class="string">"&#123;&#125; &#123;&#125;"</span>.format(rows,cols))</span><br><span class="line"><span class="number">342</span> <span class="number">548</span></span><br><span class="line">In [<span class="number">19</span>]: nrows = cv.getOptimalDFTSize(rows)</span><br><span class="line">In [<span class="number">20</span>]: ncols = cv.getOptimalDFTSize(cols)</span><br><span class="line">In [<span class="number">21</span>]: print(<span class="string">"&#123;&#125; &#123;&#125;"</span>.format(nrows,ncols))</span><br><span class="line"><span class="number">360</span> <span class="number">576</span></span><br></pre></td></tr></table></figure>

<p>参见，将大小（342,548）修改为（360，576）。现在让我们用零填充（对于OpenCV），并找到其DFT计算性能。您可以通过创建一个新的大零数组并将数据复制到其中来完成此操作，或者使用<code>cv.copyMakeBorder()</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nimg = np.zeros((nrows,ncols))</span><br><span class="line">nimg[:rows,:cols] = img</span><br></pre></td></tr></table></figure>

<p>或者：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">right = ncols - cols</span><br><span class="line">bottom = nrows - rows</span><br><span class="line">bordertype = cv.BORDER_CONSTANT <span class="comment">#just to avoid line breakup in PDF file</span></span><br><span class="line">nimg = cv.copyMakeBorder(img,<span class="number">0</span>,bottom,<span class="number">0</span>,right,bordertype, value = <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>现在，我们计算Numpy函数的DFT性能比较：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">22</span>]: %timeit fft1 = np.fft.fft2(img)</span><br><span class="line"><span class="number">10</span> loops, best of <span class="number">3</span>: <span class="number">40.9</span> ms per loop</span><br><span class="line">In [<span class="number">23</span>]: %timeit fft2 = np.fft.fft2(img,[nrows,ncols])</span><br><span class="line"><span class="number">100</span> loops, best of <span class="number">3</span>: <span class="number">10.4</span> ms per loop</span><br></pre></td></tr></table></figure>

<p>它显示了4倍的加速。现在，我们将尝试使用OpenCV函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">24</span>]: %timeit dft1= cv.dft(np.float32(img),flags=cv.DFT_COMPLEX_OUTPUT)</span><br><span class="line"><span class="number">100</span> loops, best of <span class="number">3</span>: <span class="number">13.5</span> ms per loop</span><br><span class="line">In [<span class="number">27</span>]: %timeit dft2= cv.dft(np.float32(nimg),flags=cv.DFT_COMPLEX_OUTPUT)</span><br><span class="line"><span class="number">100</span> loops, best of <span class="number">3</span>: <span class="number">3.11</span> ms per loop</span><br></pre></td></tr></table></figure>

<p>它还显示了4倍的加速。您还可以看到OpenCV函数比Numpy函数快3倍左右。也可以对逆FFT进行测试，这留给您练习。</p>
<h2 id="为什么拉普拉斯算子是高通滤波器？"><a href="#为什么拉普拉斯算子是高通滤波器？" class="headerlink" title="为什么拉普拉斯算子是高通滤波器？"></a>为什么拉普拉斯算子是高通滤波器？</h2><p>在论坛上提出了类似的问题。问题是，为什么拉普拉斯算子是高通滤波器？为什么Sobel是HPF？等等。第一个得到的答案是傅里叶变换。只需对Laplacian进行傅立叶变换，以获得更大的FFT大小。分析一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># simple averaging filter without scaling parameter</span></span><br><span class="line">mean_filter = np.ones((<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"><span class="comment"># creating a gaussian filter</span></span><br><span class="line">x = cv.getGaussianKernel(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">gaussian = x*x.T</span><br><span class="line"><span class="comment"># different edge detecting filters</span></span><br><span class="line"><span class="comment"># scharr in x-direction</span></span><br><span class="line">scharr = np.array([[<span class="number">-3</span>, <span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">                   [<span class="number">-10</span>,<span class="number">0</span>,<span class="number">10</span>],</span><br><span class="line">                   [<span class="number">-3</span>, <span class="number">0</span>, <span class="number">3</span>]])</span><br><span class="line"><span class="comment"># sobel in x direction</span></span><br><span class="line">sobel_x= np.array([[<span class="number">-1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                   [<span class="number">-2</span>, <span class="number">0</span>, <span class="number">2</span>],</span><br><span class="line">                   [<span class="number">-1</span>, <span class="number">0</span>, <span class="number">1</span>]])</span><br><span class="line"><span class="comment"># sobel in y direction</span></span><br><span class="line">sobel_y= np.array([[<span class="number">-1</span>,<span class="number">-2</span>,<span class="number">-1</span>],</span><br><span class="line">                   [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                   [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line"><span class="comment"># laplacian</span></span><br><span class="line">laplacian=np.array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                    [<span class="number">1</span>,<span class="number">-4</span>, <span class="number">1</span>],</span><br><span class="line">                    [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line">filters = [mean_filter, gaussian, laplacian, sobel_x, sobel_y, scharr]</span><br><span class="line">filter_name = [<span class="string">'mean_filter'</span>, <span class="string">'gaussian'</span>,<span class="string">'laplacian'</span>, <span class="string">'sobel_x'</span>, \</span><br><span class="line">                <span class="string">'sobel_y'</span>, <span class="string">'scharr_x'</span>]</span><br><span class="line">fft_filters = [np.fft.fft2(x) <span class="keyword">for</span> x <span class="keyword">in</span> filters]</span><br><span class="line">fft_shift = [np.fft.fftshift(y) <span class="keyword">for</span> y <span class="keyword">in</span> fft_filters]</span><br><span class="line">mag_spectrum = [np.log(np.abs(z)+<span class="number">1</span>) <span class="keyword">for</span> z <span class="keyword">in</span> fft_shift]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>),plt.imshow(mag_spectrum[i],cmap = <span class="string">'gray'</span>)</span><br><span class="line">    plt.title(filter_name[i]), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/fft5.jpg" alt></p>
<p>从图像中，您可以看到每个内核阻止的频率区域以及它经过的区域。从这些信息中，我们可以说出为什么每个内核都是HPF或LPF</p>
<h1 id="模板匹配"><a href="#模板匹配" class="headerlink" title="模板匹配"></a>模板匹配</h1><h2 id="目标-17"><a href="#目标-17" class="headerlink" title="目标"></a>目标</h2><ul>
<li>使用模板匹配在图像中查找对象</li>
<li>您将看到以下功能：<code>cv.matchTemplate()</code>，<code>cv.minMaxLoc()</code></li>
</ul>
<h2 id="理论-9"><a href="#理论-9" class="headerlink" title="理论"></a>理论</h2><p>模板匹配是一种用于在较大图像中搜索和查找模板图像位置的方法。为此，OpenCV带有一个函数<code>cv.matchTemplate()</code>。它只是在输入图像上滑动模板图像（如2D卷积），然后在模板图像下比较模板和输入图像的补丁。OpenCV中实现了几种比较方法。（您可以检查文档以了解更多详细信息）。它返回一个灰度图像，其中每个像素表示该像素的邻域与模板匹配多少。</p>
<p>如果输入图像的尺寸为（WxH），模板图像的尺寸为（wxh），则输出图像的尺寸将为（W-w + 1，H-h + 1）。获得结果后，可以使用<code>cv.minMaxLoc()</code>函数查找最大/最小值在哪里。将其作为矩形的左上角，并以（w，h）作为矩形的宽度和高度。该矩形是您模板的区域。</p>
<blockquote>
<p>注意:如果使用<code>cv.TM_SQDIFF</code>作为比较方法，则最小值提供最佳匹配。</p>
</blockquote>
<h2 id="OpenCV中的模板匹配"><a href="#OpenCV中的模板匹配" class="headerlink" title="OpenCV中的模板匹配"></a>OpenCV中的模板匹配</h2><p>作为示例，我们将在梅西的照片中搜索他的脸。所以我创建了一个模板，如下所示：<br><img src="/images/messi_face.jpg" alt><br>我们将尝试所有比较方法，以便我们可以看到它们的结果如何：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'messi5.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">img2 = img.copy()</span><br><span class="line">template = cv.imread(<span class="string">'template.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">w, h = template.shape[::<span class="number">-1</span>]</span><br><span class="line"><span class="comment"># All the 6 methods for comparison in a list</span></span><br><span class="line">methods = [<span class="string">'cv.TM_CCOEFF'</span>, <span class="string">'cv.TM_CCOEFF_NORMED'</span>, <span class="string">'cv.TM_CCORR'</span>,</span><br><span class="line">            <span class="string">'cv.TM_CCORR_NORMED'</span>, <span class="string">'cv.TM_SQDIFF'</span>, <span class="string">'cv.TM_SQDIFF_NORMED'</span>]</span><br><span class="line"><span class="keyword">for</span> meth <span class="keyword">in</span> methods:</span><br><span class="line">    img = img2.copy()</span><br><span class="line">    method = eval(meth)</span><br><span class="line">    <span class="comment"># Apply template Matching</span></span><br><span class="line">    res = cv.matchTemplate(img,template,method)</span><br><span class="line">    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)</span><br><span class="line">    <span class="comment"># If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum</span></span><br><span class="line">    <span class="keyword">if</span> method <span class="keyword">in</span> [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:</span><br><span class="line">        top_left = min_loc</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        top_left = max_loc</span><br><span class="line">    bottom_right = (top_left[<span class="number">0</span>] + w, top_left[<span class="number">1</span>] + h)</span><br><span class="line">    cv.rectangle(img,top_left, bottom_right, <span class="number">255</span>, <span class="number">2</span>)</span><br><span class="line">    plt.subplot(<span class="number">121</span>),plt.imshow(res,cmap = <span class="string">'gray'</span>)</span><br><span class="line">    plt.title(<span class="string">'Matching Result'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">    plt.subplot(<span class="number">122</span>),plt.imshow(img,cmap = <span class="string">'gray'</span>)</span><br><span class="line">    plt.title(<span class="string">'Detected Point'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">    plt.suptitle(meth)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<p>结果如下：</p>
<ul>
<li><strong>cv.TM_CCOEFF</strong></li>
</ul>
<p><img src="/images/template_ccoeff_1.jpg" alt></p>
<ul>
<li><strong>cv.TM_CCOEFF_NORMED</strong></li>
</ul>
<p><img src="/images/template_ccoeffn_2.jpg" alt></p>
<ul>
<li><strong>cv.TM_CCORR</strong></li>
</ul>
<p><img src="/images/template_ccorr_3.jpg" alt></p>
<ul>
<li><strong>cv.TM_CCORR_NORMED</strong></li>
</ul>
<p><img src="/images/template_ccorrn_4.jpg" alt></p>
<ul>
<li><strong>cv.TM_SQDIFF</strong></li>
</ul>
<p><img src="/images/template_sqdiff_5.jpg" alt></p>
<ul>
<li><strong>cv.TM_SQDIFF_NORMED</strong><br><img src="/images/template_sqdiffn_6.jpg" alt></li>
</ul>
<h2 id="模板与多个对象匹配"><a href="#模板与多个对象匹配" class="headerlink" title="模板与多个对象匹配"></a>模板与多个对象匹配</h2><p>在上一节中，我们在图像中搜索了梅西的脸，该脸在图像中仅出现一次。假设您正在搜索具有多次出现的对象，则<code>cv.minMaxLoc()</code>不会为您提供所有位置。在这种情况下，我们将使用阈值。因此，在此示例中，我们将使用著名游戏Mario的屏幕截图，并在其中找到硬币。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img_rgb = cv.imread(<span class="string">'mario.png'</span>)</span><br><span class="line">img_gray = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)</span><br><span class="line">template = cv.imread(<span class="string">'mario_coin.png'</span>,<span class="number">0</span>)</span><br><span class="line">w, h = template.shape[::<span class="number">-1</span>]</span><br><span class="line">res = cv.matchTemplate(img_gray,template,cv.TM_CCOEFF_NORMED)</span><br><span class="line">threshold = <span class="number">0.8</span></span><br><span class="line">loc = np.where( res &gt;= threshold)</span><br><span class="line"><span class="keyword">for</span> pt <span class="keyword">in</span> zip(*loc[::<span class="number">-1</span>]):</span><br><span class="line">    cv.rectangle(img_rgb, pt, (pt[<span class="number">0</span>] + w, pt[<span class="number">1</span>] + h), (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line">cv.imwrite(<span class="string">'res.png'</span>,img_rgb)</span><br></pre></td></tr></table></figure>

<p><img src="/images/res_mario.jpg" alt></p>
<h1 id="霍夫线变换"><a href="#霍夫线变换" class="headerlink" title="霍夫线变换"></a>霍夫线变换</h1><h2 id="目标-18"><a href="#目标-18" class="headerlink" title="目标"></a>目标</h2><ul>
<li>我们将了解霍夫变换的概念。</li>
<li>我们将看到如何使用它来检测图像中的线条。</li>
<li>我们将看到以下函数：<code>cv.HoughLines()</code>，<code>cv.HoughLinesP()</code></li>
</ul>
<h2 id="理论-10"><a href="#理论-10" class="headerlink" title="理论"></a>理论</h2><p>如果可以用数学形式表示形状，则霍夫变换是一种检测任何形状的流行技术。即使形状有些破损或变形，也可以检测出形状。</p>
<h2 id="OpenCV中的霍夫变换"><a href="#OpenCV中的霍夫变换" class="headerlink" title="OpenCV中的霍夫变换"></a>OpenCV中的霍夫变换</h2><p>上面解释的所有内容都封装在OpenCV函数<code>cv.HoughLines()</code>中。第一个参数，输入图像应该是二进制图像，因此在应用霍夫变换之前，请应用阈值或使用Canny边缘检测。第二和第三参数是ρ和θ准确度。第四个参数是阈值，这意味着应该将其视为行的最低投票。请记住，票数取决于线上的点数。因此，它表示应检测到的最小线长。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img = cv.imread(cv.samples.findFile(<span class="string">'sudoku.png'</span>))</span><br><span class="line">gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line">edges = cv.Canny(gray,<span class="number">50</span>,<span class="number">150</span>,apertureSize = <span class="number">3</span>)</span><br><span class="line">lines = cv.HoughLines(edges,<span class="number">1</span>,np.pi/<span class="number">180</span>,<span class="number">200</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">    rho,theta = line[<span class="number">0</span>]</span><br><span class="line">    a = np.cos(theta)</span><br><span class="line">    b = np.sin(theta)</span><br><span class="line">    x0 = a*rho</span><br><span class="line">    y0 = b*rho</span><br><span class="line">    x1 = int(x0 + <span class="number">1000</span>*(-b))</span><br><span class="line">    y1 = int(y0 + <span class="number">1000</span>*(a))</span><br><span class="line">    x2 = int(x0 - <span class="number">1000</span>*(-b))</span><br><span class="line">    y2 = int(y0 - <span class="number">1000</span>*(a))</span><br><span class="line">    cv.line(img,(x1,y1),(x2,y2),(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>),<span class="number">2</span>)</span><br><span class="line">cv.imwrite(<span class="string">'houghlines3.jpg'</span>,img)</span><br></pre></td></tr></table></figure>

<p><img src="/images/houghlines3.jpg" alt></p>
<h2 id="概率霍夫变换"><a href="#概率霍夫变换" class="headerlink" title="概率霍夫变换"></a>概率霍夫变换</h2><p>在霍夫变换中，您可以看到即使对于带有两个参数的行，也需要大量的计算。概率霍夫变换是我们看到的霍夫变换的优化。它没有考虑所有要点。取而代之的是，它仅采用随机的点子集，足以进行线检测。只是我们必须降低阈值。参见下图，比较了霍夫空间中的霍夫变换和概率霍夫变换。（图片提供：Franck Bettinger的主页）</p>
<p>OpenCV的实现基于Matas，J.和Galambos，C.和Kittler，JV使用渐进式概率霍夫变换对行进行的稳健检测。使用的函数是<code>cv.HoughLinesP()</code>。它有两个新的论点。</p>
<ul>
<li>minLineLength-最小长度。小于此长度的线段将被拒绝。</li>
<li>maxLineGap-线段之间允许将它们视为一条线的最大间隙。<br>最好的是，它直接返回行的两个端点。在以前的情况下，您仅获得线的参数，并且必须找到所有点。在这里，一切都是直接而简单的。</li>
</ul>
<p><img src="/images/houghlines5.jpg" alt></p>
<h1 id="霍夫圆变换"><a href="#霍夫圆变换" class="headerlink" title="霍夫圆变换"></a>霍夫圆变换</h1><h2 id="目标-19"><a href="#目标-19" class="headerlink" title="目标"></a>目标</h2><p>在这一章当中，</p>
<ul>
<li>我们将学习使用霍夫变换在图像中查找圆。</li>
<li>我们将看到以下函数：<code>cv.HoughCircles（）</code></li>
</ul>
<h2 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">'opencv-logo-white.png'</span>,<span class="number">0</span>)</span><br><span class="line">img = cv.medianBlur(img,<span class="number">5</span>)</span><br><span class="line">cimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)</span><br><span class="line">circles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,<span class="number">1</span>,<span class="number">20</span>,</span><br><span class="line">                            param1=<span class="number">50</span>,param2=<span class="number">30</span>,minRadius=<span class="number">0</span>,maxRadius=<span class="number">0</span>)</span><br><span class="line">circles = np.uint16(np.around(circles))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> circles[<span class="number">0</span>,:]:</span><br><span class="line">    <span class="comment"># draw the outer circle</span></span><br><span class="line">    cv.circle(cimg,(i[<span class="number">0</span>],i[<span class="number">1</span>]),i[<span class="number">2</span>],(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># draw the center of the circle</span></span><br><span class="line">    cv.circle(cimg,(i[<span class="number">0</span>],i[<span class="number">1</span>]),<span class="number">2</span>,(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>),<span class="number">3</span>)</span><br><span class="line">cv.imshow(<span class="string">'detected circles'</span>,cimg)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<p><img src="/images/houghcircles2.jpg" alt></p>
<h1 id="分水岭算法的图像分割"><a href="#分水岭算法的图像分割" class="headerlink" title="分水岭算法的图像分割"></a>分水岭算法的图像分割</h1><h2 id="目标-20"><a href="#目标-20" class="headerlink" title="目标"></a>目标</h2><ul>
<li>我们将学习使用分水岭算法使用基于标记的图像分割</li>
<li>我们将看到：<code>cv.watershed()</code></li>
</ul>
<h2 id="理论-11"><a href="#理论-11" class="headerlink" title="理论"></a>理论</h2><p>任何灰度图像都可以视为地形图表面，其中高强度表示山峰和丘陵，而低强度表示山谷。您开始用不同颜色的水（标签）填充每个孤立的山谷（局部最小值）。随着水的上升，取决于附近的峰（梯度），来自不同山谷（显然具有不同颜色）的水将开始合并。为了避免这种情况，您可以在水汇合的位置建造障碍。您将继续填充水和建造障碍物的工作，直到所有山峰都在水下。然后，您创建的障碍将为您提供细分结果。这就是分水岭背后的“哲学”。您可以访问<a href="http://www.cmm.mines-paristech.fr/~beucher/wtshed.html" target="_blank" rel="noopener">分水岭</a>上的<a href="http://www.cmm.mines-paristech.fr/~beucher/wtshed.html" target="_blank" rel="noopener">CMM网页</a>，借助一些动画来了解它。</p>
<p>但是，这种方法会由于噪声或图像中的任何其他不规则性而给您造成过分分割的结果。因此，OpenCV实施了基于标记的分水岭算法，您可以在其中指定要合并的所有山谷点，哪些不是。这是一个交互式图像分割。我们要做的是为我们知道的对象提供不同的标签。用一种颜色（或强度）标记我们确定为前景或对象的区域，用另一种颜色标记我们确定为背景或非对象的区域，最后标记为我们不确定的区域，将其标记为0。这就是我们的标记。然后应用分水岭算法。然后，我们的标记将使用给定的标签进行更新，并且对象的边界的值为-1。</p>
<h2 id="代码示例："><a href="#代码示例：" class="headerlink" title="代码示例："></a>代码示例：</h2><p>下面我们将看到一个有关如何使用距离变换和分水岭分割相互接触的对象的示例。</p>
<p>考虑下面的硬币图像，硬币彼此接触。即使您设置阈值，它也会彼此接触。</p>
<p><img src="/images/water_coins.jpg" alt><br>我们从找到硬币的近似估计开始。为此，我们可以使用Otsu的二值化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'coins.png'</span>)</span><br><span class="line">gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line">ret, thresh = cv.threshold(gray,<span class="number">0</span>,<span class="number">255</span>,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)</span><br></pre></td></tr></table></figure>

<p><img src="/images/water_thresh.jpg" alt></p>
<p>现在我们需要去除图像中的任何小白噪声。为此，我们可以使用形态学开放。要去除对象中的任何小孔，我们可以使用形态学封闭。因此，现在我们可以确定，靠近对象中心的区域是前景，而离对象中心很远的区域是背景。我们不确定的唯一区域是硬币的边界区域。</p>
<p>因此，我们需要提取我们确定它们是硬币的区域。侵蚀会去除边界像素。因此，无论剩余多少，我们都可以肯定它是硬币。如果物体彼此不接触，那将起作用。但是，由于它们彼此接触，因此另一个好选择是找到距离变换并应用适当的阈值。接下来，我们需要找到我们确定它们不是硬币的区域。为此，我们扩大了结果。膨胀将对象边界增加到背景。这样，由于边界区域已删除，因此我们可以确保结果中背景中的任何区域实际上都是背景。参见下图。</p>
<p><img src="/images/water_fgbg.jpg" alt></p>
<p>其余的区域是我们不知道的区域，无论是硬币还是背景。分水岭算法应该找到它。这些区域通常位于前景和背景相遇（甚至两个不同的硬币相遇）的硬币边界附近。我们称之为边界。可以通过从<code>sure_bg</code>区域中减去<code>sure_fg</code>区域来获得。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># noise removal</span></span><br><span class="line">kernel = np.ones((<span class="number">3</span>,<span class="number">3</span>),np.uint8)</span><br><span class="line">opening = cv.morphologyEx(thresh,cv.MORPH_OPEN,kernel, iterations = <span class="number">2</span>)</span><br><span class="line"><span class="comment"># sure background area</span></span><br><span class="line">sure_bg = cv.dilate(opening,kernel,iterations=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># Finding sure foreground area</span></span><br><span class="line">dist_transform = cv.distanceTransform(opening,cv.DIST_L2,<span class="number">5</span>)</span><br><span class="line">ret, sure_fg = cv.threshold(dist_transform,<span class="number">0.7</span>*dist_transform.max(),<span class="number">255</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># Finding unknown region</span></span><br><span class="line">sure_fg = np.uint8(sure_fg)</span><br><span class="line">unknown = cv.subtract(sure_bg,sure_fg)</span><br></pre></td></tr></table></figure>

<p>查看结果。在阈值图像中，我们得到了一些硬币区域，我们确定这些区域是硬币，现在已经分离了。（在某些情况下，您可能只对前景分割感兴趣，而不对分离相互接触的对象感兴趣。在那种情况下，您无需使用距离变换，只需腐蚀就足够了。腐蚀只是另一种提取确定前景区域的方法，那就是所有。）</p>
<p><img src="/images/water_dt.jpg" alt></p>
<p>现在我们可以确定哪些是硬币区域，哪些是背景硬币以及所有硬币。因此，我们创建标记（它的大小与原始图像的大小相同，但具有int32数据类型），并标记其中的区域。我们肯定知道的区域（无论是前景还是背景）都标有任何正整数，但标记为不同的整数，而我们不确定的区域则保留为零。为此，我们使用<code>cv.connectedComponents()</code>。它用0标记图像的背景，然后其他对象用从1开始的整数标记。</p>
<p>但是我们知道，如果背景标记为0，则分水岭会将其视为未知区域。所以我们想用不同的整数来标记它。相反，我们将未知定义的未知区域标记为0。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Marker labelling</span></span><br><span class="line">ret, markers = cv.connectedComponents(sure_fg)</span><br><span class="line"><span class="comment"># Add one to all labels so that sure background is not 0, but 1</span></span><br><span class="line">markers = markers+<span class="number">1</span></span><br><span class="line"><span class="comment"># Now, mark the region of unknown with zero</span></span><br><span class="line">markers[unknown==<span class="number">255</span>] = <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>请参见JET颜色图中显示的结果。深蓝色区域显示未知区域。当然，硬币的颜色会不同。与未知区域相比，可以确定背景的其余区域以浅蓝色显示。</p>
<p><img src="/images/water_marker.jpg" alt></p>
<p>现在我们的标记器已准备就绪。现在是最后一步的时候了，申请分水岭。然后标记图像将被修改。边界区域将标记为-1。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">markers = cv.watershed(img,markers)</span><br><span class="line">img[markers == <span class="number">-1</span>] = [<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

<p>请参阅下面的结果。对于某些硬币，它们接触的区域被正确地分割，而对于某些硬币，则不是。<br><img src="/images/water_result.jpg" alt></p>
<h1 id="使用GrabCut算法进行交互式前景提取"><a href="#使用GrabCut算法进行交互式前景提取" class="headerlink" title="使用GrabCut算法进行交互式前景提取"></a>使用GrabCut算法进行交互式前景提取</h1><h2 id="目标-21"><a href="#目标-21" class="headerlink" title="目标"></a>目标</h2><ul>
<li>我们将看到GrabCut算法提取图像中的前景</li>
<li>我们将为此创建一个交互式应用程序。</li>
</ul>
<h2 id="理论-12"><a href="#理论-12" class="headerlink" title="理论"></a>理论</h2><p>GrabCut算法由英国微软研究院的Carsten Rother，Vladimir Kolmogorov和Andrew Blake设计。在他们的论文“GrabCut”中：使用迭代图割的交互式前景提取。需要用最少的用户交互进行前景提取的算法，结果是GrabCut。</p>
<p>从用户角度来看，它是如何工作的？最初，用户在前景区域周围绘制一个矩形（前景区域应完全位于矩形内部）。然后，算法会对其进行迭代分割，以获得最佳结果。完成。但在某些情况下，分割可能不会很好，例如，可能已将某些前景区域标记为背景，反之亦然。在这种情况下，用户需要进行精细修饰。只需在图像上画些笔画，那里就会有一些错误的结果。笔画基本上说*“嘿，该区域应该是前景，您将其标记为背景，在下一次迭代中对其进行校正” *或与背景相反。然后在下一次迭代中，您将获得更好的结果。</p>
<p>参见下图。第一名球员和球被封闭在一个蓝色矩形中。然后用白色笔划（表示前景）和黑色笔划（表示背景）进行最后的修饰。而且我们得到了不错的结果。</p>
<p><img src="/images/grabcut_output1.jpg" alt></p>
<p>那么背景发生了什么呢？</p>
<ul>
<li>用户输入矩形。此矩形之外的所有内容都将用作背景（这是在矩形应包含所有对象之前提到的原因）。矩形内的所有内容都是未知的。同样，任何指定前景和背景的用户输入都被视为硬标签，这意味着它们在此过程中不会更改。</li>
<li>计算机根据我们提供的数据进行初始标记。它标记前景和背景像素（或对其进行硬标记）</li>
<li>现在，使用高斯混合模型（GMM）对前景和背景进行建模。</li>
<li>根据我们提供的数据，GMM可以学习并创建新的像素分布。也就是说，未知像素根据颜色统计上与其他硬标记像素的关系而被标记为可能的前景或可能的背景（就像聚类一样）。</li>
<li>根据此像素分布构建图形。图中的节点为像素。添加了另外两个节点，即Source节点和Sink节点。每个前景像素都连接到源节点，每个背景像素都连接到接收器节点。</li>
<li>将像素连接到源节点/末端节点的边缘的权重由像素是前景/背景的概率定义。像素之间的权重由边缘信息或像素相似度定义。如果像素颜色差异很大，则它们之间的边缘将变低。</li>
<li>然后使用mincut算法对图进行分段。它将图切成具有最小成本函数的两个分离的源节点和宿节点。成本函数是被切割边缘的所有权重的总和。剪切后，连接到“源”节点的所有像素都变为前景，而连接到“接收器”节点的像素都变为背景。</li>
<li>继续该过程，直到分类收敛为止。<br>下图对此进行了说明（图片提供：http : //<a href="http://www.cs.ru.ac.za/research/g02m1682/）" target="_blank" rel="noopener">www.cs.ru.ac.za/research/g02m1682/）</a></li>
</ul>
<p><img src="/images/grabcut_scheme.jpg" alt></p>
<h2 id="演示版"><a href="#演示版" class="headerlink" title="演示版"></a>演示版</h2><p>现在我们使用OpenCV进行抓取算法。OpenCV 为此具有功能<code>cv.grabCut()</code>。我们将首先看到其参数：</p>
<ul>
<li>img-输入图片</li>
<li>mask-这是一个蒙版图像，其中我们指定哪些区域是背景，前景或可能的背景/前景等。它是通过以下标志cv.GC_BGD，cv.GC_FGD，cv.GC_PR_BGD，cv.GC_PR_FGD来完成的，或者只是通过0,1,2,3到图像。</li>
<li>rect-它是矩形的坐标，其中包括格式为（x，y，w，h）的前景对象</li>
<li>bdgModel，fgdModel-这些是算法内部使用的数组。您只需创建两个大小为（1,65）的np.float64类型零数组。</li>
<li>iterCount-算法应运行的迭代次数。</li>
<li>mode-应该为cv.GC_INIT_WITH_RECT或cv.GC_INIT_WITH_MASK或两者结合，决定我们要绘制矩形还是最终的修饰笔触。<br>首先让我们看看矩形模式。我们加载图像，创建类似的蒙版图像。我们创建fgdModel和bgdModel。我们给出矩形参数。一切都是直截了当的。让算法运行5次迭代。模式应为<code>cv.GC_INIT_WITH_RECT</code>，因为我们使用的是矩形。然后运行抓取。修改蒙版图像。在新的蒙版图像中，像素将被标记有四个标记，分别表示上面指定的背景/前景。因此，我们修改蒙版，使所有0像素和2像素都置为0（即背景），而所有1像素和3像素均置为1（即前景像素）。现在，我们的最终蒙版已经准备就绪。只需将其与输入图像相乘即可得到分割的图像。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'messi5.jpg'</span>)</span><br><span class="line">mask = np.zeros(img.shape[:<span class="number">2</span>],np.uint8)</span><br><span class="line">bgdModel = np.zeros((<span class="number">1</span>,<span class="number">65</span>),np.float64)</span><br><span class="line">fgdModel = np.zeros((<span class="number">1</span>,<span class="number">65</span>),np.float64)</span><br><span class="line">rect = (<span class="number">50</span>,<span class="number">50</span>,<span class="number">450</span>,<span class="number">290</span>)</span><br><span class="line">cv.grabCut(img,mask,rect,bgdModel,fgdModel,<span class="number">5</span>,cv.GC_INIT_WITH_RECT)</span><br><span class="line">mask2 = np.where((mask==<span class="number">2</span>)|(mask==<span class="number">0</span>),<span class="number">0</span>,<span class="number">1</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line">img = img*mask2[:,:,np.newaxis]</span><br><span class="line">plt.imshow(img),plt.colorbar(),plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/grabcut_rect.jpg" alt></p>
<p>糟糕，梅西的头发不见了。谁会喜欢没有头发的梅西？我们需要把它带回来。因此，我们将使用1像素（确保前景）进行精细修饰。同时，一些我们不需要的地面图片和一些徽标也出现了。我们需要删除它们。在那里，我们给出了一些0像素的修饰（确保背景）。因此，如现在所说，我们在以前的情况下修改了生成的蒙版。</p>
<p>我实际上所做的是，我在paint应用程序中打开了输入图像，并在图像中添加了另一层。使用画笔中的画笔工具，我在新图层上用白色标记了错过的前景（头发，鞋子，球等），而用白色标记了不需要的背景（例如徽标，地面等）。然后用灰色填充剩余的背景。然后将该蒙版图像加载到OpenCV中，编辑我们在新添加的蒙版图像中具有相应值的原始蒙版图像。检查以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># newmask is the mask image I manually labelled</span></span><br><span class="line">newmask = cv.imread(<span class="string">'newmask.png'</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># wherever it is marked white (sure foreground), change mask=1</span></span><br><span class="line"><span class="comment"># wherever it is marked black (sure background), change mask=0</span></span><br><span class="line">mask[newmask == <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">mask[newmask == <span class="number">255</span>] = <span class="number">1</span></span><br><span class="line">mask, bgdModel, fgdModel = cv.grabCut(img,mask,<span class="literal">None</span>,bgdModel,fgdModel,<span class="number">5</span>,cv.GC_INIT_WITH_MASK)</span><br><span class="line">mask = np.where((mask==<span class="number">2</span>)|(mask==<span class="number">0</span>),<span class="number">0</span>,<span class="number">1</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line">img = img*mask[:,:,np.newaxis]</span><br><span class="line">plt.imshow(img),plt.colorbar(),plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/grabcut_mask.jpg" alt></p>
<p>就是这样了。在这里，您无需直接在rect模式下初始化，而可以直接进入mask模式。只需用2像素或3像素（可能的背景/前景）标记蒙版图像中的矩形区域。然后像在第二个示例中一样，将我们的<code>sure_foreground</code>标记为1像素。然后直接在遮罩模式下应用grabCut功能。</p>

    </div>

    
    
    
        
      
        <div id="reward-container">
  <div>您的支持是对我最大的鼓励</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
        
      
      <div style="display: inline-block">
        <img src="/images/weixin.jpg" alt="陈 建 微信支付">
        <p>微信支付</p>
      </div>
        
      
      <div style="display: inline-block">
        <img src="/images/alipay.jpg" alt="陈 建 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

      
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>陈 建</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://leesin.cc/opencv/OpenCV中的图像处理.html" title="OpenCV中的图像处理">http://leesin.cc/opencv/OpenCV中的图像处理.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>
</div>

      

      <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/opencv/OpenCV的核心操作.html" rel="next" title="OpenCV的核心操作">
                  <i class="fa fa-chevron-left"></i> OpenCV的核心操作
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/opencv/特征检测与描述.html" rel="prev" title="特征检测与描述">
                  特征检测与描述 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar.jpg"
      alt="陈 建">
  <p class="site-author-name" itemprop="name">陈 建</p>
  <div class="site-description motion-element" itemprop="description">当时明月在，曾照彩云归</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">109</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/LeeSinCOOC" title="GitHub &rarr; https://github.com/LeeSinCOOC" rel="noopener" target="_blank"><i class="fa fa-fw fa-GitHub"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:690246265@qq.com" title="E-Mail &rarr; mailto:690246265@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-E-Mail"></i>E-Mail</a>
      </span>
    
  </div>


  <div class="links-of-blogroll motion-element links-of-blogroll-block">
    <div class="links-of-blogroll-title">
      <i class="fa  fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.baidu.com" title="https://www.baidu.com" rel="noopener" target="_blank">baidu</a>
        </li>
      
    </ul>
  </div>


        </div>
      </div>
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#改变色彩空间"><span class="nav-number">1.</span> <span class="nav-text">改变色彩空间</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标"><span class="nav-number">1.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#改变色彩空间-1"><span class="nav-number">1.2.</span> <span class="nav-text">改变色彩空间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#对象追踪"><span class="nav-number">1.3.</span> <span class="nav-text">对象追踪</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#如何找到要追踪的HSV值？"><span class="nav-number">1.4.</span> <span class="nav-text">如何找到要追踪的HSV值？</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#图像的几何变换"><span class="nav-number">2.</span> <span class="nav-text">图像的几何变换</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标-1"><span class="nav-number">2.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#转换"><span class="nav-number">2.2.</span> <span class="nav-text">转换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#缩放"><span class="nav-number">2.3.</span> <span class="nav-text">缩放</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#平移"><span class="nav-number">2.4.</span> <span class="nav-text">平移</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#旋转"><span class="nav-number">2.5.</span> <span class="nav-text">旋转</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#仿射变换"><span class="nav-number">2.6.</span> <span class="nav-text">仿射变换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#透视变换"><span class="nav-number">2.7.</span> <span class="nav-text">透视变换</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#图像阈值"><span class="nav-number">3.</span> <span class="nav-text">图像阈值</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标-2"><span class="nav-number">3.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#简单阈值"><span class="nav-number">3.2.</span> <span class="nav-text">简单阈值</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#自适应阈值"><span class="nav-number">3.3.</span> <span class="nav-text">自适应阈值</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Otsu’s-Binarization"><span class="nav-number">3.4.</span> <span class="nav-text">Otsu’s Binarization</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#平滑图像"><span class="nav-number">4.</span> <span class="nav-text">平滑图像</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标-3"><span class="nav-number">4.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2D卷积（图像过滤）"><span class="nav-number">4.2.</span> <span class="nav-text">2D卷积（图像过滤）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像模糊（图像平滑）"><span class="nav-number">4.3.</span> <span class="nav-text">图像模糊（图像平滑）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-平均"><span class="nav-number">4.3.1.</span> <span class="nav-text">1.平均</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-高斯模糊"><span class="nav-number">4.3.2.</span> <span class="nav-text">2.高斯模糊</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-中位模糊"><span class="nav-number">4.3.3.</span> <span class="nav-text">3.中位模糊</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-双边过滤"><span class="nav-number">4.3.4.</span> <span class="nav-text">4.双边过滤</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#形态转换"><span class="nav-number">5.</span> <span class="nav-text">形态转换</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标-4"><span class="nav-number">5.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#理论"><span class="nav-number">5.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-侵蚀"><span class="nav-number">5.3.</span> <span class="nav-text">1.侵蚀</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-膨胀"><span class="nav-number">5.4.</span> <span class="nav-text">2.膨胀</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-开运算"><span class="nav-number">5.5.</span> <span class="nav-text">3.开运算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-闭运算"><span class="nav-number">5.6.</span> <span class="nav-text">4.闭运算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-形态梯度"><span class="nav-number">5.7.</span> <span class="nav-text">5.形态梯度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-高帽"><span class="nav-number">5.8.</span> <span class="nav-text">6.高帽</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-黑帽"><span class="nav-number">5.9.</span> <span class="nav-text">7.黑帽</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#结构元素"><span class="nav-number">5.10.</span> <span class="nav-text">结构元素</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#图像渐变"><span class="nav-number">6.</span> <span class="nav-text">图像渐变</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标-5"><span class="nav-number">6.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#理论-1"><span class="nav-number">6.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#一个重要的事情！"><span class="nav-number">6.3.</span> <span class="nav-text">一个重要的事情！</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Canny边缘检测"><span class="nav-number">7.</span> <span class="nav-text">Canny边缘检测</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标-6"><span class="nav-number">7.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#理论-2"><span class="nav-number">7.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OpenCV中的Canny-Edge检测"><span class="nav-number">7.3.</span> <span class="nav-text">OpenCV中的Canny Edge检测</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#图像金字塔"><span class="nav-number">8.</span> <span class="nav-text">图像金字塔</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标-7"><span class="nav-number">8.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#理论-3"><span class="nav-number">8.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用金字塔进行图像融合"><span class="nav-number">8.3.</span> <span class="nav-text">使用金字塔进行图像融合</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#OpenCV中的轮廓"><span class="nav-number">9.</span> <span class="nav-text">OpenCV中的轮廓</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#轮廓：入门"><span class="nav-number">9.1.</span> <span class="nav-text">轮廓：入门</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#目标-8"><span class="nav-number">9.1.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#什么是轮廓？"><span class="nav-number">9.1.2.</span> <span class="nav-text">什么是轮廓？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#如何绘制轮廓？"><span class="nav-number">9.1.3.</span> <span class="nav-text">如何绘制轮廓？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#轮廓近似法"><span class="nav-number">9.1.4.</span> <span class="nav-text">轮廓近似法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#轮廓特征"><span class="nav-number">9.2.</span> <span class="nav-text">轮廓特征</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#目标-9"><span class="nav-number">9.2.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-时刻"><span class="nav-number">9.2.2.</span> <span class="nav-text">1.时刻</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-轮廓面积"><span class="nav-number">9.2.3.</span> <span class="nav-text">2.轮廓面积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-轮廓周长"><span class="nav-number">9.2.4.</span> <span class="nav-text">3.轮廓周长</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-轮廓近似"><span class="nav-number">9.2.5.</span> <span class="nav-text">4.轮廓近似</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-凸包"><span class="nav-number">9.2.6.</span> <span class="nav-text">5.凸包</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-检查凸度"><span class="nav-number">9.2.7.</span> <span class="nav-text">6.检查凸度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-边界矩形"><span class="nav-number">9.2.8.</span> <span class="nav-text">7.边界矩形</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-A-直角矩形"><span class="nav-number">9.2.8.1.</span> <span class="nav-text">7.A. 直角矩形</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-b-旋转矩形"><span class="nav-number">9.2.8.2.</span> <span class="nav-text">7.b. 旋转矩形</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-最小外接圆"><span class="nav-number">9.2.9.</span> <span class="nav-text">8.最小外接圆</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-拟合椭圆"><span class="nav-number">9.2.10.</span> <span class="nav-text">9.拟合椭圆</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-拟合线"><span class="nav-number">9.2.11.</span> <span class="nav-text">10.拟合线</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#轮廓属性"><span class="nav-number">9.3.</span> <span class="nav-text">轮廓属性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-长宽比"><span class="nav-number">9.3.1.</span> <span class="nav-text">1.长宽比</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-范围"><span class="nav-number">9.3.2.</span> <span class="nav-text">2.范围</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-坚固性"><span class="nav-number">9.3.3.</span> <span class="nav-text">3.坚固性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-等效直径"><span class="nav-number">9.3.4.</span> <span class="nav-text">4.等效直径</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-方向"><span class="nav-number">9.3.5.</span> <span class="nav-text">5.方向</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-遮罩和像素点"><span class="nav-number">9.3.6.</span> <span class="nav-text">6.遮罩和像素点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-最大值，最小值及其位置"><span class="nav-number">9.3.7.</span> <span class="nav-text">7.最大值，最小值及其位置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-平均颜色或平均强度"><span class="nav-number">9.3.8.</span> <span class="nav-text">8.平均颜色或平均强度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-极端点"><span class="nav-number">9.3.9.</span> <span class="nav-text">9.极端点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#轮廓：更多功能"><span class="nav-number">9.4.</span> <span class="nav-text">轮廓：更多功能</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#目标-10"><span class="nav-number">9.4.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#理论与规范"><span class="nav-number">9.4.2.</span> <span class="nav-text">理论与规范</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-凸性缺陷"><span class="nav-number">9.4.3.</span> <span class="nav-text">1.凸性缺陷</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-点多边形测试"><span class="nav-number">9.4.4.</span> <span class="nav-text">2.点多边形测试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-比较形状"><span class="nav-number">9.4.5.</span> <span class="nav-text">3.比较形状</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#轮廓层次"><span class="nav-number">9.5.</span> <span class="nav-text">轮廓层次</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#目标-11"><span class="nav-number">9.5.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#理论-4"><span class="nav-number">9.5.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#什么是层次结构？"><span class="nav-number">9.5.3.</span> <span class="nav-text">什么是层次结构？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#轮廓检索模式"><span class="nav-number">9.6.</span> <span class="nav-text">轮廓检索模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-RETR-LIST"><span class="nav-number">9.6.1.</span> <span class="nav-text">1. RETR_LIST</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-RETR-EXTERNAL"><span class="nav-number">9.6.2.</span> <span class="nav-text">2. RETR_EXTERNAL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-RETR-CCOMP"><span class="nav-number">9.6.3.</span> <span class="nav-text">3. RETR_CCOMP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-RETR-TREE"><span class="nav-number">9.6.4.</span> <span class="nav-text">4. RETR_TREE</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#OpenCV中的直方图"><span class="nav-number">10.</span> <span class="nav-text">OpenCV中的直方图</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#直方图-1：查找，绘制，分析"><span class="nav-number">10.1.</span> <span class="nav-text">直方图-1：查找，绘制，分析!!!</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#目标-12"><span class="nav-number">10.1.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#理论-5"><span class="nav-number">10.1.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#查找直方图"><span class="nav-number">10.1.3.</span> <span class="nav-text">查找直方图</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-OpenCV中的直方图计算"><span class="nav-number">10.1.3.1.</span> <span class="nav-text">1. OpenCV中的直方图计算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-Numpy中的直方图计算"><span class="nav-number">10.1.3.2.</span> <span class="nav-text">2. Numpy中的直方图计算</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#绘制直方图"><span class="nav-number">10.1.4.</span> <span class="nav-text">绘制直方图</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-使用Matplotlib"><span class="nav-number">10.1.4.1.</span> <span class="nav-text">1.使用Matplotlib</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-使用OpenCV"><span class="nav-number">10.1.4.2.</span> <span class="nav-text">2.使用OpenCV</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#掩膜的应用"><span class="nav-number">10.1.5.</span> <span class="nav-text">掩膜的应用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#直方图-2：直方图均衡"><span class="nav-number">10.2.</span> <span class="nav-text">直方图-2：直方图均衡</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#目标-13"><span class="nav-number">10.2.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#理论-6"><span class="nav-number">10.2.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OpenCV中的直方图均衡"><span class="nav-number">10.2.3.</span> <span class="nav-text">OpenCV中的直方图均衡</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CLAHE（对比度受限的自适应直方图均衡）"><span class="nav-number">10.2.4.</span> <span class="nav-text">CLAHE（对比度受限的自适应直方图均衡）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#直方图-3：2D直方图"><span class="nav-number">10.3.</span> <span class="nav-text">直方图-3：2D直方图</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#目标-14"><span class="nav-number">10.3.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#介绍"><span class="nav-number">10.3.2.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OpenCV中的2D直方图"><span class="nav-number">10.3.3.</span> <span class="nav-text">OpenCV中的2D直方图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#numpy中的2D直方图"><span class="nav-number">10.3.4.</span> <span class="nav-text">numpy中的2D直方图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#绘制2D直方图"><span class="nav-number">10.3.5.</span> <span class="nav-text">绘制2D直方图</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#方法-1：使用cv-imshow"><span class="nav-number">10.3.5.1.</span> <span class="nav-text">方法-1：使用cv.imshow()</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#方法-2：使用Matplotlib"><span class="nav-number">10.3.5.2.</span> <span class="nav-text">方法-2：使用Matplotlib</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#方法3：OpenCV示例样式！"><span class="nav-number">10.3.5.3.</span> <span class="nav-text">方法3：OpenCV示例样式！</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#直方图-4：直方图反投影"><span class="nav-number">10.4.</span> <span class="nav-text">直方图-4：直方图反投影</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#目标-15"><span class="nav-number">10.4.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#理论-7"><span class="nav-number">10.4.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Numpy中的算法"><span class="nav-number">10.4.3.</span> <span class="nav-text">Numpy中的算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OpenCV中的反投影"><span class="nav-number">10.4.4.</span> <span class="nav-text">OpenCV中的反投影</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#OpenCV中的图像转换"><span class="nav-number">11.</span> <span class="nav-text">OpenCV中的图像转换</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#傅立叶变换"><span class="nav-number">11.1.</span> <span class="nav-text">傅立叶变换</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#目标-16"><span class="nav-number">11.1.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#理论-8"><span class="nav-number">11.1.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#numpy中的傅立叶变换"><span class="nav-number">11.1.3.</span> <span class="nav-text">numpy中的傅立叶变换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OpenCV中的傅立叶变换"><span class="nav-number">11.1.4.</span> <span class="nav-text">OpenCV中的傅立叶变换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DFT的性能优化"><span class="nav-number">11.1.5.</span> <span class="nav-text">DFT的性能优化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#为什么拉普拉斯算子是高通滤波器？"><span class="nav-number">11.2.</span> <span class="nav-text">为什么拉普拉斯算子是高通滤波器？</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模板匹配"><span class="nav-number">12.</span> <span class="nav-text">模板匹配</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标-17"><span class="nav-number">12.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#理论-9"><span class="nav-number">12.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OpenCV中的模板匹配"><span class="nav-number">12.3.</span> <span class="nav-text">OpenCV中的模板匹配</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模板与多个对象匹配"><span class="nav-number">12.4.</span> <span class="nav-text">模板与多个对象匹配</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#霍夫线变换"><span class="nav-number">13.</span> <span class="nav-text">霍夫线变换</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标-18"><span class="nav-number">13.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#理论-10"><span class="nav-number">13.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OpenCV中的霍夫变换"><span class="nav-number">13.3.</span> <span class="nav-text">OpenCV中的霍夫变换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#概率霍夫变换"><span class="nav-number">13.4.</span> <span class="nav-text">概率霍夫变换</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#霍夫圆变换"><span class="nav-number">14.</span> <span class="nav-text">霍夫圆变换</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标-19"><span class="nav-number">14.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#示例代码"><span class="nav-number">14.2.</span> <span class="nav-text">示例代码</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分水岭算法的图像分割"><span class="nav-number">15.</span> <span class="nav-text">分水岭算法的图像分割</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标-20"><span class="nav-number">15.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#理论-11"><span class="nav-number">15.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#代码示例："><span class="nav-number">15.3.</span> <span class="nav-text">代码示例：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#使用GrabCut算法进行交互式前景提取"><span class="nav-number">16.</span> <span class="nav-text">使用GrabCut算法进行交互式前景提取</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标-21"><span class="nav-number">16.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#理论-12"><span class="nav-number">16.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#演示版"><span class="nav-number">16.3.</span> <span class="nav-text">演示版</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">陈 建</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.3.0</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  
    <span class="post-meta-divider">|</span>
  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>








        
      </div>
    </footer>
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
      </div>

    

  </div>

  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>

<script src="/js/schemes/muse.js?v=7.3.0"></script>



<script src="/js/next-boot.js?v=7.3.0"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>















  <script src="/js/local-search.js?v=7.3.0"></script>














  

  

  


  
  <script src="/js/scrollspy.js?v=7.3.0"></script><script src="/js/post-details.js?v=7.3.0"></script>


</body>
</html>
