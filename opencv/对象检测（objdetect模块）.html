<!DOCTYPE html>





<html class="theme-next mist use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="generator" content="Hexo 3.9.0">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/bitbug_favicon1.ico?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/bitbug_favicon.ico?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"right","display":"hide","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    save_scroll: false,
    copycode: {"enable":true,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="级联分类器目标 我们将学习Haar级联对象检测的工作原理。 我们将使用基于Haar Feature的Cascade分类器了解人脸检测和眼睛检测的基础知识我们将使用cv :: CascadeClassifier类来检测视频流中的对象。特别是，我们将使用以下功能：cv :: CascadeClassifier :: load来加载.xml分类器文件。它可以是Haar或LBP分类器cv :: Casca">
<meta name="keywords" content="python,tensorflow,pytorch,人工智能">
<meta property="og:type" content="article">
<meta property="og:title" content="对象检测（objdetect模块）">
<meta property="og:url" content="http://leesin.cc/opencv/对象检测（objdetect模块）.html">
<meta property="og:site_name" content="Chen Jian&#39;s Blog">
<meta property="og:description" content="级联分类器目标 我们将学习Haar级联对象检测的工作原理。 我们将使用基于Haar Feature的Cascade分类器了解人脸检测和眼睛检测的基础知识我们将使用cv :: CascadeClassifier类来检测视频流中的对象。特别是，我们将使用以下功能：cv :: CascadeClassifier :: load来加载.xml分类器文件。它可以是Haar或LBP分类器cv :: Casca">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://leesin.cc/images/haar_features.jpg">
<meta property="og:image" content="http://leesin.cc/images/haar.png">
<meta property="og:image" content="http://leesin.cc/images/Cascade_Classifier_Tutorial_Result_Haar.jpg">
<meta property="og:image" content="http://leesin.cc/images/Cascade_Classifier_Tutorial_Result_LBP.jpg">
<meta property="og:image" content="http://leesin.cc/images/visualisation_video.png">
<meta property="og:image" content="http://leesin.cc/images/visualisation_single_stage.png">
<meta property="og:updated_time" content="2019-10-20T06:41:53.764Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="对象检测（objdetect模块）">
<meta name="twitter:description" content="级联分类器目标 我们将学习Haar级联对象检测的工作原理。 我们将使用基于Haar Feature的Cascade分类器了解人脸检测和眼睛检测的基础知识我们将使用cv :: CascadeClassifier类来检测视频流中的对象。特别是，我们将使用以下功能：cv :: CascadeClassifier :: load来加载.xml分类器文件。它可以是Haar或LBP分类器cv :: Casca">
<meta name="twitter:image" content="http://leesin.cc/images/haar_features.jpg">
  <link rel="canonical" href="http://leesin.cc/opencv/对象检测（objdetect模块）">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>对象检测（objdetect模块） | Chen Jian's Blog</title>
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  <div class="container sidebar-position-right">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Chen Jian's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-reading">
      
    

    <a href="/reading/" rel="section"><i class="menu-item-icon fa fa-fw fa-book"></i> <br>笔记</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-miscellaneous">
      
    

    <a href="/miscellaneous/" rel="section"><i class="menu-item-icon fa fa-fw fa-link"></i> <br>常用网站</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
      </li>
    
  </ul>

    

</nav>
  <div class="site-search">
    
  <div class="popup search-popup">
  <div class="search-header">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <div class="search-input-wrapper">
      <input autocomplete="off" autocorrect="off" autocapitalize="none"
             placeholder="搜索..." spellcheck="false"
             type="text" id="search-input">
    </div>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>
  <div id="search-result"></div>
</div>


  </div>
</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content page-post-detail">
            

  <div id="posts" class="posts-expand">
    

  <article class="post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leesin.cc/opencv/对象检测（objdetect模块）.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="陈 建">
      <meta itemprop="description" content="当时明月在，曾照彩云归">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen Jian's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">对象检测（objdetect模块）

          
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2019-10-08 14:11:00" itemprop="dateCreated datePublished" datetime="2019-10-08T14:11:00+08:00">2019-10-08</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-10-20 14:41:53" itemprop="dateModified" datetime="2019-10-20T14:41:53+08:00">2019-10-20</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/OpenCV-Python-教程/" itemprop="url" rel="index"><span itemprop="name">OpenCV-Python 教程</span></a></span>

                
                
              
            </span>
          

          
            <span class="post-meta-item" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="级联分类器"><a href="#级联分类器" class="headerlink" title="级联分类器"></a>级联分类器</h1><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ul>
<li>我们将学习Haar级联对象检测的工作原理。</li>
<li>我们将使用基于<code>Haar Feature</code>的<code>Cascade</code>分类器了解人脸检测和眼睛检测的基础知识<br>我们将使用<code>cv :: CascadeClassifier</code>类来检测视频流中的对象。特别是，我们将使用以下功能：<br><code>cv :: CascadeClassifier :: load</code>来加载<code>.xml</code>分类器文件。它可以是<code>Haar</code>或<code>LBP</code>分类器<br><code>cv :: CascadeClassifier :: detectMultiScale</code>执行检测。</li>
</ul><a id="more"></a>
<h2 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h2><p>使用基于Haar特征的级联分类器进行对象检测是Paul Viola和Michael Jones在其论文“使用简单特征的增强级联进行快速对象检测”中于2001年提出的一种有效的对象检测方法。这是一种基于机器学习的方法，其中从许多正负图像中训练级联函数。然后用于检测其他图像中的对象。</p>
<p>在这里，我们将进行人脸检测。最初，该算法需要大量正图像（面部图像）和负图像（无面部图像）来训练分类器。然后，我们需要从中提取特征。为此，使用下图所示的Haar功能。它们就像我们的卷积核。每个特征都是通过从黑色矩形下的像素总和中减去白色矩形下的像素总和而获得的单个值。</p>
<p><img src="/images/haar_features.jpg" alt></p>
<p>现在，每个内核的所有可能大小和位置都用于计算许多功能。（试想一下它需要多少计算？即使是一个24x24的窗口也会产生超过160000个特征）。对于每个特征计算，我们需要找到白色和黑色矩形下的像素总和。为了解决这个问题，他们引入了整体形象。无论您的图像有多大，它都会将给定像素的计算减少到仅涉及四个像素的操作。很好，不是吗？它使事情变得超快。</p>
<p>但是在我们计算的所有这些功能中，大多数都不相关。例如，考虑下图。第一行显示了两个良好的功能。选择的第一个特征似乎着眼于眼睛区域通常比鼻子和脸颊区域更暗的性质。选择的第二个功能依赖于眼睛比鼻梁更黑的属性。但是，将相同的窗口应用于脸颊或其他任何地方都是无关紧要的。那么，我们如何从16万多个功能中选择最佳功能？它是由Adaboost实现的。</p>
<p><img src="/images/haar.png" alt></p>
<p>为此，我们将所有功能应用于所有训练图像。对于每个功能，它会找到最佳的阈值，该阈值会将人脸分为正面和负面。显然，会出现错误或分类错误。我们选择错误率最低的特征，这意味着它们是对人脸和非人脸图像进行最准确分类的特征。（此过程并非如此简单。在开始时，每个图像的权重均相等。在每次分类后，错误分类的图像的权重都会增加。然后执行相同的过程。将计算新的错误率。还要计算新的权重。继续进行此过程，直到达到所需的精度或错误率或找到所需的功能数量为止。</p>
<p>最终分类器是这些弱分类器的加权和。之所以称为弱分类，是因为仅凭它不能对图像进行分类，而是与其他分类一起形成强分类器。该论文说，甚至200个功能都可以提供95％的准确度检测。他们的最终设置具有大约6000个功能。（想象一下，从160000多个功能减少到6000个功能。这是很大的收获）。</p>
<p>因此，现在您拍摄一张照片。取每个24x24窗口。向其应用6000个功能。检查是否有脸。哇..这不是效率低下又费时吗？是的。作者对此有一个很好的解决方案。</p>
<p>在图像中，大多数图像是非面部区域。因此，最好有一种简单的方法来检查窗口是否不是面部区域。如果不是，请一次性丢弃它，不要再次对其进行处理。相反，应将重点放在可能有脸的区域。这样，我们将花费更多时间检查可能的面部区域。</p>
<p>为此，他们引入了级联分类器的概念。不是将所有6000个功能部件应用到一个窗口中，而是将这些功能部件分组到不同阶段的分类器中，并一一应用。（通常前几个阶段将包含很少的功能）。如果窗口在第一阶段失败，则将其丢弃。我们不考虑它的其余功能。如果通过，则应用功能的第二阶段并继续该过程。经过所有阶段的窗口是一个面部区域。那计划怎么样？</p>
<p>作者的检测器具有6000多个特征，具有38个阶段，在前五个阶段具有1、10、25、25和50个特征。（上图中的两个功能实际上是从Adaboost获得的最佳两个功能）。根据作者的说法，每个子窗口平均评估了6000多个特征中的10个特征。</p>
<p>因此，这是Viola-Jones人脸检测工作原理的简单直观说明。阅读本文以获取更多详细信息，或查看其他资源部分中的参考资料。</p>
<h2 id="OpenCV中的Haar级联检测"><a href="#OpenCV中的Haar级联检测" class="headerlink" title="OpenCV中的Haar级联检测"></a>OpenCV中的Haar级联检测</h2><p>OpenCV提供了一种训练方法（请参阅Cascade Classifier Training）或预先训练的模型，可以使用<code>cv::CascadeClassifier::load</code>方法读取它。预训练的模型位于OpenCV安装的data文件夹中，或在<a href="https://github.com/opencv/opencv/tree/master/data" target="_blank" rel="noopener">此处</a>找到。</p>
<p>以下代码示例将使用预训练的Haar级联模型来检测图像中的面部和眼睛。首先，创建一个<code>cv::CascadeClassifier</code>并使用<code>cv::CascadeClassifier::load</code>方法加载必要的<code>XML</code>文件。然后，使用<code>cv::CascadeClassifier::detectMultiScale</code>方法完成检测，该方法返回检测到的脸部或眼睛的边界矩形。</p>
<p>本教程的代码如下所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detectAndDisplay</span><span class="params">(frame)</span>:</span></span><br><span class="line">    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)</span><br><span class="line">    frame_gray = cv.equalizeHist(frame_gray)</span><br><span class="line">    <span class="comment">#-- Detect faces</span></span><br><span class="line">    faces = face_cascade.detectMultiScale(frame_gray)</span><br><span class="line">    <span class="keyword">for</span> (x,y,w,h) <span class="keyword">in</span> faces:</span><br><span class="line">        center = (x + w//<span class="number">2</span>, y + h//<span class="number">2</span>)</span><br><span class="line">        frame = cv.ellipse(frame, center, (w//<span class="number">2</span>, h//<span class="number">2</span>), <span class="number">0</span>, <span class="number">0</span>, <span class="number">360</span>, (<span class="number">255</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">4</span>)</span><br><span class="line">        faceROI = frame_gray[y:y+h,x:x+w]</span><br><span class="line">        <span class="comment">#-- In each face, detect eyes</span></span><br><span class="line">        eyes = eyes_cascade.detectMultiScale(faceROI)</span><br><span class="line">        <span class="keyword">for</span> (x2,y2,w2,h2) <span class="keyword">in</span> eyes:</span><br><span class="line">            eye_center = (x + x2 + w2//<span class="number">2</span>, y + y2 + h2//<span class="number">2</span>)</span><br><span class="line">            radius = int(round((w2 + h2)*<span class="number">0.25</span>))</span><br><span class="line">            frame = cv.circle(frame, eye_center, radius, (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span> ), <span class="number">4</span>)</span><br><span class="line">    cv.imshow(<span class="string">'Capture - Face detection'</span>, frame)</span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">'Code for Cascade Classifier tutorial.'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--face_cascade'</span>, help=<span class="string">'Path to face cascade.'</span>, default=<span class="string">'data/haarcascades/haarcascade_frontalface_alt.xml'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--eyes_cascade'</span>, help=<span class="string">'Path to eyes cascade.'</span>, default=<span class="string">'data/haarcascades/haarcascade_eye_tree_eyeglasses.xml'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--camera'</span>, help=<span class="string">'Camera devide number.'</span>, type=int, default=<span class="number">0</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">face_cascade_name = args.face_cascade</span><br><span class="line">eyes_cascade_name = args.eyes_cascade</span><br><span class="line">face_cascade = cv.CascadeClassifier()</span><br><span class="line">eyes_cascade = cv.CascadeClassifier()</span><br><span class="line"><span class="comment">#-- 1. Load the cascades</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> face_cascade.load(cv.samples.findFile(face_cascade_name)):</span><br><span class="line">    print(<span class="string">'--(!)Error loading face cascade'</span>)</span><br><span class="line">    exit(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> eyes_cascade.load(cv.samples.findFile(eyes_cascade_name)):</span><br><span class="line">    print(<span class="string">'--(!)Error loading eyes cascade'</span>)</span><br><span class="line">    exit(<span class="number">0</span>)</span><br><span class="line">camera_device = args.camera</span><br><span class="line"><span class="comment">#-- 2. Read the video stream</span></span><br><span class="line">cap = cv.VideoCapture(camera_device)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> cap.isOpened:</span><br><span class="line">    print(<span class="string">'--(!)Error opening video capture'</span>)</span><br><span class="line">    exit(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    <span class="keyword">if</span> frame <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        print(<span class="string">'--(!) No captured frame -- Break!'</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    detectAndDisplay(frame)</span><br><span class="line">    <span class="keyword">if</span> cv.waitKey(<span class="number">10</span>) == <span class="number">27</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>这是运行上面的代码并将内置摄像头的视频流用作输入的结果：</p>
<p><img src="/images/Cascade_Classifier_Tutorial_Result_Haar.jpg" alt></p>
<p>确保程序会找到文件<code>haarcascade_frontalface_alt.xml</code>和<code>haarcascade_eye_tree_eyeglasses.xml</code>的路径。它们位于<code>opencv/data/haarcascades</code>中</p>
<p>这是使用文件<code>lbpcascade_frontalface.xml</code>（经过LBP训练）进行人脸检测的结果。对于眼睛，我们继续使用本教程中使用的文件。</p>
<p><img src="/images/Cascade_Classifier_Tutorial_Result_LBP.jpg" alt></p>
<h1 id="级联分类器训练"><a href="#级联分类器训练" class="headerlink" title="级联分类器训练"></a>级联分类器训练</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>使用弱分类器的增强级联包括两个主要阶段：训练和检测阶段。对象检测教程中介绍了使用基于HAAR或LBP模型的检测阶段。本文档概述了训练自己的弱分类器的级联所需的功能。当前指南将分各个阶段进行：收集训练数据，准备训练数据并执行实际模型训练。</p>
<p>为了支持本教程，将使用几个官方的OpenCV应用程序：<a href="https://github.com/opencv/opencv/tree/master/apps/createsamples" target="_blank" rel="noopener">opencv_createsamples</a>，<a href="https://github.com/opencv/opencv/tree/master/apps/annotation" target="_blank" rel="noopener">opencv_annotation</a>，<a href="https://github.com/opencv/opencv/tree/master/apps/traincascade" target="_blank" rel="noopener">opencv_traincascade</a>和<a href="https://github.com/opencv/opencv/tree/master/apps/visualisation" target="_blank" rel="noopener">opencv_visualisation</a>。</p>
<h3 id="重要笔记"><a href="#重要笔记" class="headerlink" title="重要笔记"></a>重要笔记</h3><ul>
<li>如果您遇到任何提及旧的opencv_haartraining工具（不推荐使用，仍在使用OpenCV1.x接口）的教程，请忽略该教程并坚持使用opencv_traincascade工具。此工具是较新的版本，根据OpenCV 2.x和OpenCV 3.x API用C ++编写。opencv_traincascade同时支持类似HAAR的小波特征和LBP（局部二进制模式）特征。与HAAR特征相比，LBP特征产生整数精度，从而产生浮点精度，因此LBP的训练和检测速度都比HAAR特征快几倍。关于LBP和HAAR的检测质量，主要取决于所使用的训练数据和选择的训练参数。可以训练基于LBP的分类器，该分类器将在训练时间的一定百分比内提供与基于HAAR的分类器几乎相同的质量。</li>
<li>来自OpenCV 2.x和OpenCV 3.x（cv :: CascadeClassifier）的较新的级联分类器检测接口支持使用新旧模型格式。如果由于某些原因而使用旧界面，则opencv_traincascade甚至可以旧格式保存（导出）经过训练的级联。然后至少可以在最稳定的界面中训练模型。</li>
<li>opencv_traincascade应用程序可以使用TBB进行多线程处理。要在多核模式下使用它，必须在启用TBB支持的情况下构建OpenCV。</li>
</ul>
<h2 id="准备训练数据"><a href="#准备训练数据" class="headerlink" title="准备训练数据"></a>准备训练数据</h2><p>为了训练弱分类器的增强级联，我们需要一组正样本（包含您要检测的实际对象）和一组负图像（包含您不想检测的所有内容）。负样本集必须手动准备，而正样本集是使用<code>opencv_createsamples</code>应用程序创建的。</p>
<h3 id="负样本"><a href="#负样本" class="headerlink" title="负样本"></a>负样本</h3><p>负样本取自任意图像，其中不包含要检测的对象。这些负图像（从中生成样本）应在特殊的负图像文件中列出，该文件每行包含一个图像路径（可以是绝对路径，也可以是相对路径）。注意，负样本和样本图像也称为背景样本或背景图像，在本文档中可以互换使用。</p>
<p>所描述的图像可能具有不同的尺寸。但是，每个图像都应等于或大于所需的训练窗口大小（与模型尺寸相对应，大多数情况下是对象的平均大小），因为这些图像用于将给定的负像子采样为几个图像具有此训练窗口大小的样本。</p>
<p>否定描述文件的示例：</p>
<p>目录结构：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/ IMG</span><br><span class="line">  img1.jpg</span><br><span class="line">  img2.jpg</span><br><span class="line">bg.txt</span><br></pre></td></tr></table></figure>

<p>您的一组否定窗口样本将用于告诉机器学习步骤，在这种情况下，当尝试查找您感兴趣的对象时，可以增强不需要查找的内容。</p>
<h3 id="正样本"><a href="#正样本" class="headerlink" title="正样本"></a>正样本</h3><p>正样本由<code>opencv_createsamples</code>应用程序创建。增强过程使用它们来定义在尝试找到感兴趣的对象时模型应实际寻找的内容。该应用程序支持两种生成正样本数据集的方式。</p>
<p>1.您可以从单个正对象图像生成一堆正值。<br>2.您可以自己提供所有肯定的内容，仅使用该工具将其切出，调整大小并以opencv所需的二进制格式放置。</p>
<p>虽然第一种方法对固定对象（例如非常刚性的徽标）效果不错，但对于刚性较差的对象，它往往很快就会失效。在这种情况下，我们建议使用第二种方法。网络上的许多教程甚至都指出，使用<code>opencv_createsamples</code>应用程序，与1000个人工生成的正片相比，可以生成100个真实的对象图像更好的模型。但是，如果您决定采用第一种方法，请记住以下几点：</p>
<ul>
<li>请注意，在将其提供给上述应用程序之前，您需要多个正样本，因为它仅应用透视变换。</li>
<li>如果您需要一个健壮的模型，请获取涵盖对象类中可能出现的多种变化的样本。例如，对于面孔，您应该考虑不同的种族和年龄段，情绪以及胡须风格。当使用第二种方法时，这也适用。</li>
</ul>
<p>第一种方法采用带有公司徽标的单个对象图像，并通过随机旋转对象，更改图像强度以及将图像放置在任意背景上，从给定的对象图像中创建大量正样本。随机性的数量和范围可以由<code>opencv_createsamples</code>应用程序的命令行参数控制。</p>
<p>命令行参数：</p>
<ul>
<li><code>-vec &lt;vec_file_name&gt;</code> ：包含用于训练的正样本的输出文件的名称。</li>
<li><code>-img &lt;image_file_name&gt;</code> ：源对象图像（例如公司徽标）。</li>
<li><code>-bg &lt;background_file_name&gt;</code>：背景描述文件；包含图像列表，这些图像用作对象的随机变形版本的背景。</li>
<li><code>-num &lt;number_of_samples&gt;</code> ：要生成的阳性样本数。</li>
<li><code>-bgcolor &lt;background_color&gt;</code>：背景色（目前假设为灰度图像）；背景色表示透明色。由于可能存在压缩伪影，因此可以通过-bgthresh指定颜色容忍度。bgcolor-bgthresh和bgcolor + bgthresh范围内的所有像素均被解释为透明的。</li>
<li><code>-bgthresh &lt;background_color_threshold&gt;</code></li>
<li><code>-inv</code> ：如果指定，颜色将被反转。</li>
<li><code>-randinv</code> ：如果指定，颜色将随机反转。</li>
<li><code>-maxidev &lt;max_intensity_deviation&gt;</code> ：前景样本中像素的最大强度偏差。</li>
<li><code>-maxxangle &lt;max_x_rotation_angle&gt;</code> ：相对于x轴的最大旋转角度，必须以弧度为单位。</li>
<li><code>-maxyangle &lt;max_y_rotation_angle&gt;</code> ：朝向y轴的最大旋转角必须以弧度为单位。</li>
<li><code>-maxzangle &lt;max_z_rotation_angle&gt;</code> ：朝向z轴的最大旋转角必须以弧度为单位。</li>
<li><code>-show</code>：有用的调试选项。如果指定，将显示每个样本。按Esc将继续示例创建过程，而不会显示每个示例。</li>
<li><code>-w &lt;sample_width&gt;</code> ：输出样本的宽度（以像素为单位）。</li>
<li><code>-h &lt;sample_height&gt;</code> ：输出样本的高度（以像素为单位）。<br>当以这种方式运行opencv_createsamples时，将使用以下过程来创建样本对象实例：给定的源图像围绕所有三个轴随机旋转。所选择的角由限制<code>-maxxangle</code>，<code>-maxyangle</code>和<code>-maxzangle</code>。然后，像素具有<code>[bg_color-bg_color_threshold; bg_color + bg_c​​olor_threshold]</code>范围被解释为透明。白噪声被添加到前景的强度。如果<code>-inv</code>指定了键，则前景像素强度会反转。如果<code>-randinv</code>指定了key，则算法将随机选择是否应将反演应用于此样本。最后，将获得的图像放置在背景描述文件中的任意背景上，并调整为由<code>-w</code>和指定的所需大小<code>-h</code>并存储到由<code>-vec</code>命令行选项指定的vec文件中。</li>
</ul>
<p>也可以从以前标记的图像的集合中获取正样本，这是构建鲁棒对象模型时的理想方式。该集合由类似于背景描述文件的文本文件描述。该文件的每一行都对应一个图像。该行的第一个元素是文件名，后跟对象注释的数量，后跟描述包围矩形（x，y，宽度，高度）的对象坐标的数字。</p>
<p>描述文件的示例：</p>
<p>目录结构：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/ IMG</span><br><span class="line">  img1.jpg</span><br><span class="line">  img2.jpg</span><br><span class="line">info.dat</span><br></pre></td></tr></table></figure>

<p>文件info.dat：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img / img1.jpg 1140100 45 45</span><br><span class="line">img / img2.jpg 210020050 50 50 30 25 25</span><br></pre></td></tr></table></figure>

<p>图像img1.jpg包含具有以下边界矩形坐标的单个对象实例：（140，100，45，45）。图像img2.jpg包含两个对象实例。</p>
<p>为了从此类集合中创建正样本，<code>-info</code>应指定参数而不是<code>-img</code>：</p>
<ul>
<li><code>-info &lt;collection_file_name&gt;</code> ：标记的图像集合的描述文件。<br>请注意，在这种情况下，像这样<code>-bg, -bgcolor, -bgthreshold, -inv, -randinv, -maxxangle, -maxyangle, -maxzangle</code>的参数将被简单地忽略并且不再使用。在这种情况下，样本创建的方案如下。通过从原始图像中切出提供的边界框，从给定图像中获取对象实例。然后将它们调整为目标样本大小（由<code>-w</code>和定义<code>-h</code>），并存储在由<code>-vec</code>参数定义的输出vec文件中。无失真应用，所以只能影响参数是<code>-w，-h，-show和-num</code>。</li>
</ul>
<p><code>-info</code>也可以使用opencv_annotation工具完成手动创建文件的过程。这是一个开放源代码工具，用于在任何给定图像中直观地选择对象实例的关注区域。以下小节将详细讨论如何使用此应用程序。</p>
<p><strong>额外备注</strong></p>
<ul>
<li>opencv_createsamples实用程序可用于检查存储在任何给定正样本文件中的样本。为了做到这一点只-vec，-w并-h应指定的参数。</li>
<li>此处提供了vec-file的示例<code>opencv/data/vec_files/trainingfaces_24-24.vec</code>。它可用于训练具有以下窗口大小的面部检测器：<code>-w 24 -h 24</code>。</li>
</ul>
<h2 id="使用OpenCV的集成注释工具"><a href="#使用OpenCV的集成注释工具" class="headerlink" title="使用OpenCV的集成注释工具"></a>使用OpenCV的集成注释工具</h2><p>从OpenCV 3.x开始，社区一直在提供和维护用于生成<code>-info</code><br>文件的开源注释工具。如果构建了OpenCV应用程序，则可以通过命令opencv_annotation访问该工具。</p>
<p>使用该工具非常简单。该工具接受几个必需参数和一些可选参数：</p>
<ul>
<li><code>--annotations</code> （必需）：注释txt文件的路径，您要在其中存储注释，然后将其传递到<code>-info</code>参数[example-/data/annotations.txt]</li>
<li><code>--images</code> （必填）：包含带有您的对象的图像的文件夹的路径[示例-/ data / testimages /]</li>
<li><code>--maxWindowHeight</code> （可选）：如果输入图像的高度大于此处的给定分辨率，请使用调整图像的大小以便于注释<code>--resizeFactor</code>。</li>
<li><code>--resizeFactor</code> （可选）：使用<code>-maxWindowHeight</code>参数时用于调整输入图像大小的因子。<br>请注意，可选参数只能一起使用。可以使用的命令示例如下所示</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">opencv_annotation --annotations = /path/to/annotations/file.txt --images=/path/to/image/folder/</span><br></pre></td></tr></table></figure>

<p>此命令将启动一个窗口，其中包含第一张图像和您的鼠标光标，这些窗口将用于注释。有关如何使用注释工具的视频，请参见此处。基本上，有几个按键可以触发一个动作。鼠标左键用于选择对象的第一个角，然后一直进行绘图直到您感觉很好为止，并在记录第二次鼠标左键单击时停止。每次选择后，您有以下选择：</p>
<ul>
<li>按c：确认注释，将注释变为绿色并确认已存储</li>
<li>按下d：从注释列表中删除最后一个注释（易于删除错误的注释）</li>
<li>按下n：继续下一张图像</li>
<li>按下ESC：这将退出注释软件<br>最后，您将获得一个可用的注释文件，该文件可以传递给<code>-infoopencv_createsamples</code>的参数。</li>
</ul>
<h2 id="级联训练"><a href="#级联训练" class="headerlink" title="级联训练"></a>级联训练</h2><p>下一步是基于预先准备的正数和负数数据集对弱分类器的增强级联进行实际训练。</p>
<p>opencv_traincascade应用程序的命令行参数按用途分组：</p>
<ul>
<li>常用参数：</li>
<li><code>-data &lt;cascade_dir_name&gt;</code>：应将经过训练的分类器存储在哪里。此文件夹应事先手动创建。</li>
<li><code>-vec &lt;vec_file_name&gt;</code> ：带有正样本的vec文件（由opencv_createsamples实用程序创建）。</li>
<li><code>-bg &lt;background_file_name&gt;</code>：背景描述文件。这是包含阴性样本图像的文件。</li>
<li><code>-numPos &lt;number_of_positive_samples&gt;</code> ：每个分类器阶段用于训练的阳性样本数。</li>
<li><code>-numNeg &lt;number_of_negative_samples&gt;</code> ：每个分类器阶段用于训练的阴性样本数。</li>
<li><code>-numStages &lt;number_of_stages&gt;</code> ：要训练的级联级数。</li>
<li><code>-precalcValBufSize &lt;precalculated_vals_buffer_size_in_Mb&gt;</code>：用于预先计算的特征值的缓冲区大小（以Mb为单位）。您分配的内存越多，培训过程就越快，但是请记住，<code>-precalcValBufSize</code>和的<code>-precalcIdxBufSize</code>总和不应超过您的可用系统内存。</li>
<li><code>-precalcIdxBufSize &lt;precalculated_idxs_buffer_size_in_Mb&gt;</code>：用于预先计算的特征索引的缓冲区大小（以Mb为单位）。您分配的内存越多，培训过程就越快，但是请记住，<code>-precalcValBufSize</code>和的<code>-precalcIdxBufSize</code>总和不应超过您的可用系统内存。</li>
<li><code>-baseFormatSave</code>：对于类似Haar的功能，此参数是实际的。如果指定，级联将以旧格式保存。仅出于向后兼容的原因，并且允许用户停留在旧的不赞成使用的界面上，至少可以使用较新的界面训练模型，才可以使用此功能。</li>
<li><code>-numThreads &lt;max_number_of_threads&gt;</code>：训练期间要使用的最大线程数。请注意，实际使用的线程数可能会更少，具体取决于您的计算机和编译选项。默认情况下，如果您使用TBB支持构建了OpenCV，则将选择最大可用线程，这是此优化所必需的。</li>
<li><code>-acceptanceRatioBreakValue &lt;break_value&gt;</code>：此参数用于确定模型应保持学习的精确度以及何时停止。良好的指导原则是进行不超过10e-5的训练，以确保模型不会对您的训练数据过度训练。默认情况下，此值设置为-1以禁用此功能。</li>
<li>级联参数：</li>
<li><code>-stageType &lt;BOOST(default)&gt;</code>：阶段类型。目前仅支持提升分类器作为阶段类型。</li>
<li><code>-featureType&lt;{HAAR(default), LBP}&gt;</code> ：功能类型：HAAR-类似Haar的功能，LBP-本地二进制模式。</li>
<li><code>-w &lt;sampleWidth&gt;</code>：训练样本的宽度（以像素为单位）。必须具有与训练样本创建期间使用的值完全相同的值（opencv_createsamples实用程序）。</li>
<li><code>-h &lt;sampleHeight&gt;</code>：训练样本的高度（以像素为单位）。必须具有与训练样本创建期间使用的值完全相同的值（opencv_createsamples实用程序）。</li>
<li>提升分类器参数：</li>
<li><code>-bt &lt;{DAB, RAB, LB, GAB(default)}&gt;</code> ：增强分类器的类型：DAB-离散AdaBoost，RAB-真实AdaBoost，LB-LogitBoost，GAB-温和AdaBoost。</li>
<li><code>-minHitRate &lt;min_hit_rate&gt;</code>：分类器每个阶段的最低期望命中率。总命中率可以估计为（min_hit_rate ^ number_of_stages），[228] §4.1。</li>
<li><code>-maxFalseAlarmRate &lt;max_false_alarm_rate&gt;</code>：分类器每个阶段的最大期望误报率。总体误报率可以估计为（max_false_alarm_rate ^ number_of_stages）。</li>
<li><code>-weightTrimRate &lt;weight_trim_rate&gt;</code>：指定是否应使用修剪及其重量。不错的选择是0.95。</li>
<li><code>-maxDepth &lt;max_depth_of_weak_tree&gt;</code>：一棵弱树的最大深度。一个不错的选择是1，这是树桩的情况。</li>
<li><code>-maxWeakCount &lt;max_weak_tree_count&gt;</code>：每个级联阶段的弱树的最大数量。提升分类器（阶段）将具有太多弱树（&lt;= maxWeakCount），这是实现给定所需的-<code>maxFalseAlarmRate</code>。</li>
<li>类似Haar的特征参数：</li>
<li><code>-mode &lt;BASIC (default) | CORE | ALL&gt;</code>：选择训练中使用的Haar功能集的类型。BASIC仅使用直立功能，而ALL使用整套直立和45度旋转功能集。</li>
<li>本地二进制模式参数：本地二进制模式没有参数。<br>opencv_traincascade应用程序完成工作后，经过训练的级联将保存<code>cascade.xml</code>在该<code>-data</code>文件夹中的文件中。此文件夹中的其他文件是为中断培训而创建的，因此您可以在培训完成后将其删除。</li>
</ul>
<p>训练已完成，您可以测试级联分类器！</p>
<h2 id="可视化级联分类器"><a href="#可视化级联分类器" class="headerlink" title="可视化级联分类器"></a>可视化级联分类器</h2><p>有时，可视化受过训练的级联，查看其选择的功能以及其阶段的复杂性可能会很有用。为此，OpenCV提供了一个<code>opencv_visualisation</code>应用程序。该应用程序具有以下命令：</p>
<ul>
<li><code>--image</code> （必需）：对象模型的参考图像的路径。这应该是带有标注<code>[ -w，-h]</code>的注释，同时传递给<code>opencv_createsamples</code>和<code>opencv_traincascade</code>应用程序。</li>
<li><code>--model</code> （必需）：训练模型的路径，该路径应该在<code>-dataopencv_traincascade</code>应用程序的参数提供的文件夹中。</li>
<li><code>--data</code> （可选）：如果提供了数据文件夹（必须事先手动创建），则将存储舞台输出和功能视频。<br>下面是一个示例命令</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">opencv_visualisation --image = /data/object.png --model = /data/model.xml --data = /data/result/</span><br></pre></td></tr></table></figure>

<p>当前可视化工具的一些限制</p>
<ul>
<li>仅处理由opencv_traincascade工具训练的级联分类器模型，其中包含<strong>stumps</strong>作为决策树[默认设置]。</li>
<li>提供的图像必须是带有原始模型尺寸的样本窗口，并传递给<code>--image</code>参数。<br><code>HAAR/LBP</code>人脸模型的示例在Angelina Jolie的给定窗口上运行，该窗口具有与级联分类器文件相同的预处理-&gt; 24x24像素图像，灰度转换和直方图均衡化：</li>
</ul>
<p>每个阶段都会制作一个视频，以显示每个功能：<br><img src="/images/visualisation_video.png" alt><br>每个阶段都作为图像存储，以供将来对功能进行验证：<br><img src="/images/visualisation_single_stage.png" alt></p>

    </div>

    
    
    
        
      
        <div id="reward-container">
  <div>您的支持是对我最大的鼓励</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
        
      
      <div style="display: inline-block">
        <img src="/images/weixin.jpg" alt="陈 建 微信支付">
        <p>微信支付</p>
      </div>
        
      
      <div style="display: inline-block">
        <img src="/images/alipay.jpg" alt="陈 建 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

      
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>陈 建</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://leesin.cc/opencv/对象检测（objdetect模块）.html" title="对象检测（objdetect模块）">http://leesin.cc/opencv/对象检测（objdetect模块）.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>
</div>

      

      <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/opencv/机器学习.html" rel="next" title="机器学习">
                  <i class="fa fa-chevron-left"></i> 机器学习
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/opencv/OpenCV-Python绑定.html" rel="prev" title="OpenCV-Python绑定">
                  OpenCV-Python绑定 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar.jpg"
      alt="陈 建">
  <p class="site-author-name" itemprop="name">陈 建</p>
  <div class="site-description motion-element" itemprop="description">当时明月在，曾照彩云归</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">81</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/LeeSinCOOC" title="GitHub &rarr; https://github.com/LeeSinCOOC" rel="noopener" target="_blank"><i class="fa fa-fw fa-GitHub"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:690246265@qq.com" title="E-Mail &rarr; mailto:690246265@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-E-Mail"></i>E-Mail</a>
      </span>
    
  </div>


  <div class="links-of-blogroll motion-element links-of-blogroll-block">
    <div class="links-of-blogroll-title">
      <i class="fa  fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.baidu.com" title="https://www.baidu.com" rel="noopener" target="_blank">baidu</a>
        </li>
      
    </ul>
  </div>


        </div>
      </div>
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#级联分类器"><span class="nav-number">1.</span> <span class="nav-text">级联分类器</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目标"><span class="nav-number">1.1.</span> <span class="nav-text">目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#理论"><span class="nav-number">1.2.</span> <span class="nav-text">理论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OpenCV中的Haar级联检测"><span class="nav-number">1.3.</span> <span class="nav-text">OpenCV中的Haar级联检测</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#结果"><span class="nav-number">1.4.</span> <span class="nav-text">结果</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#级联分类器训练"><span class="nav-number">2.</span> <span class="nav-text">级联分类器训练</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#介绍"><span class="nav-number">2.1.</span> <span class="nav-text">介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#重要笔记"><span class="nav-number">2.1.1.</span> <span class="nav-text">重要笔记</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#准备训练数据"><span class="nav-number">2.2.</span> <span class="nav-text">准备训练数据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#负样本"><span class="nav-number">2.2.1.</span> <span class="nav-text">负样本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#正样本"><span class="nav-number">2.2.2.</span> <span class="nav-text">正样本</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用OpenCV的集成注释工具"><span class="nav-number">2.3.</span> <span class="nav-text">使用OpenCV的集成注释工具</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#级联训练"><span class="nav-number">2.4.</span> <span class="nav-text">级联训练</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#可视化级联分类器"><span class="nav-number">2.5.</span> <span class="nav-text">可视化级联分类器</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">陈 建</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.3.0</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  
    <span class="post-meta-divider">|</span>
  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>








        
      </div>
    </footer>
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
      </div>

    

  </div>

  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>

<script src="/js/schemes/muse.js?v=7.3.0"></script>



<script src="/js/next-boot.js?v=7.3.0"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>















  <script src="/js/local-search.js?v=7.3.0"></script>














  

  

  


  
  <script src="/js/scrollspy.js?v=7.3.0"></script><script src="/js/post-details.js?v=7.3.0"></script>


</body>
</html>
