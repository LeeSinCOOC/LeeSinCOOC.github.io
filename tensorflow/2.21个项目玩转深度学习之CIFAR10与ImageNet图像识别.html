<!DOCTYPE html>





<html class="theme-next mist use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="generator" content="Hexo 3.9.0">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/bitbug_favicon1.ico?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/bitbug_favicon.ico?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"right","display":"hide","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    save_scroll: false,
    copycode: {"enable":true,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="CIFAR-10图像识别CIFAR-10数据集下载建议使用欧洲网络代理，下载地址，解压后：   文件名 文件用途    batches.meta.txt 文本文件，存储类别名称   data_batch_1~5.bin 5个以二进制存储10000张彩色图像的训练数据   test_batch.bin 测试图像和测试图像的标签   readme.html 数据集介绍文件">
<meta name="keywords" content="python,tensorflow,pytorch,人工智能">
<meta property="og:type" content="article">
<meta property="og:title" content="2.21个项目玩转深度学习之CIFAR10与ImageNet图像识别">
<meta property="og:url" content="http://leesin.cc/tensorflow/2.21个项目玩转深度学习之CIFAR10与ImageNet图像识别.html">
<meta property="og:site_name" content="Chen Jian&#39;s Blog">
<meta property="og:description" content="CIFAR-10图像识别CIFAR-10数据集下载建议使用欧洲网络代理，下载地址，解压后：   文件名 文件用途    batches.meta.txt 文本文件，存储类别名称   data_batch_1~5.bin 5个以二进制存储10000张彩色图像的训练数据   test_batch.bin 测试图像和测试图像的标签   readme.html 数据集介绍文件">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://leesin.cc/tensorflow/images/abc.PNG">
<meta property="og:image" content="http://leesin.cc/tensorflow/images/abc15.PNG">
<meta property="og:image" content="http://leesin.cc/tensorflow/images/30cifar.PNG">
<meta property="og:updated_time" content="2019-09-24T05:55:43.088Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="2.21个项目玩转深度学习之CIFAR10与ImageNet图像识别">
<meta name="twitter:description" content="CIFAR-10图像识别CIFAR-10数据集下载建议使用欧洲网络代理，下载地址，解压后：   文件名 文件用途    batches.meta.txt 文本文件，存储类别名称   data_batch_1~5.bin 5个以二进制存储10000张彩色图像的训练数据   test_batch.bin 测试图像和测试图像的标签   readme.html 数据集介绍文件">
<meta name="twitter:image" content="http://leesin.cc/tensorflow/images/abc.PNG">
  <link rel="canonical" href="http://leesin.cc/tensorflow/2.21个项目玩转深度学习之CIFAR10与ImageNet图像识别">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>2.21个项目玩转深度学习之CIFAR10与ImageNet图像识别 | Chen Jian's Blog</title>
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  <div class="container sidebar-position-right">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Chen Jian's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-reading">
      
    

    <a href="/reading/" rel="section"><i class="menu-item-icon fa fa-fw fa-book"></i> <br>笔记</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-miscellaneous">
      
    

    <a href="/miscellaneous/" rel="section"><i class="menu-item-icon fa fa-fw fa-link"></i> <br>常用网站</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
      </li>
    
  </ul>

    

</nav>
  <div class="site-search">
    
  <div class="popup search-popup">
  <div class="search-header">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <div class="search-input-wrapper">
      <input autocomplete="off" autocorrect="off" autocapitalize="none"
             placeholder="搜索..." spellcheck="false"
             type="text" id="search-input">
    </div>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>
  <div id="search-result"></div>
</div>


  </div>
</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content page-post-detail">
            

  <div id="posts" class="posts-expand">
    

  <article class="post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leesin.cc/tensorflow/2.21个项目玩转深度学习之CIFAR10与ImageNet图像识别.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="陈 建">
      <meta itemprop="description" content="当时明月在，曾照彩云归">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen Jian's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">2.21个项目玩转深度学习之CIFAR10与ImageNet图像识别

          
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2019-09-04 21:19:25" itemprop="dateCreated datePublished" datetime="2019-09-04T21:19:25+08:00">2019-09-04</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-09-24 13:55:43" itemprop="dateModified" datetime="2019-09-24T13:55:43+08:00">2019-09-24</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/TensorFlow教程/" itemprop="url" rel="index"><span itemprop="name">TensorFlow教程</span></a></span>

                
                
              
            </span>
          

          
            <span class="post-meta-item" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="CIFAR-10图像识别"><a href="#CIFAR-10图像识别" class="headerlink" title="CIFAR-10图像识别"></a>CIFAR-10图像识别</h1><h2 id="CIFAR-10数据集下载"><a href="#CIFAR-10数据集下载" class="headerlink" title="CIFAR-10数据集下载"></a>CIFAR-10数据集下载</h2><p>建议使用欧洲网络代理，<a href="http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz" target="_blank" rel="noopener">下载地址</a>，解压后：</p><table>
<thead>
<tr>
<th align="left">文件名</th>
<th align="right">文件用途</th>
</tr>
</thead>
<tbody><tr>
<td align="left">batches.meta.txt</td>
<td align="right">文本文件，存储类别名称</td>
</tr>
<tr>
<td align="left">data_batch_1~5.bin</td>
<td align="right">5个以二进制存储10000张彩色图像的训练数据</td>
</tr>
<tr>
<td align="left">test_batch.bin</td>
<td align="right">测试图像和测试图像的标签</td>
</tr>
<tr>
<td align="left">readme.html</td>
<td align="right">数据集介绍文件</td>
</tr>
</tbody></table><a id="more"></a>

<h2 id="Tensorflow-的数据读取机制"><a href="#Tensorflow-的数据读取机制" class="headerlink" title="Tensorflow 的数据读取机制"></a>Tensorflow 的数据读取机制</h2><p>TensorFlow使用“文件名队列 + 内存队列” 的双队列形式读入文件，如何在TensorFlow创建两个队列？</p>
<p><strong>文件名队列:</strong> 使用 <code>tf.train.string_input_producer</code></p>
<ul>
<li>传入：文件名list</li>
<li>重要参数：<code>num_epochs</code> , <code>shuffle</code></li>
</ul>
<p><strong>内存队列:</strong> 不需要自己建立，只需要使用reader对象从文件名队列中读取数据就可以了</p>
<p><code>tf.train.start_queue_runners</code>:使用<code>tf.train.string_input_producer</code>创建文件名队列后，整个系统还是停滞的，需要使用<br>    <code>tf.train.start_queue_runner</code>才会启动填充队列的进程</p>
<h3 id="读取示例"><a href="#读取示例" class="headerlink" title="读取示例"></a>读取示例</h3><p>假设当前文件夹已有：A.jpg,B.jpg，C.jpg,读取5个epoch并把读取的结果重新存入read文件夹</p>
<p><img src="images/abc.PNG" alt="当前图片"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'read'</span>):</span><br><span class="line">    os.makedirs(<span class="string">'read/'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入TensorFlow</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建一个Session</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 我们要读三幅图片A.jpg, B.jpg, C.jpg</span></span><br><span class="line">    filename = [<span class="string">'A.jpg'</span>, <span class="string">'B.jpg'</span>, <span class="string">'C.jpg'</span>]</span><br><span class="line">    <span class="comment"># string_input_producer会产生一个文件名队列</span></span><br><span class="line">    filename_queue = tf.train.string_input_producer(filename, shuffle=<span class="literal">False</span>, num_epochs=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># reader从文件名队列中读数据。对应的方法是reader.read</span></span><br><span class="line">    reader = tf.WholeFileReader()</span><br><span class="line">    key, value = reader.read(filename_queue)</span><br><span class="line">    <span class="comment"># tf.train.string_input_producer定义了一个epoch变量，要对它进行初始化</span></span><br><span class="line">    tf.local_variables_initializer().run()</span><br><span class="line">    <span class="comment"># 使用start_queue_runners之后，才会开始填充队列</span></span><br><span class="line">    threads = tf.train.start_queue_runners(sess=sess)</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 获取图片数据并保存</span></span><br><span class="line">        image_data = sess.run(value)</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'read/test_%d.jpg'</span> % i, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(image_data)</span><br><span class="line"><span class="comment"># 程序最后会抛出一个OutOfRangeError，这是epoch跑完，队列关闭的标志</span></span><br></pre></td></tr></table></figure>

<p>结果如下：<br><img src="images/abc15.PNG" alt="生成15张图片"></p>
<h3 id="将CIFAR-10数据保存为图片"><a href="#将CIFAR-10数据保存为图片" class="headerlink" title="将CIFAR-10数据保存为图片"></a>将CIFAR-10数据保存为图片</h3><p>一个样本由3073个字节组成，第一个是标签，剩下的是图像数据。</p>
<p>如何使用TensorFlow读取数据？</p>
<p>1.用<code>tf.train.string_input_producer</code>建立队列</p>
<p>2.通过<code>reader.read</code>读数据，一个文件就是一张图片，所以用<code>tf.WholeFileReader()</code>,这里的数据是固定字节的，所以要用<code>tf.FixedLengthRecordReader()</code></p>
<p>3.调用<code>tf.train.start_queue_runner</code></p>
<p>4.通过<code>sess.run()</code>取出图片结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding: utf-8</span></span><br><span class="line"><span class="comment"># 导入当前目录的cifar10_input，这个模块负责读入cifar10数据</span></span><br><span class="line"><span class="keyword">import</span> cifar10_input</span><br><span class="line"><span class="comment"># 导入TensorFlow和其他一些可能用到的模块。</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> scipy.misc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inputs_origin</span><span class="params">(data_dir)</span>:</span></span><br><span class="line">  <span class="comment"># filenames一共5个，从data_batch_1.bin到data_batch_5.bin</span></span><br><span class="line">  <span class="comment"># 读入的都是训练图像</span></span><br><span class="line">  filenames = [os.path.join(data_dir, <span class="string">'data_batch_%d.bin'</span> % i)</span><br><span class="line">               <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">6</span>)]</span><br><span class="line">  <span class="comment"># 判断文件是否存在</span></span><br><span class="line">  <span class="keyword">for</span> f <span class="keyword">in</span> filenames:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> tf.gfile.Exists(f):</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">'Failed to find file: '</span> + f)</span><br><span class="line">  <span class="comment"># 将文件名的list包装成TensorFlow中queue的形式</span></span><br><span class="line">  filename_queue = tf.train.string_input_producer(filenames)</span><br><span class="line">  <span class="comment"># cifar10_input.read_cifar10是事先写好的从queue中读取文件的函数</span></span><br><span class="line">  <span class="comment"># 返回的结果read_input的属性uint8image就是图像的Tensor</span></span><br><span class="line">  read_input = cifar10_input.read_cifar10(filename_queue)</span><br><span class="line">  <span class="comment"># 将图片转换为实数形式</span></span><br><span class="line">  reshaped_image = tf.cast(read_input.uint8image, tf.float32)</span><br><span class="line">  <span class="comment"># 返回的reshaped_image是一张图片的tensor</span></span><br><span class="line">  <span class="comment"># 我们应当这样理解reshaped_image：每次使用sess.run(reshaped_image)，就会取出一张图片</span></span><br><span class="line">  <span class="keyword">return</span> reshaped_image</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  <span class="comment"># 创建一个会话sess</span></span><br><span class="line">  <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 调用inputs_origin。cifar10_data/cifar-10-batches-bin是我们下载的数据的文件夹位置</span></span><br><span class="line">    reshaped_image = inputs_origin(<span class="string">'cifar10_data/cifar-10-batches-bin'</span>)</span><br><span class="line">    <span class="comment"># 这一步start_queue_runner很重要。</span></span><br><span class="line">    <span class="comment"># 我们之前有filename_queue = tf.train.string_input_producer(filenames)</span></span><br><span class="line">    <span class="comment"># 这个queue必须通过start_queue_runners才能启动</span></span><br><span class="line">    <span class="comment"># 缺少start_queue_runners程序将不能执行</span></span><br><span class="line">    threads = tf.train.start_queue_runners(sess=sess)</span><br><span class="line">    <span class="comment"># 变量初始化</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="comment"># 创建文件夹cifar10_data/raw/</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'cifar10_data/raw/'</span>):</span><br><span class="line">      os.makedirs(<span class="string">'cifar10_data/raw/'</span>)</span><br><span class="line">    <span class="comment"># 保存30张图片</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">30</span>):</span><br><span class="line">      <span class="comment"># 每次sess.run(reshaped_image)，都会取出一张图片</span></span><br><span class="line">      image_array = sess.run(reshaped_image)</span><br><span class="line">      <span class="comment"># 将图片保存</span></span><br><span class="line">      scipy.misc.toimage(image_array).save(<span class="string">'cifar10_data/raw/%d.jpg'</span> % i)</span><br></pre></td></tr></table></figure>

<p><img src="images/30cifar.PNG" alt></p>
<h2 id="TensorFlow-训练-CIFAR-10"><a href="#TensorFlow-训练-CIFAR-10" class="headerlink" title="TensorFlow 训练 CIFAR-10"></a>TensorFlow 训练 CIFAR-10</h2><h3 id="数据增强常用方法"><a href="#数据增强常用方法" class="headerlink" title="数据增强常用方法"></a>数据增强常用方法</h3><table>
<thead>
<tr>
<th align="left">方法</th>
<th align="right">介绍</th>
</tr>
</thead>
<tbody><tr>
<td align="left">平移：</td>
<td align="right">一定尺度范围的平移</td>
</tr>
<tr>
<td align="left">旋转：</td>
<td align="right">一定尺度范围的旋转</td>
</tr>
<tr>
<td align="left">翻转：</td>
<td align="right">水平或垂直翻转</td>
</tr>
<tr>
<td align="left">裁剪：</td>
<td align="right">原有图像裁剪</td>
</tr>
<tr>
<td align="left">缩放：</td>
<td align="right">一定尺度的放大缩小</td>
</tr>
<tr>
<td align="left">颜色变换</td>
<td align="right">对图像的RGB颜色空间进行变换</td>
</tr>
<tr>
<td align="left">噪声扰动</td>
<td align="right">给图像加入一些人工产生的噪声</td>
</tr>
</tbody></table>
<h3 id="TensorFlow中数据增强的实现"><a href="#TensorFlow中数据增强的实现" class="headerlink" title="TensorFlow中数据增强的实现"></a>TensorFlow中数据增强的实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Randomly crop a [height, width] section of the image.</span></span><br><span class="line">随机裁剪</span><br><span class="line">distorted_image = tf.random_crop(reshaped_image, [height, width, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">随机翻转</span><br><span class="line"><span class="comment"># Randomly flip the image horizontally.</span></span><br><span class="line">distorted_image = tf.image.random_flip_left_right(distorted_image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Because these operations are not commutative, consider randomizing</span></span><br><span class="line"><span class="comment"># the order their operation.</span></span><br><span class="line">随机改变亮度和对比度</span><br><span class="line">distorted_image = tf.image.random_brightness(distorted_image,</span><br><span class="line">                                               max_delta=<span class="number">63</span>)</span><br><span class="line">distorted_image = tf.image.random_contrast(distorted_image,</span><br><span class="line">                                             lower=<span class="number">0.2</span>, upper=<span class="number">1.8</span>)</span><br></pre></td></tr></table></figure>

<h3 id="CIFAR-10识别模型"><a href="#CIFAR-10识别模型" class="headerlink" title="CIFAR-10识别模型"></a>CIFAR-10识别模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span><span class="params">(images)</span>:</span></span><br><span class="line">  <span class="string">"""Build the CIFAR-10 model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    images: Images returned from distorted_inputs() or inputs().</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    Logits.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># We instantiate all variables using tf.get_variable() instead of</span></span><br><span class="line">  <span class="comment"># tf.Variable() in order to share variables across multiple GPU training runs.</span></span><br><span class="line">  <span class="comment"># If we only ran this model on a single GPU, we could simplify this function</span></span><br><span class="line">  <span class="comment"># by replacing all instances of tf.get_variable() with tf.Variable().</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># conv1</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">'conv1'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    kernel = _variable_with_weight_decay(<span class="string">'weights'</span>,</span><br><span class="line">                                         shape=[<span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">64</span>],</span><br><span class="line">                                         stddev=<span class="number">5e-2</span>,</span><br><span class="line">                                         wd=<span class="number">0.0</span>)</span><br><span class="line">    conv = tf.nn.conv2d(images, kernel, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    biases = _variable_on_cpu(<span class="string">'biases'</span>, [<span class="number">64</span>], tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line">    pre_activation = tf.nn.bias_add(conv, biases)</span><br><span class="line">    conv1 = tf.nn.relu(pre_activation, name=scope.name)</span><br><span class="line">    _activation_summary(conv1)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># pool1</span></span><br><span class="line">  pool1 = tf.nn.max_pool(conv1, ksize=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                         padding=<span class="string">'SAME'</span>, name=<span class="string">'pool1'</span>)</span><br><span class="line">  <span class="comment"># norm1</span></span><br><span class="line">  norm1 = tf.nn.lrn(pool1, <span class="number">4</span>, bias=<span class="number">1.0</span>, alpha=<span class="number">0.001</span> / <span class="number">9.0</span>, beta=<span class="number">0.75</span>,</span><br><span class="line">                    name=<span class="string">'norm1'</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># conv2</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">'conv2'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    kernel = _variable_with_weight_decay(<span class="string">'weights'</span>,</span><br><span class="line">                                         shape=[<span class="number">5</span>, <span class="number">5</span>, <span class="number">64</span>, <span class="number">64</span>],</span><br><span class="line">                                         stddev=<span class="number">5e-2</span>,</span><br><span class="line">                                         wd=<span class="number">0.0</span>)</span><br><span class="line">    conv = tf.nn.conv2d(norm1, kernel, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    biases = _variable_on_cpu(<span class="string">'biases'</span>, [<span class="number">64</span>], tf.constant_initializer(<span class="number">0.1</span>))</span><br><span class="line">    pre_activation = tf.nn.bias_add(conv, biases)</span><br><span class="line">    conv2 = tf.nn.relu(pre_activation, name=scope.name)</span><br><span class="line">    _activation_summary(conv2)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># norm2</span></span><br><span class="line">  norm2 = tf.nn.lrn(conv2, <span class="number">4</span>, bias=<span class="number">1.0</span>, alpha=<span class="number">0.001</span> / <span class="number">9.0</span>, beta=<span class="number">0.75</span>,</span><br><span class="line">                    name=<span class="string">'norm2'</span>)</span><br><span class="line">  <span class="comment"># pool2</span></span><br><span class="line">  pool2 = tf.nn.max_pool(norm2, ksize=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">                         strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>, name=<span class="string">'pool2'</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># local3</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">'local3'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    <span class="comment"># Move everything into depth so we can perform a single matrix multiply.</span></span><br><span class="line">    reshape = tf.reshape(pool2, [FLAGS.batch_size, <span class="number">-1</span>])</span><br><span class="line">    dim = reshape.get_shape()[<span class="number">1</span>].value</span><br><span class="line">    weights = _variable_with_weight_decay(<span class="string">'weights'</span>, shape=[dim, <span class="number">384</span>],</span><br><span class="line">                                          stddev=<span class="number">0.04</span>, wd=<span class="number">0.004</span>)</span><br><span class="line">    biases = _variable_on_cpu(<span class="string">'biases'</span>, [<span class="number">384</span>], tf.constant_initializer(<span class="number">0.1</span>))</span><br><span class="line">    local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)</span><br><span class="line">    _activation_summary(local3)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># local4</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">'local4'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    weights = _variable_with_weight_decay(<span class="string">'weights'</span>, shape=[<span class="number">384</span>, <span class="number">192</span>],</span><br><span class="line">                                          stddev=<span class="number">0.04</span>, wd=<span class="number">0.004</span>)</span><br><span class="line">    biases = _variable_on_cpu(<span class="string">'biases'</span>, [<span class="number">192</span>], tf.constant_initializer(<span class="number">0.1</span>))</span><br><span class="line">    local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)</span><br><span class="line">    _activation_summary(local4)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># linear layer(WX + b),</span></span><br><span class="line">  <span class="comment"># We don't apply softmax here because</span></span><br><span class="line">  <span class="comment"># tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits</span></span><br><span class="line">  <span class="comment"># and performs the softmax internally for efficiency.</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">'softmax_linear'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    weights = _variable_with_weight_decay(<span class="string">'weights'</span>, [<span class="number">192</span>, NUM_CLASSES],</span><br><span class="line">                                          stddev=<span class="number">1</span>/<span class="number">192.0</span>, wd=<span class="number">0.0</span>)</span><br><span class="line">    biases = _variable_on_cpu(<span class="string">'biases'</span>, [NUM_CLASSES],</span><br><span class="line">                              tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line">    softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)</span><br><span class="line">    _activation_summary(softmax_linear)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> softmax_linear</span><br></pre></td></tr></table></figure>

<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python cifar10_train.py --train_dir cifar10_train/ --data_dir</span><br></pre></td></tr></table></figure>

<h3 id="在TensorFlow中查看训练进度"><a href="#在TensorFlow中查看训练进度" class="headerlink" title="在TensorFlow中查看训练进度"></a>在TensorFlow中查看训练进度</h3><p>要使用TensorBoard,打开另一个命令窗口，切换到当前目录，输入以下命令</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir cifar10_train</span><br></pre></td></tr></table></figure>

<p>默认运行在6006端口，打开浏览器，输入<code>http://127.0.0.1:6006</code>或<code>http://localhost:6006</code></p>
<blockquote>
<p>注意：如果展开<code>global_step</code>对应的训练速度发生较大的变化，或者越来越慢，可能是程序出现了错误，需要进行检查</p>
</blockquote>
<p>TensorBoard工作原理：在指定训练文件夹cifar10_train下，可以找到一个以events.out开头的文件，在训练过程中，程序将日志<br>信息写入这个文件，运行TensorBoard只要指定训练文件夹，就会自动搜索这个文件，并在网页中显示</p>
<h3 id="测试模型效果"><a href="#测试模型效果" class="headerlink" title="测试模型效果"></a>测试模型效果</h3><figure class="highlight python"><figcaption><span>cifar10_eval.py --data_dir cifar10_data/ --eval_dir cifar10_eval/ --checkpoint_dir cifar10_train/```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; 训练测试不能在同一块GPU上，可能会显存不足，使用另一张显卡的方法是设置不同的`CUDA_VISIBLE_DEVICES`,比如训练先运行：</span><br><span class="line">&gt; `export CUDA_VISIBLE_DEVICES=<span class="number">0</span>`再进行训练，测试使用<span class="number">1</span>就可以了</span><br><span class="line"></span><br><span class="line"><span class="comment"># 附录</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## cifar10.py</span></span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="comment"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""Builds the CIFAR-10 network.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Summary of available functions:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> # Compute input images and labels for training. If you would like to run</span></span><br><span class="line"><span class="string"> # evaluations, use inputs() instead.</span></span><br><span class="line"><span class="string"> inputs, labels = distorted_inputs()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> # Compute inference on the model inputs to make a prediction.</span></span><br><span class="line"><span class="string"> predictions = inference(inputs)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> # Compute the total loss of the prediction with respect to the labels.</span></span><br><span class="line"><span class="string"> loss = loss(predictions, labels)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> # Create a graph to run one step of training with respect to the loss.</span></span><br><span class="line"><span class="string"> train_op = train(loss, global_step)</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># pylint: disable=missing-docstring</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cifar10_input</span><br><span class="line"></span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line"></span><br><span class="line"><span class="comment"># Basic model parameters.</span></span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'batch_size'</span>, <span class="number">128</span>,</span><br><span class="line">                            <span class="string">"""Number of images to process in a batch."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">'data_dir'</span>, <span class="string">'/tmp/cifar10_data'</span>,</span><br><span class="line">                           <span class="string">"""Path to the CIFAR-10 data directory."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_boolean(<span class="string">'use_fp16'</span>, <span class="literal">False</span>,</span><br><span class="line">                            <span class="string">"""Train the model using fp16."""</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Global constants describing the CIFAR-10 data set.</span></span><br><span class="line">IMAGE_SIZE = cifar10_input.IMAGE_SIZE</span><br><span class="line">NUM_CLASSES = cifar10_input.NUM_CLASSES</span><br><span class="line">NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN</span><br><span class="line">NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_EVAL</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Constants describing the training process.</span></span><br><span class="line">MOVING_AVERAGE_DECAY = <span class="number">0.9999</span>     <span class="comment"># The decay to use for the moving average.</span></span><br><span class="line">NUM_EPOCHS_PER_DECAY = <span class="number">350.0</span>      <span class="comment"># Epochs after which learning rate decays.</span></span><br><span class="line">LEARNING_RATE_DECAY_FACTOR = <span class="number">0.1</span>  <span class="comment"># Learning rate decay factor.</span></span><br><span class="line">INITIAL_LEARNING_RATE = <span class="number">0.1</span>       <span class="comment"># Initial learning rate.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># If a model is trained with multiple GPUs, prefix all Op names with tower_name</span></span><br><span class="line"><span class="comment"># to differentiate the operations. Note that this prefix is removed from the</span></span><br><span class="line"><span class="comment"># names of the summaries when visualizing a model.</span></span><br><span class="line">TOWER_NAME = <span class="string">'tower'</span></span><br><span class="line"></span><br><span class="line">DATA_URL = <span class="string">'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_activation_summary</span><span class="params">(x)</span>:</span></span><br><span class="line">  <span class="string">"""Helper to create summaries for activations.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Creates a summary that provides a histogram of activations.</span></span><br><span class="line"><span class="string">  Creates a summary that measures the sparsity of activations.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    x: Tensor</span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    nothing</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training</span></span><br><span class="line">  <span class="comment"># session. This helps the clarity of presentation on tensorboard.</span></span><br><span class="line">  tensor_name = re.sub(<span class="string">'%s_[0-9]*/'</span> % TOWER_NAME, <span class="string">''</span>, x.op.name)</span><br><span class="line">  tf.summary.histogram(tensor_name + <span class="string">'/activations'</span>, x)</span><br><span class="line">  tf.summary.scalar(tensor_name + <span class="string">'/sparsity'</span>,</span><br><span class="line">                                       tf.nn.zero_fraction(x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_variable_on_cpu</span><span class="params">(name, shape, initializer)</span>:</span></span><br><span class="line">  <span class="string">"""Helper to create a Variable stored on CPU memory.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    name: name of the variable</span></span><br><span class="line"><span class="string">    shape: list of ints</span></span><br><span class="line"><span class="string">    initializer: initializer for Variable</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    Variable Tensor</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line">    dtype = tf.float16 <span class="keyword">if</span> FLAGS.use_fp16 <span class="keyword">else</span> tf.float32</span><br><span class="line">    var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)</span><br><span class="line">  <span class="keyword">return</span> var</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_variable_with_weight_decay</span><span class="params">(name, shape, stddev, wd)</span>:</span></span><br><span class="line">  <span class="string">"""Helper to create an initialized Variable with weight decay.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Note that the Variable is initialized with a truncated normal distribution.</span></span><br><span class="line"><span class="string">  A weight decay is added only if one is specified.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    name: name of the variable</span></span><br><span class="line"><span class="string">    shape: list of ints</span></span><br><span class="line"><span class="string">    stddev: standard deviation of a truncated Gaussian</span></span><br><span class="line"><span class="string">    wd: add L2Loss weight decay multiplied by this float. If None, weight</span></span><br><span class="line"><span class="string">        decay is not added for this Variable.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    Variable Tensor</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  dtype = tf.float16 <span class="keyword">if</span> FLAGS.use_fp16 <span class="keyword">else</span> tf.float32</span><br><span class="line">  var = _variable_on_cpu(</span><br><span class="line">      name,</span><br><span class="line">      shape,</span><br><span class="line">      tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))</span><br><span class="line">  <span class="keyword">if</span> wd <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name=<span class="string">'weight_loss'</span>)</span><br><span class="line">    tf.add_to_collection(<span class="string">'losses'</span>, weight_decay)</span><br><span class="line">  <span class="keyword">return</span> var</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distorted_inputs</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="string">"""Construct distorted input for CIFAR training using the Reader ops.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.</span></span><br><span class="line"><span class="string">    labels: Labels. 1D tensor of [batch_size] size.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Raises:</span></span><br><span class="line"><span class="string">    ValueError: If no data_dir</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> FLAGS.data_dir:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'Please supply a data_dir'</span>)</span><br><span class="line">  data_dir = os.path.join(FLAGS.data_dir, <span class="string">'cifar-10-batches-bin'</span>)</span><br><span class="line">  images, labels = cifar10_input.distorted_inputs(data_dir=data_dir,</span><br><span class="line">                                                  batch_size=FLAGS.batch_size)</span><br><span class="line">  <span class="keyword">if</span> FLAGS.use_fp16:</span><br><span class="line">    images = tf.cast(images, tf.float16)</span><br><span class="line">    labels = tf.cast(labels, tf.float16)</span><br><span class="line">  <span class="keyword">return</span> images, labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inputs</span><span class="params">(eval_data)</span>:</span></span><br><span class="line">  <span class="string">"""Construct input for CIFAR evaluation using the Reader ops.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    eval_data: bool, indicating if one should use the train or eval data set.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.</span></span><br><span class="line"><span class="string">    labels: Labels. 1D tensor of [batch_size] size.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Raises:</span></span><br><span class="line"><span class="string">    ValueError: If no data_dir</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> FLAGS.data_dir:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'Please supply a data_dir'</span>)</span><br><span class="line">  data_dir = os.path.join(FLAGS.data_dir, <span class="string">'cifar-10-batches-bin'</span>)</span><br><span class="line">  images, labels = cifar10_input.inputs(eval_data=eval_data,</span><br><span class="line">                                        data_dir=data_dir,</span><br><span class="line">                                        batch_size=FLAGS.batch_size)</span><br><span class="line">  <span class="keyword">if</span> FLAGS.use_fp16:</span><br><span class="line">    images = tf.cast(images, tf.float16)</span><br><span class="line">    labels = tf.cast(labels, tf.float16)</span><br><span class="line">  <span class="keyword">return</span> images, labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span><span class="params">(images)</span>:</span></span><br><span class="line">  <span class="string">"""Build the CIFAR-10 model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    images: Images returned from distorted_inputs() or inputs().</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    Logits.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># We instantiate all variables using tf.get_variable() instead of</span></span><br><span class="line">  <span class="comment"># tf.Variable() in order to share variables across multiple GPU training runs.</span></span><br><span class="line">  <span class="comment"># If we only ran this model on a single GPU, we could simplify this function</span></span><br><span class="line">  <span class="comment"># by replacing all instances of tf.get_variable() with tf.Variable().</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># conv1</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">'conv1'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    kernel = _variable_with_weight_decay(<span class="string">'weights'</span>,</span><br><span class="line">                                         shape=[<span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">64</span>],</span><br><span class="line">                                         stddev=<span class="number">5e-2</span>,</span><br><span class="line">                                         wd=<span class="number">0.0</span>)</span><br><span class="line">    conv = tf.nn.conv2d(images, kernel, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    biases = _variable_on_cpu(<span class="string">'biases'</span>, [<span class="number">64</span>], tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line">    pre_activation = tf.nn.bias_add(conv, biases)</span><br><span class="line">    conv1 = tf.nn.relu(pre_activation, name=scope.name)</span><br><span class="line">    _activation_summary(conv1)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># pool1</span></span><br><span class="line">  pool1 = tf.nn.max_pool(conv1, ksize=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                         padding=<span class="string">'SAME'</span>, name=<span class="string">'pool1'</span>)</span><br><span class="line">  <span class="comment"># norm1</span></span><br><span class="line">  norm1 = tf.nn.lrn(pool1, <span class="number">4</span>, bias=<span class="number">1.0</span>, alpha=<span class="number">0.001</span> / <span class="number">9.0</span>, beta=<span class="number">0.75</span>,</span><br><span class="line">                    name=<span class="string">'norm1'</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># conv2</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">'conv2'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    kernel = _variable_with_weight_decay(<span class="string">'weights'</span>,</span><br><span class="line">                                         shape=[<span class="number">5</span>, <span class="number">5</span>, <span class="number">64</span>, <span class="number">64</span>],</span><br><span class="line">                                         stddev=<span class="number">5e-2</span>,</span><br><span class="line">                                         wd=<span class="number">0.0</span>)</span><br><span class="line">    conv = tf.nn.conv2d(norm1, kernel, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    biases = _variable_on_cpu(<span class="string">'biases'</span>, [<span class="number">64</span>], tf.constant_initializer(<span class="number">0.1</span>))</span><br><span class="line">    pre_activation = tf.nn.bias_add(conv, biases)</span><br><span class="line">    conv2 = tf.nn.relu(pre_activation, name=scope.name)</span><br><span class="line">    _activation_summary(conv2)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># norm2</span></span><br><span class="line">  norm2 = tf.nn.lrn(conv2, <span class="number">4</span>, bias=<span class="number">1.0</span>, alpha=<span class="number">0.001</span> / <span class="number">9.0</span>, beta=<span class="number">0.75</span>,</span><br><span class="line">                    name=<span class="string">'norm2'</span>)</span><br><span class="line">  <span class="comment"># pool2</span></span><br><span class="line">  pool2 = tf.nn.max_pool(norm2, ksize=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">                         strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>, name=<span class="string">'pool2'</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># local3</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">'local3'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    <span class="comment"># Move everything into depth so we can perform a single matrix multiply.</span></span><br><span class="line">    reshape = tf.reshape(pool2, [FLAGS.batch_size, <span class="number">-1</span>])</span><br><span class="line">    dim = reshape.get_shape()[<span class="number">1</span>].value</span><br><span class="line">    weights = _variable_with_weight_decay(<span class="string">'weights'</span>, shape=[dim, <span class="number">384</span>],</span><br><span class="line">                                          stddev=<span class="number">0.04</span>, wd=<span class="number">0.004</span>)</span><br><span class="line">    biases = _variable_on_cpu(<span class="string">'biases'</span>, [<span class="number">384</span>], tf.constant_initializer(<span class="number">0.1</span>))</span><br><span class="line">    local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)</span><br><span class="line">    _activation_summary(local3)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># local4</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">'local4'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    weights = _variable_with_weight_decay(<span class="string">'weights'</span>, shape=[<span class="number">384</span>, <span class="number">192</span>],</span><br><span class="line">                                          stddev=<span class="number">0.04</span>, wd=<span class="number">0.004</span>)</span><br><span class="line">    biases = _variable_on_cpu(<span class="string">'biases'</span>, [<span class="number">192</span>], tf.constant_initializer(<span class="number">0.1</span>))</span><br><span class="line">    local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)</span><br><span class="line">    _activation_summary(local4)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># linear layer(WX + b),</span></span><br><span class="line">  <span class="comment"># We don't apply softmax here because</span></span><br><span class="line">  <span class="comment"># tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits</span></span><br><span class="line">  <span class="comment"># and performs the softmax internally for efficiency.</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">'softmax_linear'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    weights = _variable_with_weight_decay(<span class="string">'weights'</span>, [<span class="number">192</span>, NUM_CLASSES],</span><br><span class="line">                                          stddev=<span class="number">1</span>/<span class="number">192.0</span>, wd=<span class="number">0.0</span>)</span><br><span class="line">    biases = _variable_on_cpu(<span class="string">'biases'</span>, [NUM_CLASSES],</span><br><span class="line">                              tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line">    softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)</span><br><span class="line">    _activation_summary(softmax_linear)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> softmax_linear</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(logits, labels)</span>:</span></span><br><span class="line">  <span class="string">"""Add L2Loss to all the trainable variables.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Add summary for "Loss" and "Loss/avg".</span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    logits: Logits from inference().</span></span><br><span class="line"><span class="string">    labels: Labels from distorted_inputs or inputs(). 1-D tensor</span></span><br><span class="line"><span class="string">            of shape [batch_size]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    Loss tensor of type float.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># Calculate the average cross entropy loss across the batch.</span></span><br><span class="line">  labels = tf.cast(labels, tf.int64)</span><br><span class="line">  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(</span><br><span class="line">      labels=labels, logits=logits, name=<span class="string">'cross_entropy_per_example'</span>)</span><br><span class="line">  cross_entropy_mean = tf.reduce_mean(cross_entropy, name=<span class="string">'cross_entropy'</span>)</span><br><span class="line">  tf.add_to_collection(<span class="string">'losses'</span>, cross_entropy_mean)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># The total loss is defined as the cross entropy loss plus all of the weight</span></span><br><span class="line">  <span class="comment"># decay terms (L2 loss).</span></span><br><span class="line">  <span class="keyword">return</span> tf.add_n(tf.get_collection(<span class="string">'losses'</span>), name=<span class="string">'total_loss'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_add_loss_summaries</span><span class="params">(total_loss)</span>:</span></span><br><span class="line">  <span class="string">"""Add summaries for losses in CIFAR-10 model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Generates moving average for all losses and associated summaries for</span></span><br><span class="line"><span class="string">  visualizing the performance of the network.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    total_loss: Total loss from loss().</span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    loss_averages_op: op for generating moving averages of losses.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># Compute the moving average of all individual losses and the total loss.</span></span><br><span class="line">  loss_averages = tf.train.ExponentialMovingAverage(<span class="number">0.9</span>, name=<span class="string">'avg'</span>)</span><br><span class="line">  losses = tf.get_collection(<span class="string">'losses'</span>)</span><br><span class="line">  loss_averages_op = loss_averages.apply(losses + [total_loss])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Attach a scalar summary to all individual losses and the total loss; do the</span></span><br><span class="line">  <span class="comment"># same for the averaged version of the losses.</span></span><br><span class="line">  <span class="keyword">for</span> l <span class="keyword">in</span> losses + [total_loss]:</span><br><span class="line">    <span class="comment"># Name each loss as '(raw)' and name the moving average version of the loss</span></span><br><span class="line">    <span class="comment"># as the original loss name.</span></span><br><span class="line">    tf.summary.scalar(l.op.name + <span class="string">' (raw)'</span>, l)</span><br><span class="line">    tf.summary.scalar(l.op.name, loss_averages.average(l))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> loss_averages_op</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(total_loss, global_step)</span>:</span></span><br><span class="line">  <span class="string">"""Train CIFAR-10 model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Create an optimizer and apply to all trainable variables. Add moving</span></span><br><span class="line"><span class="string">  average for all trainable variables.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    total_loss: Total loss from loss().</span></span><br><span class="line"><span class="string">    global_step: Integer Variable counting the number of training steps</span></span><br><span class="line"><span class="string">      processed.</span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    train_op: op for training.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># Variables that affect learning rate.</span></span><br><span class="line">  num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size</span><br><span class="line">  decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Decay the learning rate exponentially based on the number of steps.</span></span><br><span class="line">  lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE,</span><br><span class="line">                                  global_step,</span><br><span class="line">                                  decay_steps,</span><br><span class="line">                                  LEARNING_RATE_DECAY_FACTOR,</span><br><span class="line">                                  staircase=<span class="literal">True</span>)</span><br><span class="line">  tf.summary.scalar(<span class="string">'learning_rate'</span>, lr)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Generate moving averages of all losses and associated summaries.</span></span><br><span class="line">  loss_averages_op = _add_loss_summaries(total_loss)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Compute gradients.</span></span><br><span class="line">  <span class="keyword">with</span> tf.control_dependencies([loss_averages_op]):</span><br><span class="line">    opt = tf.train.GradientDescentOptimizer(lr)</span><br><span class="line">    grads = opt.compute_gradients(total_loss)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Apply gradients.</span></span><br><span class="line">  apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Add histograms for trainable variables.</span></span><br><span class="line">  <span class="keyword">for</span> var <span class="keyword">in</span> tf.trainable_variables():</span><br><span class="line">    tf.summary.histogram(var.op.name, var)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Add histograms for gradients.</span></span><br><span class="line">  <span class="keyword">for</span> grad, var <span class="keyword">in</span> grads:</span><br><span class="line">    <span class="keyword">if</span> grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">      tf.summary.histogram(var.op.name + <span class="string">'/gradients'</span>, grad)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Track the moving averages of all trainable variables.</span></span><br><span class="line">  variable_averages = tf.train.ExponentialMovingAverage(</span><br><span class="line">      MOVING_AVERAGE_DECAY, global_step)</span><br><span class="line">  variables_averages_op = variable_averages.apply(tf.trainable_variables())</span><br><span class="line"></span><br><span class="line">  <span class="keyword">with</span> tf.control_dependencies([apply_gradient_op, variables_averages_op]):</span><br><span class="line">    train_op = tf.no_op(name=<span class="string">'train'</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> train_op</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maybe_download_and_extract</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="string">"""Download and extract the tarball from Alex's website."""</span></span><br><span class="line">  dest_directory = FLAGS.data_dir</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dest_directory):</span><br><span class="line">    os.makedirs(dest_directory)</span><br><span class="line">  filename = DATA_URL.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">  filepath = os.path.join(dest_directory, filename)</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(filepath):</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_progress</span><span class="params">(count, block_size, total_size)</span>:</span></span><br><span class="line">      sys.stdout.write(<span class="string">'\r&gt;&gt; Downloading %s %.1f%%'</span> % (filename,</span><br><span class="line">          float(count * block_size) / float(total_size) * <span class="number">100.0</span>))</span><br><span class="line">      sys.stdout.flush()</span><br><span class="line">    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)</span><br><span class="line">    print()</span><br><span class="line">    statinfo = os.stat(filepath)</span><br><span class="line">    print(<span class="string">'Successfully downloaded'</span>, filename, statinfo.st_size, <span class="string">'bytes.'</span>)</span><br><span class="line">  extracted_dir_path = os.path.join(dest_directory, <span class="string">'cifar-10-batches-bin'</span>)</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(extracted_dir_path):</span><br><span class="line">    tarfile.open(filepath, <span class="string">'r:gz'</span>).extractall(dest_directory)</span><br></pre></td></tr></table></figure>

<h2 id="cifar10-download-py"><a href="#cifar10-download-py" class="headerlink" title="cifar10_download.py"></a>cifar10_download.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="comment"># 引入当前目录中的已经编写好的cifar10模块</span></span><br><span class="line"><span class="keyword">import</span> cifar10</span><br><span class="line"><span class="comment"># 引入tensorflow</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.app.flags.FLAGS是TensorFlow内部的一个全局变量存储器，同时可以用于命令行参数的处理</span></span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line"><span class="comment"># 在cifar10模块中预先定义了f.app.flags.FLAGS.data_dir为CIFAR-10的数据路径</span></span><br><span class="line"><span class="comment"># 我们把这个路径改为cifar10_data</span></span><br><span class="line">FLAGS.data_dir = <span class="string">'cifar10_data/'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果不存在数据文件，就会执行下载</span></span><br><span class="line">cifar10.maybe_download_and_extract()</span><br></pre></td></tr></table></figure>

<h2 id="cifar10-eval-py"><a href="#cifar10-eval-py" class="headerlink" title="cifar10_eval.py"></a>cifar10_eval.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""Evaluation for CIFAR-10.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Accuracy:</span></span><br><span class="line"><span class="string">cifar10_train.py achieves 83.0% accuracy after 100K steps (256 epochs</span></span><br><span class="line"><span class="string">of data) as judged by cifar10_eval.py.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Speed:</span></span><br><span class="line"><span class="string">On a single Tesla K40, cifar10_train.py processes a single batch of 128 images</span></span><br><span class="line"><span class="string">in 0.25-0.35 sec (i.e. 350 - 600 images /sec). The model reaches ~86%</span></span><br><span class="line"><span class="string">accuracy after 100K steps in 8 hours of training time.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Usage:</span></span><br><span class="line"><span class="string">Please see the tutorial and website for how to download the CIFAR-10</span></span><br><span class="line"><span class="string">data set, compile the program and train the model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">http://tensorflow.org/tutorials/deep_cnn/</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cifar10</span><br><span class="line"></span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line"></span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">'eval_dir'</span>, <span class="string">'/tmp/cifar10_eval'</span>,</span><br><span class="line">                           <span class="string">"""Directory where to write event logs."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">'eval_data'</span>, <span class="string">'test'</span>,</span><br><span class="line">                           <span class="string">"""Either 'test' or 'train_eval'."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">'checkpoint_dir'</span>, <span class="string">'/tmp/cifar10_train'</span>,</span><br><span class="line">                           <span class="string">"""Directory where to read model checkpoints."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'eval_interval_secs'</span>, <span class="number">60</span> * <span class="number">5</span>,</span><br><span class="line">                            <span class="string">"""How often to run the eval."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'num_examples'</span>, <span class="number">10000</span>,</span><br><span class="line">                            <span class="string">"""Number of examples to run."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_boolean(<span class="string">'run_once'</span>, <span class="literal">False</span>,</span><br><span class="line">                         <span class="string">"""Whether to run eval only once."""</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval_once</span><span class="params">(saver, summary_writer, top_k_op, summary_op)</span>:</span></span><br><span class="line">  <span class="string">"""Run Eval once.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    saver: Saver.</span></span><br><span class="line"><span class="string">    summary_writer: Summary writer.</span></span><br><span class="line"><span class="string">    top_k_op: Top K op.</span></span><br><span class="line"><span class="string">    summary_op: Summary op.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)</span><br><span class="line">    <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">      <span class="comment"># Restores from checkpoint</span></span><br><span class="line">      saver.restore(sess, ckpt.model_checkpoint_path)</span><br><span class="line">      <span class="comment"># Assuming model_checkpoint_path looks something like:</span></span><br><span class="line">      <span class="comment">#   /my-favorite-path/cifar10_train/model.ckpt-0,</span></span><br><span class="line">      <span class="comment"># extract global_step from it.</span></span><br><span class="line">      global_step = ckpt.model_checkpoint_path.split(<span class="string">'/'</span>)[<span class="number">-1</span>].split(<span class="string">'-'</span>)[<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      print(<span class="string">'No checkpoint file found'</span>)</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Start the queue runners.</span></span><br><span class="line">    coord = tf.train.Coordinator()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">      threads = []</span><br><span class="line">      <span class="keyword">for</span> qr <span class="keyword">in</span> tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):</span><br><span class="line">        threads.extend(qr.create_threads(sess, coord=coord, daemon=<span class="literal">True</span>,</span><br><span class="line">                                         start=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">      num_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size))</span><br><span class="line">      true_count = <span class="number">0</span>  <span class="comment"># Counts the number of correct predictions.</span></span><br><span class="line">      total_sample_count = num_iter * FLAGS.batch_size</span><br><span class="line">      step = <span class="number">0</span></span><br><span class="line">      <span class="keyword">while</span> step &lt; num_iter <span class="keyword">and</span> <span class="keyword">not</span> coord.should_stop():</span><br><span class="line">        predictions = sess.run([top_k_op])</span><br><span class="line">        true_count += np.sum(predictions)</span><br><span class="line">        step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># Compute precision @ 1.</span></span><br><span class="line">      precision = true_count / total_sample_count</span><br><span class="line">      print(<span class="string">'%s: precision @ 1 = %.3f'</span> % (datetime.now(), precision))</span><br><span class="line"></span><br><span class="line">      summary = tf.Summary()</span><br><span class="line">      summary.ParseFromString(sess.run(summary_op))</span><br><span class="line">      summary.value.add(tag=<span class="string">'Precision @ 1'</span>, simple_value=precision)</span><br><span class="line">      summary_writer.add_summary(summary, global_step)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:  <span class="comment"># pylint: disable=broad-except</span></span><br><span class="line">      coord.request_stop(e)</span><br><span class="line"></span><br><span class="line">    coord.request_stop()</span><br><span class="line">    coord.join(threads, stop_grace_period_secs=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="string">"""Eval CIFAR-10 for a number of steps."""</span></span><br><span class="line">  <span class="keyword">with</span> tf.Graph().as_default() <span class="keyword">as</span> g:</span><br><span class="line">    <span class="comment"># Get images and labels for CIFAR-10.</span></span><br><span class="line">    eval_data = FLAGS.eval_data == <span class="string">'test'</span></span><br><span class="line">    images, labels = cifar10.inputs(eval_data=eval_data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build a Graph that computes the logits predictions from the</span></span><br><span class="line">    <span class="comment"># inference model.</span></span><br><span class="line">    logits = cifar10.inference(images)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate predictions.</span></span><br><span class="line">    top_k_op = tf.nn.in_top_k(logits, labels, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Restore the moving average version of the learned variables for eval.</span></span><br><span class="line">    variable_averages = tf.train.ExponentialMovingAverage(</span><br><span class="line">        cifar10.MOVING_AVERAGE_DECAY)</span><br><span class="line">    variables_to_restore = variable_averages.variables_to_restore()</span><br><span class="line">    saver = tf.train.Saver(variables_to_restore)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build the summary operation based on the TF collection of Summaries.</span></span><br><span class="line">    summary_op = tf.summary.merge_all()</span><br><span class="line"></span><br><span class="line">    summary_writer = tf.summary.FileWriter(FLAGS.eval_dir, g)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">      eval_once(saver, summary_writer, top_k_op, summary_op)</span><br><span class="line">      <span class="keyword">if</span> FLAGS.run_once:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">      time.sleep(FLAGS.eval_interval_secs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(argv=None)</span>:</span>  <span class="comment"># pylint: disable=unused-argument</span></span><br><span class="line">  cifar10.maybe_download_and_extract()</span><br><span class="line">  <span class="keyword">if</span> tf.gfile.Exists(FLAGS.eval_dir):</span><br><span class="line">    tf.gfile.DeleteRecursively(FLAGS.eval_dir)</span><br><span class="line">  tf.gfile.MakeDirs(FLAGS.eval_dir)</span><br><span class="line">  evaluate()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  tf.app.run()</span><br></pre></td></tr></table></figure>

<h2 id="cifar10-extract-py"><a href="#cifar10-extract-py" class="headerlink" title="cifar10_extract.py"></a>cifar10_extract.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding: utf-8</span></span><br><span class="line"><span class="comment"># 导入当前目录的cifar10_input，这个模块负责读入cifar10数据</span></span><br><span class="line"><span class="keyword">import</span> cifar10_input</span><br><span class="line"><span class="comment"># 导入TensorFlow和其他一些可能用到的模块。</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> scipy.misc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inputs_origin</span><span class="params">(data_dir)</span>:</span></span><br><span class="line">  <span class="comment"># filenames一共5个，从data_batch_1.bin到data_batch_5.bin</span></span><br><span class="line">  <span class="comment"># 读入的都是训练图像</span></span><br><span class="line">  filenames = [os.path.join(data_dir, <span class="string">'data_batch_%d.bin'</span> % i)</span><br><span class="line">               <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1</span>, <span class="number">6</span>)]</span><br><span class="line">  <span class="comment"># 判断文件是否存在</span></span><br><span class="line">  <span class="keyword">for</span> f <span class="keyword">in</span> filenames:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> tf.gfile.Exists(f):</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">'Failed to find file: '</span> + f)</span><br><span class="line">  <span class="comment"># 将文件名的list包装成TensorFlow中queue的形式</span></span><br><span class="line">  filename_queue = tf.train.string_input_producer(filenames)</span><br><span class="line">  <span class="comment"># cifar10_input.read_cifar10是事先写好的从queue中读取文件的函数</span></span><br><span class="line">  <span class="comment"># 返回的结果read_input的属性uint8image就是图像的Tensor</span></span><br><span class="line">  read_input = cifar10_input.read_cifar10(filename_queue)</span><br><span class="line">  <span class="comment"># 将图片转换为实数形式</span></span><br><span class="line">  reshaped_image = tf.cast(read_input.uint8image, tf.float32)</span><br><span class="line">  <span class="comment"># 返回的reshaped_image是一张图片的tensor</span></span><br><span class="line">  <span class="comment"># 我们应当这样理解reshaped_image：每次使用sess.run(reshaped_image)，就会取出一张图片</span></span><br><span class="line">  <span class="keyword">return</span> reshaped_image</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  <span class="comment"># 创建一个会话sess</span></span><br><span class="line">  <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 调用inputs_origin。cifar10_data/cifar-10-batches-bin是我们下载的数据的文件夹位置</span></span><br><span class="line">    reshaped_image = inputs_origin(<span class="string">'cifar10_data/cifar-10-batches-bin'</span>)</span><br><span class="line">    <span class="comment"># 这一步start_queue_runner很重要。</span></span><br><span class="line">    <span class="comment"># 我们之前有filename_queue = tf.train.string_input_producer(filenames)</span></span><br><span class="line">    <span class="comment"># 这个queue必须通过start_queue_runners才能启动</span></span><br><span class="line">    <span class="comment"># 缺少start_queue_runners程序将不能执行</span></span><br><span class="line">    threads = tf.train.start_queue_runners(sess=sess)</span><br><span class="line">    <span class="comment"># 变量初始化</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="comment"># 创建文件夹cifar10_data/raw/</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'cifar10_data/raw/'</span>):</span><br><span class="line">      os.makedirs(<span class="string">'cifar10_data/raw/'</span>)</span><br><span class="line">    <span class="comment"># 保存30张图片</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">30</span>):</span><br><span class="line">      <span class="comment"># 每次sess.run(reshaped_image)，都会取出一张图片</span></span><br><span class="line">      image_array = sess.run(reshaped_image)</span><br><span class="line">      <span class="comment"># 将图片保存</span></span><br><span class="line">      scipy.misc.toimage(image_array).save(<span class="string">'cifar10_data/raw/%d.jpg'</span> % i)</span><br></pre></td></tr></table></figure>

<h2 id="cifar10-input-py"><a href="#cifar10-input-py" class="headerlink" title="cifar10_input.py"></a>cifar10_input.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""Routine for decoding the CIFAR-10 binary file format."""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> xrange  <span class="comment"># pylint: disable=redefined-builtin</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Process images of this size. Note that this differs from the original CIFAR</span></span><br><span class="line"><span class="comment"># image size of 32 x 32. If one alters this number, then the entire model</span></span><br><span class="line"><span class="comment"># architecture will change and any model would need to be retrained.</span></span><br><span class="line">IMAGE_SIZE = <span class="number">24</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Global constants describing the CIFAR-10 data set.</span></span><br><span class="line">NUM_CLASSES = <span class="number">10</span></span><br><span class="line">NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = <span class="number">50000</span></span><br><span class="line">NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_cifar10</span><span class="params">(filename_queue)</span>:</span></span><br><span class="line">  <span class="string">"""Reads and parses examples from CIFAR10 data files.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Recommendation: if you want N-way read parallelism, call this function</span></span><br><span class="line"><span class="string">  N times.  This will give you N independent Readers reading different</span></span><br><span class="line"><span class="string">  files &amp; positions within those files, which will give better mixing of</span></span><br><span class="line"><span class="string">  examples.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    filename_queue: A queue of strings with the filenames to read from.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    An object representing a single example, with the following fields:</span></span><br><span class="line"><span class="string">      height: number of rows in the result (32)</span></span><br><span class="line"><span class="string">      width: number of columns in the result (32)</span></span><br><span class="line"><span class="string">      depth: number of color channels in the result (3)</span></span><br><span class="line"><span class="string">      key: a scalar string Tensor describing the filename &amp; record number</span></span><br><span class="line"><span class="string">        for this example.</span></span><br><span class="line"><span class="string">      label: an int32 Tensor with the label in the range 0..9.</span></span><br><span class="line"><span class="string">      uint8image: a [height, width, depth] uint8 Tensor with the image data</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">CIFAR10Record</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">  result = CIFAR10Record()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Dimensions of the images in the CIFAR-10 dataset.</span></span><br><span class="line">  <span class="comment"># See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the</span></span><br><span class="line">  <span class="comment"># input format.</span></span><br><span class="line">  label_bytes = <span class="number">1</span>  <span class="comment"># 2 for CIFAR-100</span></span><br><span class="line">  result.height = <span class="number">32</span></span><br><span class="line">  result.width = <span class="number">32</span></span><br><span class="line">  result.depth = <span class="number">3</span></span><br><span class="line">  image_bytes = result.height * result.width * result.depth</span><br><span class="line">  <span class="comment"># Every record consists of a label followed by the image, with a</span></span><br><span class="line">  <span class="comment"># fixed number of bytes for each.</span></span><br><span class="line">  record_bytes = label_bytes + image_bytes</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Read a record, getting filenames from the filename_queue.  No</span></span><br><span class="line">  <span class="comment"># header or footer in the CIFAR-10 format, so we leave header_bytes</span></span><br><span class="line">  <span class="comment"># and footer_bytes at their default of 0.</span></span><br><span class="line">  reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)</span><br><span class="line">  result.key, value = reader.read(filename_queue)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Convert from a string to a vector of uint8 that is record_bytes long.</span></span><br><span class="line">  record_bytes = tf.decode_raw(value, tf.uint8)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># The first bytes represent the label, which we convert from uint8-&gt;int32.</span></span><br><span class="line">  result.label = tf.cast(</span><br><span class="line">      tf.strided_slice(record_bytes, [<span class="number">0</span>], [label_bytes]), tf.int32)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># The remaining bytes after the label represent the image, which we reshape</span></span><br><span class="line">  <span class="comment"># from [depth * height * width] to [depth, height, width].</span></span><br><span class="line">  depth_major = tf.reshape(</span><br><span class="line">      tf.strided_slice(record_bytes, [label_bytes],</span><br><span class="line">                       [label_bytes + image_bytes]),</span><br><span class="line">      [result.depth, result.height, result.width])</span><br><span class="line">  <span class="comment"># Convert from [depth, height, width] to [height, width, depth].</span></span><br><span class="line">  result.uint8image = tf.transpose(depth_major, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_generate_image_and_label_batch</span><span class="params">(image, label, min_queue_examples,</span></span></span><br><span class="line"><span class="function"><span class="params">                                    batch_size, shuffle)</span>:</span></span><br><span class="line">  <span class="string">"""Construct a queued batch of images and labels.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    image: 3-D Tensor of [height, width, 3] of type.float32.</span></span><br><span class="line"><span class="string">    label: 1-D Tensor of type.int32</span></span><br><span class="line"><span class="string">    min_queue_examples: int32, minimum number of samples to retain</span></span><br><span class="line"><span class="string">      in the queue that provides of batches of examples.</span></span><br><span class="line"><span class="string">    batch_size: Number of images per batch.</span></span><br><span class="line"><span class="string">    shuffle: boolean indicating whether to use a shuffling queue.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    images: Images. 4D tensor of [batch_size, height, width, 3] size.</span></span><br><span class="line"><span class="string">    labels: Labels. 1D tensor of [batch_size] size.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># Create a queue that shuffles the examples, and then</span></span><br><span class="line">  <span class="comment"># read 'batch_size' images + labels from the example queue.</span></span><br><span class="line">  num_preprocess_threads = <span class="number">16</span></span><br><span class="line">  <span class="keyword">if</span> shuffle:</span><br><span class="line">    images, label_batch = tf.train.shuffle_batch(</span><br><span class="line">        [image, label],</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        num_threads=num_preprocess_threads,</span><br><span class="line">        capacity=min_queue_examples + <span class="number">3</span> * batch_size,</span><br><span class="line">        min_after_dequeue=min_queue_examples)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    images, label_batch = tf.train.batch(</span><br><span class="line">        [image, label],</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        num_threads=num_preprocess_threads,</span><br><span class="line">        capacity=min_queue_examples + <span class="number">3</span> * batch_size)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Display the training images in the visualizer.</span></span><br><span class="line">  tf.summary.image(<span class="string">'images'</span>, images)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> images, tf.reshape(label_batch, [batch_size])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distorted_inputs</span><span class="params">(data_dir, batch_size)</span>:</span></span><br><span class="line">  <span class="string">"""Construct distorted input for CIFAR training using the Reader ops.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    data_dir: Path to the CIFAR-10 data directory.</span></span><br><span class="line"><span class="string">    batch_size: Number of images per batch.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.</span></span><br><span class="line"><span class="string">    labels: Labels. 1D tensor of [batch_size] size.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  filenames = [os.path.join(data_dir, <span class="string">'data_batch_%d.bin'</span> % i)</span><br><span class="line">               <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1</span>, <span class="number">6</span>)]</span><br><span class="line">  <span class="keyword">for</span> f <span class="keyword">in</span> filenames:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> tf.gfile.Exists(f):</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">'Failed to find file: '</span> + f)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Create a queue that produces the filenames to read.</span></span><br><span class="line">  filename_queue = tf.train.string_input_producer(filenames)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Read examples from files in the filename queue.</span></span><br><span class="line">  read_input = read_cifar10(filename_queue)</span><br><span class="line">  reshaped_image = tf.cast(read_input.uint8image, tf.float32)</span><br><span class="line"></span><br><span class="line">  height = IMAGE_SIZE</span><br><span class="line">  width = IMAGE_SIZE</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Image processing for training the network. Note the many random</span></span><br><span class="line">  <span class="comment"># distortions applied to the image.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Randomly crop a [height, width] section of the image.</span></span><br><span class="line">  distorted_image = tf.random_crop(reshaped_image, [height, width, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Randomly flip the image horizontally.</span></span><br><span class="line">  distorted_image = tf.image.random_flip_left_right(distorted_image)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Because these operations are not commutative, consider randomizing</span></span><br><span class="line">  <span class="comment"># the order their operation.</span></span><br><span class="line">  distorted_image = tf.image.random_brightness(distorted_image,</span><br><span class="line">                                               max_delta=<span class="number">63</span>)</span><br><span class="line">  distorted_image = tf.image.random_contrast(distorted_image,</span><br><span class="line">                                             lower=<span class="number">0.2</span>, upper=<span class="number">1.8</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Subtract off the mean and divide by the variance of the pixels.</span></span><br><span class="line">  float_image = tf.image.per_image_standardization(distorted_image)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Set the shapes of tensors.</span></span><br><span class="line">  float_image.set_shape([height, width, <span class="number">3</span>])</span><br><span class="line">  read_input.label.set_shape([<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Ensure that the random shuffling has good mixing properties.</span></span><br><span class="line">  min_fraction_of_examples_in_queue = <span class="number">0.4</span></span><br><span class="line">  min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *</span><br><span class="line">                           min_fraction_of_examples_in_queue)</span><br><span class="line">  print(<span class="string">'Filling queue with %d CIFAR images before starting to train. '</span></span><br><span class="line">        <span class="string">'This will take a few minutes.'</span> % min_queue_examples)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Generate a batch of images and labels by building up a queue of examples.</span></span><br><span class="line">  <span class="keyword">return</span> _generate_image_and_label_batch(float_image, read_input.label,</span><br><span class="line">                                         min_queue_examples, batch_size,</span><br><span class="line">                                         shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inputs</span><span class="params">(eval_data, data_dir, batch_size)</span>:</span></span><br><span class="line">  <span class="string">"""Construct input for CIFAR evaluation using the Reader ops.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    eval_data: bool, indicating if one should use the train or eval data set.</span></span><br><span class="line"><span class="string">    data_dir: Path to the CIFAR-10 data directory.</span></span><br><span class="line"><span class="string">    batch_size: Number of images per batch.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.</span></span><br><span class="line"><span class="string">    labels: Labels. 1D tensor of [batch_size] size.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> eval_data:</span><br><span class="line">    filenames = [os.path.join(data_dir, <span class="string">'data_batch_%d.bin'</span> % i)</span><br><span class="line">                 <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1</span>, <span class="number">6</span>)]</span><br><span class="line">    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    filenames = [os.path.join(data_dir, <span class="string">'test_batch.bin'</span>)]</span><br><span class="line">    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> f <span class="keyword">in</span> filenames:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> tf.gfile.Exists(f):</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">'Failed to find file: '</span> + f)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Create a queue that produces the filenames to read.</span></span><br><span class="line">  filename_queue = tf.train.string_input_producer(filenames)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Read examples from files in the filename queue.</span></span><br><span class="line">  read_input = read_cifar10(filename_queue)</span><br><span class="line">  reshaped_image = tf.cast(read_input.uint8image, tf.float32)</span><br><span class="line"></span><br><span class="line">  height = IMAGE_SIZE</span><br><span class="line">  width = IMAGE_SIZE</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Image processing for evaluation.</span></span><br><span class="line">  <span class="comment"># Crop the central [height, width] of the image.</span></span><br><span class="line">  resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,</span><br><span class="line">                                                         height, width)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Subtract off the mean and divide by the variance of the pixels.</span></span><br><span class="line">  float_image = tf.image.per_image_standardization(resized_image)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Set the shapes of tensors.</span></span><br><span class="line">  float_image.set_shape([height, width, <span class="number">3</span>])</span><br><span class="line">  read_input.label.set_shape([<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Ensure that the random shuffling has good mixing properties.</span></span><br><span class="line">  min_fraction_of_examples_in_queue = <span class="number">0.4</span></span><br><span class="line">  min_queue_examples = int(num_examples_per_epoch *</span><br><span class="line">                           min_fraction_of_examples_in_queue)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Generate a batch of images and labels by building up a queue of examples.</span></span><br><span class="line">  <span class="keyword">return</span> _generate_image_and_label_batch(float_image, read_input.label,</span><br><span class="line">                                         min_queue_examples, batch_size,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h2 id="cifar10-input-test-py"><a href="#cifar10-input-test-py" class="headerlink" title="cifar10_input_test.py"></a>cifar10_input_test.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""Tests for cifar10 input."""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cifar10_input</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CIFAR10InputTest</span><span class="params">(tf.test.TestCase)</span>:</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_record</span><span class="params">(self, label, red, green, blue)</span>:</span></span><br><span class="line">    image_size = <span class="number">32</span> * <span class="number">32</span></span><br><span class="line">    record = bytes(bytearray([label] + [red] * image_size +</span><br><span class="line">                             [green] * image_size + [blue] * image_size))</span><br><span class="line">    expected = [[[red, green, blue]] * <span class="number">32</span>] * <span class="number">32</span></span><br><span class="line">    <span class="keyword">return</span> record, expected</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">testSimple</span><span class="params">(self)</span>:</span></span><br><span class="line">    labels = [<span class="number">9</span>, <span class="number">3</span>, <span class="number">0</span>]</span><br><span class="line">    records = [self._record(labels[<span class="number">0</span>], <span class="number">0</span>, <span class="number">128</span>, <span class="number">255</span>),</span><br><span class="line">               self._record(labels[<span class="number">1</span>], <span class="number">255</span>, <span class="number">0</span>, <span class="number">1</span>),</span><br><span class="line">               self._record(labels[<span class="number">2</span>], <span class="number">254</span>, <span class="number">255</span>, <span class="number">0</span>)]</span><br><span class="line">    contents = <span class="string">b""</span>.join([record <span class="keyword">for</span> record, _ <span class="keyword">in</span> records])</span><br><span class="line">    expected = [expected <span class="keyword">for</span> _, expected <span class="keyword">in</span> records]</span><br><span class="line">    filename = os.path.join(self.get_temp_dir(), <span class="string">"cifar"</span>)</span><br><span class="line">    open(filename, <span class="string">"wb"</span>).write(contents)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> self.test_session() <span class="keyword">as</span> sess:</span><br><span class="line">      q = tf.FIFOQueue(<span class="number">99</span>, [tf.string], shapes=())</span><br><span class="line">      q.enqueue([filename]).run()</span><br><span class="line">      q.close().run()</span><br><span class="line">      result = cifar10_input.read_cifar10(q)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        key, label, uint8image = sess.run([</span><br><span class="line">            result.key, result.label, result.uint8image])</span><br><span class="line">        self.assertEqual(<span class="string">"%s:%d"</span> % (filename, i), tf.compat.as_text(key))</span><br><span class="line">        self.assertEqual(labels[i], label)</span><br><span class="line">        self.assertAllEqual(expected[i], uint8image)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">with</span> self.assertRaises(tf.errors.OutOfRangeError):</span><br><span class="line">        sess.run([result.key, result.uint8image])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">  tf.test.main()</span><br></pre></td></tr></table></figure>

<h2 id="cifar10-multi-gpu-train-py"><a href="#cifar10-multi-gpu-train-py" class="headerlink" title="cifar10_multi_gpu_train.py"></a>cifar10_multi_gpu_train.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""A binary to train CIFAR-10 using multiple GPUs with synchronous updates.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Accuracy:</span></span><br><span class="line"><span class="string">cifar10_multi_gpu_train.py achieves ~86% accuracy after 100K steps (256</span></span><br><span class="line"><span class="string">epochs of data) as judged by cifar10_eval.py.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Speed: With batch_size 128.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">System        | Step Time (sec/batch)  |     Accuracy</span></span><br><span class="line"><span class="string">--------------------------------------------------------------------</span></span><br><span class="line"><span class="string">1 Tesla K20m  | 0.35-0.60              | ~86% at 60K steps  (5 hours)</span></span><br><span class="line"><span class="string">1 Tesla K40m  | 0.25-0.35              | ~86% at 100K steps (4 hours)</span></span><br><span class="line"><span class="string">2 Tesla K20m  | 0.13-0.20              | ~84% at 30K steps  (2.5 hours)</span></span><br><span class="line"><span class="string">3 Tesla K20m  | 0.13-0.18              | ~84% at 30K steps</span></span><br><span class="line"><span class="string">4 Tesla K20m  | ~0.10                  | ~84% at 30K steps</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Usage:</span></span><br><span class="line"><span class="string">Please see the tutorial and website for how to download the CIFAR-10</span></span><br><span class="line"><span class="string">data set, compile the program and train the model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">http://tensorflow.org/tutorials/deep_cnn/</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> xrange  <span class="comment"># pylint: disable=redefined-builtin</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> cifar10</span><br><span class="line"></span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line"></span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">'train_dir'</span>, <span class="string">'/tmp/cifar10_train'</span>,</span><br><span class="line">                           <span class="string">"""Directory where to write event logs """</span></span><br><span class="line">                           <span class="string">"""and checkpoint."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'max_steps'</span>, <span class="number">1000000</span>,</span><br><span class="line">                            <span class="string">"""Number of batches to run."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'num_gpus'</span>, <span class="number">1</span>,</span><br><span class="line">                            <span class="string">"""How many GPUs to use."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_boolean(<span class="string">'log_device_placement'</span>, <span class="literal">False</span>,</span><br><span class="line">                            <span class="string">"""Whether to log device placement."""</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tower_loss</span><span class="params">(scope)</span>:</span></span><br><span class="line">  <span class="string">"""Calculate the total loss on a single tower running the CIFAR model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    scope: unique prefix string identifying the CIFAR tower, e.g. 'tower_0'</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">     Tensor of shape [] containing the total loss for a batch of data</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># Get images and labels for CIFAR-10.</span></span><br><span class="line">  images, labels = cifar10.distorted_inputs()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Build inference Graph.</span></span><br><span class="line">  logits = cifar10.inference(images)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Build the portion of the Graph calculating the losses. Note that we will</span></span><br><span class="line">  <span class="comment"># assemble the total_loss using a custom function below.</span></span><br><span class="line">  _ = cifar10.loss(logits, labels)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Assemble all of the losses for the current tower only.</span></span><br><span class="line">  losses = tf.get_collection(<span class="string">'losses'</span>, scope)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Calculate the total loss for the current tower.</span></span><br><span class="line">  total_loss = tf.add_n(losses, name=<span class="string">'total_loss'</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Attach a scalar summary to all individual losses and the total loss; do the</span></span><br><span class="line">  <span class="comment"># same for the averaged version of the losses.</span></span><br><span class="line">  <span class="keyword">for</span> l <span class="keyword">in</span> losses + [total_loss]:</span><br><span class="line">    <span class="comment"># Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training</span></span><br><span class="line">    <span class="comment"># session. This helps the clarity of presentation on tensorboard.</span></span><br><span class="line">    loss_name = re.sub(<span class="string">'%s_[0-9]*/'</span> % cifar10.TOWER_NAME, <span class="string">''</span>, l.op.name)</span><br><span class="line">    tf.summary.scalar(loss_name, l)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> total_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">average_gradients</span><span class="params">(tower_grads)</span>:</span></span><br><span class="line">  <span class="string">"""Calculate the average gradient for each shared variable across all towers.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Note that this function provides a synchronization point across all towers.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    tower_grads: List of lists of (gradient, variable) tuples. The outer list</span></span><br><span class="line"><span class="string">      is over individual gradients. The inner list is over the gradient</span></span><br><span class="line"><span class="string">      calculation for each tower.</span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">     List of pairs of (gradient, variable) where the gradient has been averaged</span></span><br><span class="line"><span class="string">     across all towers.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  average_grads = []</span><br><span class="line">  <span class="keyword">for</span> grad_and_vars <span class="keyword">in</span> zip(*tower_grads):</span><br><span class="line">    <span class="comment"># Note that each grad_and_vars looks like the following:</span></span><br><span class="line">    <span class="comment">#   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))</span></span><br><span class="line">    grads = []</span><br><span class="line">    <span class="keyword">for</span> g, _ <span class="keyword">in</span> grad_and_vars:</span><br><span class="line">      <span class="comment"># Add 0 dimension to the gradients to represent the tower.</span></span><br><span class="line">      expanded_g = tf.expand_dims(g, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Append on a 'tower' dimension which we will average over below.</span></span><br><span class="line">      grads.append(expanded_g)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Average over the 'tower' dimension.</span></span><br><span class="line">    grad = tf.concat(axis=<span class="number">0</span>, values=grads)</span><br><span class="line">    grad = tf.reduce_mean(grad, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Keep in mind that the Variables are redundant because they are shared</span></span><br><span class="line">    <span class="comment"># across towers. So .. we will just return the first tower's pointer to</span></span><br><span class="line">    <span class="comment"># the Variable.</span></span><br><span class="line">    v = grad_and_vars[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">    grad_and_var = (grad, v)</span><br><span class="line">    average_grads.append(grad_and_var)</span><br><span class="line">  <span class="keyword">return</span> average_grads</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="string">"""Train CIFAR-10 for a number of steps."""</span></span><br><span class="line">  <span class="keyword">with</span> tf.Graph().as_default(), tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line">    <span class="comment"># Create a variable to count the number of train() calls. This equals the</span></span><br><span class="line">    <span class="comment"># number of batches processed * FLAGS.num_gpus.</span></span><br><span class="line">    global_step = tf.get_variable(</span><br><span class="line">        <span class="string">'global_step'</span>, [],</span><br><span class="line">        initializer=tf.constant_initializer(<span class="number">0</span>), trainable=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate the learning rate schedule.</span></span><br><span class="line">    num_batches_per_epoch = (cifar10.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN /</span><br><span class="line">                             FLAGS.batch_size)</span><br><span class="line">    decay_steps = int(num_batches_per_epoch * cifar10.NUM_EPOCHS_PER_DECAY)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Decay the learning rate exponentially based on the number of steps.</span></span><br><span class="line">    lr = tf.train.exponential_decay(cifar10.INITIAL_LEARNING_RATE,</span><br><span class="line">                                    global_step,</span><br><span class="line">                                    decay_steps,</span><br><span class="line">                                    cifar10.LEARNING_RATE_DECAY_FACTOR,</span><br><span class="line">                                    staircase=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create an optimizer that performs gradient descent.</span></span><br><span class="line">    opt = tf.train.GradientDescentOptimizer(lr)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate the gradients for each model tower.</span></span><br><span class="line">    tower_grads = []</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(tf.get_variable_scope()):</span><br><span class="line">      <span class="keyword">for</span> i <span class="keyword">in</span> xrange(FLAGS.num_gpus):</span><br><span class="line">        <span class="keyword">with</span> tf.device(<span class="string">'/gpu:%d'</span> % i):</span><br><span class="line">          <span class="keyword">with</span> tf.name_scope(<span class="string">'%s_%d'</span> % (cifar10.TOWER_NAME, i)) <span class="keyword">as</span> scope:</span><br><span class="line">            <span class="comment"># Calculate the loss for one tower of the CIFAR model. This function</span></span><br><span class="line">            <span class="comment"># constructs the entire CIFAR model but shares the variables across</span></span><br><span class="line">            <span class="comment"># all towers.</span></span><br><span class="line">            loss = tower_loss(scope)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Reuse variables for the next tower.</span></span><br><span class="line">            tf.get_variable_scope().reuse_variables()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Retain the summaries from the final tower.</span></span><br><span class="line">            summaries = tf.get_collection(tf.GraphKeys.SUMMARIES, scope)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Calculate the gradients for the batch of data on this CIFAR tower.</span></span><br><span class="line">            grads = opt.compute_gradients(loss)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Keep track of the gradients across all towers.</span></span><br><span class="line">            tower_grads.append(grads)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># We must calculate the mean of each gradient. Note that this is the</span></span><br><span class="line">    <span class="comment"># synchronization point across all towers.</span></span><br><span class="line">    grads = average_gradients(tower_grads)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add a summary to track the learning rate.</span></span><br><span class="line">    summaries.append(tf.summary.scalar(<span class="string">'learning_rate'</span>, lr))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add histograms for gradients.</span></span><br><span class="line">    <span class="keyword">for</span> grad, var <span class="keyword">in</span> grads:</span><br><span class="line">      <span class="keyword">if</span> grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        summaries.append(tf.summary.histogram(var.op.name + <span class="string">'/gradients'</span>, grad))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Apply the gradients to adjust the shared variables.</span></span><br><span class="line">    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add histograms for trainable variables.</span></span><br><span class="line">    <span class="keyword">for</span> var <span class="keyword">in</span> tf.trainable_variables():</span><br><span class="line">      summaries.append(tf.summary.histogram(var.op.name, var))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Track the moving averages of all trainable variables.</span></span><br><span class="line">    variable_averages = tf.train.ExponentialMovingAverage(</span><br><span class="line">        cifar10.MOVING_AVERAGE_DECAY, global_step)</span><br><span class="line">    variables_averages_op = variable_averages.apply(tf.trainable_variables())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Group all updates to into a single train op.</span></span><br><span class="line">    train_op = tf.group(apply_gradient_op, variables_averages_op)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a saver.</span></span><br><span class="line">    saver = tf.train.Saver(tf.global_variables())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build the summary operation from the last tower summaries.</span></span><br><span class="line">    summary_op = tf.summary.merge(summaries)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build an initialization operation to run below.</span></span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Start running operations on the Graph. allow_soft_placement must be set to</span></span><br><span class="line">    <span class="comment"># True to build towers on GPU, as some of the ops do not have GPU</span></span><br><span class="line">    <span class="comment"># implementations.</span></span><br><span class="line">    sess = tf.Session(config=tf.ConfigProto(</span><br><span class="line">        allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">        log_device_placement=FLAGS.log_device_placement))</span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Start the queue runners.</span></span><br><span class="line">    tf.train.start_queue_runners(sess=sess)</span><br><span class="line"></span><br><span class="line">    summary_writer = tf.summary.FileWriter(FLAGS.train_dir, sess.graph)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> xrange(FLAGS.max_steps):</span><br><span class="line">      start_time = time.time()</span><br><span class="line">      _, loss_value = sess.run([train_op, loss])</span><br><span class="line">      duration = time.time() - start_time</span><br><span class="line"></span><br><span class="line">      <span class="keyword">assert</span> <span class="keyword">not</span> np.isnan(loss_value), <span class="string">'Model diverged with loss = NaN'</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> step % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        num_examples_per_step = FLAGS.batch_size * FLAGS.num_gpus</span><br><span class="line">        examples_per_sec = num_examples_per_step / duration</span><br><span class="line">        sec_per_batch = duration / FLAGS.num_gpus</span><br><span class="line"></span><br><span class="line">        format_str = (<span class="string">'%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '</span></span><br><span class="line">                      <span class="string">'sec/batch)'</span>)</span><br><span class="line">        <span class="keyword">print</span> (format_str % (datetime.now(), step, loss_value,</span><br><span class="line">                             examples_per_sec, sec_per_batch))</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        summary_str = sess.run(summary_op)</span><br><span class="line">        summary_writer.add_summary(summary_str, step)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Save the model checkpoint periodically.</span></span><br><span class="line">      <span class="keyword">if</span> step % <span class="number">1000</span> == <span class="number">0</span> <span class="keyword">or</span> (step + <span class="number">1</span>) == FLAGS.max_steps:</span><br><span class="line">        checkpoint_path = os.path.join(FLAGS.train_dir, <span class="string">'model.ckpt'</span>)</span><br><span class="line">        saver.save(sess, checkpoint_path, global_step=step)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(argv=None)</span>:</span>  <span class="comment"># pylint: disable=unused-argument</span></span><br><span class="line">  cifar10.maybe_download_and_extract()</span><br><span class="line">  <span class="keyword">if</span> tf.gfile.Exists(FLAGS.train_dir):</span><br><span class="line">    tf.gfile.DeleteRecursively(FLAGS.train_dir)</span><br><span class="line">  tf.gfile.MakeDirs(FLAGS.train_dir)</span><br><span class="line">  train()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  tf.app.run()</span><br></pre></td></tr></table></figure>

<h2 id="cifar10-train-py"><a href="#cifar10-train-py" class="headerlink" title="cifar10_train.py"></a>cifar10_train.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""A binary to train CIFAR-10 using a single GPU.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Accuracy:</span></span><br><span class="line"><span class="string">cifar10_train.py achieves ~86% accuracy after 100K steps (256 epochs of</span></span><br><span class="line"><span class="string">data) as judged by cifar10_eval.py.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Speed: With batch_size 128.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">System        | Step Time (sec/batch)  |     Accuracy</span></span><br><span class="line"><span class="string">------------------------------------------------------------------</span></span><br><span class="line"><span class="string">1 Tesla K20m  | 0.35-0.60              | ~86% at 60K steps  (5 hours)</span></span><br><span class="line"><span class="string">1 Tesla K40m  | 0.25-0.35              | ~86% at 100K steps (4 hours)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Usage:</span></span><br><span class="line"><span class="string">Please see the tutorial and website for how to download the CIFAR-10</span></span><br><span class="line"><span class="string">data set, compile the program and train the model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">http://tensorflow.org/tutorials/deep_cnn/</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cifar10</span><br><span class="line"></span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line"></span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">'train_dir'</span>, <span class="string">'/tmp/cifar10_train'</span>,</span><br><span class="line">                           <span class="string">"""Directory where to write event logs """</span></span><br><span class="line">                           <span class="string">"""and checkpoint."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'max_steps'</span>, <span class="number">1000000</span>,</span><br><span class="line">                            <span class="string">"""Number of batches to run."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_boolean(<span class="string">'log_device_placement'</span>, <span class="literal">False</span>,</span><br><span class="line">                            <span class="string">"""Whether to log device placement."""</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'log_frequency'</span>, <span class="number">10</span>,</span><br><span class="line">                            <span class="string">"""How often to log results to the console."""</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="string">"""Train CIFAR-10 for a number of steps."""</span></span><br><span class="line">  <span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    global_step = tf.contrib.framework.get_or_create_global_step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get images and labels for CIFAR-10.</span></span><br><span class="line">    images, labels = cifar10.distorted_inputs()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build a Graph that computes the logits predictions from the</span></span><br><span class="line">    <span class="comment"># inference model.</span></span><br><span class="line">    logits = cifar10.inference(images)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate loss.</span></span><br><span class="line">    loss = cifar10.loss(logits, labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build a Graph that trains the model with one batch of examples and</span></span><br><span class="line">    <span class="comment"># updates the model parameters.</span></span><br><span class="line">    train_op = cifar10.train(loss, global_step)</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">_LoggerHook</span><span class="params">(tf.train.SessionRunHook)</span>:</span></span><br><span class="line">      <span class="string">"""Logs loss and runtime."""</span></span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">begin</span><span class="params">(self)</span>:</span></span><br><span class="line">        self._step = <span class="number">-1</span></span><br><span class="line">        self._start_time = time.time()</span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">before_run</span><span class="params">(self, run_context)</span>:</span></span><br><span class="line">        self._step += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> tf.train.SessionRunArgs(loss)  <span class="comment"># Asks for loss value.</span></span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">after_run</span><span class="params">(self, run_context, run_values)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self._step % FLAGS.log_frequency == <span class="number">0</span>:</span><br><span class="line">          current_time = time.time()</span><br><span class="line">          duration = current_time - self._start_time</span><br><span class="line">          self._start_time = current_time</span><br><span class="line"></span><br><span class="line">          loss_value = run_values.results</span><br><span class="line">          examples_per_sec = FLAGS.log_frequency * FLAGS.batch_size / duration</span><br><span class="line">          sec_per_batch = float(duration / FLAGS.log_frequency)</span><br><span class="line"></span><br><span class="line">          format_str = (<span class="string">'%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '</span></span><br><span class="line">                        <span class="string">'sec/batch)'</span>)</span><br><span class="line">          print(format_str % (datetime.now(), self._step, loss_value,</span><br><span class="line">                              examples_per_sec, sec_per_batch))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.train.MonitoredTrainingSession(</span><br><span class="line">        checkpoint_dir=FLAGS.train_dir,</span><br><span class="line">        hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),</span><br><span class="line">               tf.train.NanTensorHook(loss),</span><br><span class="line">               _LoggerHook()],</span><br><span class="line">        config=tf.ConfigProto(</span><br><span class="line">            log_device_placement=FLAGS.log_device_placement)) <span class="keyword">as</span> mon_sess:</span><br><span class="line">      <span class="keyword">while</span> <span class="keyword">not</span> mon_sess.should_stop():</span><br><span class="line">        mon_sess.run(train_op)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(argv=None)</span>:</span>  <span class="comment"># pylint: disable=unused-argument</span></span><br><span class="line">  cifar10.maybe_download_and_extract()</span><br><span class="line">  <span class="keyword">if</span> tf.gfile.Exists(FLAGS.train_dir):</span><br><span class="line">    tf.gfile.DeleteRecursively(FLAGS.train_dir)</span><br><span class="line">  tf.gfile.MakeDirs(FLAGS.train_dir)</span><br><span class="line">  train()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  tf.app.run()</span><br></pre></td></tr></table></figure>

<h2 id="test-py"><a href="#test-py" class="headerlink" title="test.py"></a>test.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'read'</span>):</span><br><span class="line">    os.makedirs(<span class="string">'read/'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入TensorFlow</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建一个Session</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 我们要读三幅图片A.jpg, B.jpg, C.jpg</span></span><br><span class="line">    filename = [<span class="string">'A.jpg'</span>, <span class="string">'B.jpg'</span>, <span class="string">'C.jpg'</span>]</span><br><span class="line">    <span class="comment"># string_input_producer会产生一个文件名队列</span></span><br><span class="line">    filename_queue = tf.train.string_input_producer(filename, shuffle=<span class="literal">False</span>, num_epochs=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># reader从文件名队列中读数据。对应的方法是reader.read</span></span><br><span class="line">    reader = tf.WholeFileReader()</span><br><span class="line">    key, value = reader.read(filename_queue)</span><br><span class="line">    <span class="comment"># tf.train.string_input_producer定义了一个epoch变量，要对它进行初始化</span></span><br><span class="line">    tf.local_variables_initializer().run()</span><br><span class="line">    <span class="comment"># 使用start_queue_runners之后，才会开始填充队列</span></span><br><span class="line">    threads = tf.train.start_queue_runners(sess=sess)</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 获取图片数据并保存</span></span><br><span class="line">        image_data = sess.run(value)</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'read/test_%d.jpg'</span> % i, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(image_data)</span><br><span class="line"><span class="comment"># 程序最后会抛出一个OutOfRangeError，这是epoch跑完，队列关闭的标志</span></span><br></pre></td></tr></table></figure>


    </div>

    
    
    
        
      
        <div id="reward-container">
  <div>您的支持是对我最大的鼓励</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
        
      
      <div style="display: inline-block">
        <img src="/images/weixin.jpg" alt="陈 建 微信支付">
        <p>微信支付</p>
      </div>
        
      
      <div style="display: inline-block">
        <img src="/images/alipay.jpg" alt="陈 建 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

      
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>陈 建</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://leesin.cc/tensorflow/2.21个项目玩转深度学习之CIFAR10与ImageNet图像识别.html" title="2.21个项目玩转深度学习之CIFAR10与ImageNet图像识别">http://leesin.cc/tensorflow/2.21个项目玩转深度学习之CIFAR10与ImageNet图像识别.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>
</div>

      

      <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/tensorflow/1.21个项目玩转深度学习之MNIST机器学习入门.html" rel="next" title="1.21个项目玩转深度学习之MNIST机器学习入门.md">
                  <i class="fa fa-chevron-left"></i> 1.21个项目玩转深度学习之MNIST机器学习入门.md
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/tensorflow/3.21个项目玩转深度学习之打造自己的图像识别模型.html" rel="prev" title="3.21个项目玩转深度学习之打造自己的图像识别模型">
                  3.21个项目玩转深度学习之打造自己的图像识别模型 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar.jpg"
      alt="陈 建">
  <p class="site-author-name" itemprop="name">陈 建</p>
  <div class="site-description motion-element" itemprop="description">当时明月在，曾照彩云归</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">102</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/LeeSinCOOC" title="GitHub &rarr; https://github.com/LeeSinCOOC" rel="noopener" target="_blank"><i class="fa fa-fw fa-GitHub"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:690246265@qq.com" title="E-Mail &rarr; mailto:690246265@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-E-Mail"></i>E-Mail</a>
      </span>
    
  </div>


  <div class="links-of-blogroll motion-element links-of-blogroll-block">
    <div class="links-of-blogroll-title">
      <i class="fa  fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.baidu.com" title="https://www.baidu.com" rel="noopener" target="_blank">baidu</a>
        </li>
      
    </ul>
  </div>


        </div>
      </div>
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#CIFAR-10图像识别"><span class="nav-number">1.</span> <span class="nav-text">CIFAR-10图像识别</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#CIFAR-10数据集下载"><span class="nav-number">1.1.</span> <span class="nav-text">CIFAR-10数据集下载</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tensorflow-的数据读取机制"><span class="nav-number">1.2.</span> <span class="nav-text">Tensorflow 的数据读取机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#读取示例"><span class="nav-number">1.2.1.</span> <span class="nav-text">读取示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#将CIFAR-10数据保存为图片"><span class="nav-number">1.2.2.</span> <span class="nav-text">将CIFAR-10数据保存为图片</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TensorFlow-训练-CIFAR-10"><span class="nav-number">1.3.</span> <span class="nav-text">TensorFlow 训练 CIFAR-10</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#数据增强常用方法"><span class="nav-number">1.3.1.</span> <span class="nav-text">数据增强常用方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TensorFlow中数据增强的实现"><span class="nav-number">1.3.2.</span> <span class="nav-text">TensorFlow中数据增强的实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CIFAR-10识别模型"><span class="nav-number">1.3.3.</span> <span class="nav-text">CIFAR-10识别模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练模型"><span class="nav-number">1.3.4.</span> <span class="nav-text">训练模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#在TensorFlow中查看训练进度"><span class="nav-number">1.3.5.</span> <span class="nav-text">在TensorFlow中查看训练进度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测试模型效果"><span class="nav-number">1.3.6.</span> <span class="nav-text">测试模型效果</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cifar10-download-py"><span class="nav-number">1.4.</span> <span class="nav-text">cifar10_download.py</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cifar10-eval-py"><span class="nav-number">1.5.</span> <span class="nav-text">cifar10_eval.py</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cifar10-extract-py"><span class="nav-number">1.6.</span> <span class="nav-text">cifar10_extract.py</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cifar10-input-py"><span class="nav-number">1.7.</span> <span class="nav-text">cifar10_input.py</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cifar10-input-test-py"><span class="nav-number">1.8.</span> <span class="nav-text">cifar10_input_test.py</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cifar10-multi-gpu-train-py"><span class="nav-number">1.9.</span> <span class="nav-text">cifar10_multi_gpu_train.py</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cifar10-train-py"><span class="nav-number">1.10.</span> <span class="nav-text">cifar10_train.py</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#test-py"><span class="nav-number">1.11.</span> <span class="nav-text">test.py</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">陈 建</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.3.0</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  
    <span class="post-meta-divider">|</span>
  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>








        
      </div>
    </footer>
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
      </div>

    

  </div>

  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>

<script src="/js/schemes/muse.js?v=7.3.0"></script>



<script src="/js/next-boot.js?v=7.3.0"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>















  <script src="/js/local-search.js?v=7.3.0"></script>














  

  

  


  
  <script src="/js/scrollspy.js?v=7.3.0"></script><script src="/js/post-details.js?v=7.3.0"></script>


</body>
</html>
